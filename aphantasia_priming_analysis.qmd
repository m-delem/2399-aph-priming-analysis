---
title: "Sensory priming in aphantasia - Data analysis"
author: "MaÃ«l Delem"
format: html
editor_options: 
  chunk_output_type: console
toc: true
---

This analysis was conducted in R language through the RStudio Integrated Development Environment. Just down below is the setup code, including two essential steps: 1) installing the required packages for this data analysis, and 2) importing data into the dataframes used throughout. I left this (usually hidden) step there for reference in a view of transparency for the interested reader.

```{r setup}

# --- Packages -----------------------------------------------------------------

# The package `librairian` will ease the package management with the "shelf" 
# function, which automatically: 
# 1) checks if a package is installed 
# 2) installs it if need be
# 3) loads the package like the "library()" function would.
if (!require(librarian)) install.packages(librarian)
library(librarian)

# now putting packages on our library's shelves:
shelf(
  readxl,         # Excel files management
  easystats,      # collection of data analysis packages
  tidymodels,     # collection of packages for a tidy modelling workflow
  bayesian,       # bayesian modelling with brms and tidymodels
  mclust,         # mixture clustering
  ggpubr,         # ggplot tools
  viridis,        # ggplot colour-blind friendly palettes
  tidyverse       # the essentials
)

# --- Global cosmetic theme ---
theme_set(theme_bw(base_size = 14))

# --- Fixing a seed for reproducibility ---
set.seed(14051998)

# --- Importing data -----------------------------------------------------------

# Association task
df_asso <- read_excel("data/aphantasia_priming_tidy_data.xlsx", 
                     sheet = "data_asso")

# Implicit task
df_implicit <- read_excel("data/aphantasia_priming_tidy_data.xlsx", 
                     sheet = "data_implicit")

# Explicit task
df_explicit <- read_excel("data/aphantasia_priming_tidy_data.xlsx", 
                     sheet = "data_explicit")

# Rotation task
df_rotation <- read_excel("data/aphantasia_priming_tidy_data.xlsx", 
                     sheet = "data_rotation")

# Questionnaires
df_questionnaires <- 
  read_excel(
    "data/aphantasia_priming_tidy_data.xlsx",
    sheet = "data_questionnaires"
    ) %>% 
  # creating the a/phantasia groups
  mutate(
    aphantasia = ifelse(vviq80 < 32, "yes", "no"),
    aphantasia = fct_relevel(aphantasia, "yes", "no")
    )
```

# Exploratory Data Analysis

## Questionnaire data and imagery

### Correlations

The four questionnaire variables - VVIQ, OSIQ-Object and Spatial, and SUIS - are meant to be used as predictors (independent variables) for the behavioural outcomes of the experiment (dependent variables, RTs and potentially accuracy). Three of these - VVIQ, OSIQ-Object and SUIS - evaluate visual imagery: as such, in a view of parsimony, we are going to evaluate the correlation between these continuous predictors and judge if they should be merged/omitted. The results of the Bayesian partial correlations between the four variables are displayed in @fig-cor_matrix and @tbl-cor_stats. Partial correlations have been chosen here to account for the (theoretically huge) covariance between visual imagery variables. It will result in more conservative estimations of the correlations, and a better understanding of the relations between visual and spatial imagery measures.

```{r correlation}

# --- Bayesian Pearson correlation between questionnaire scores ---
cor_questionnaires <-
  df_questionnaires %>%
  select("vviq80", "suis60","osiq_o75", "osiq_s75") %>% 
  standardise %>% 
  correlation(
    bayesian = TRUE,
    partial = TRUE,
    partial_bayesian = TRUE,
    bayesian_test = "bf"
    )
```

```{r correlation_matrix}
#| label: fig-cor_matrix
#| echo: false
#| fig-cap: "Correlation matrix of the questionnaire variables. The stars indicate the amount of evidence in favour of a correlation, as assessed by the $BF_{10}$: No star = Anecdotal evidence, * = Weak evidence, ** = Moderate evidence, *** = Extreme evidence."

# --- Correlation matrix ---
cor_questionnaires %>%
  mutate(across(c(Parameter1, Parameter2),
    ~ case_when(
    .x == "vviq80" ~ "VVIQ",
    .x == "suis60" ~ "SUIS",
    .x == "osiq_o75" ~ "OSIQ-O",
    .x == "osiq_s75" ~ "OSIQ-S"))
    ) %>% 
  summary(digits = 2) %>% 
  plot(
    text = list(size = 5),
    labs = list(title = "")
    ) +
  scale_fill_viridis(
    option = "D",
    name = expression(rho),
    alpha = .6,
    direction = 1,
    limits = c(-1,1)
    ) +
  theme_bw() +
  theme(
    panel.grid = element_blank(),
    axis.text = element_text(size = 14)
    )
```

```{r correlation_table}
#| label: tbl-cor_stats
#| echo: false
#| tbl-cap: "Detailed correlation table of the questionnaire variables."

# --- Correlation table ---
cor_questionnaires %>%
  format %>% 
  mutate(across(c(Parameter1, Parameter2),
    ~ case_when(
    .x == "vviq80" ~ "VVIQ",
    .x == "suis60" ~ "SUIS",
    .x == "osiq_o75" ~ "OSIQ-O",
    .x == "osiq_s75" ~ "OSIQ-S"))
    ) %>% 
  rename(
    "Variable 1" = Parameter1,
    "Variable 2" = Parameter2,
    "$\\rho$" = rho,
    "$BF_{10}$" = BF
  ) %>% 
  knitr::kable()
```

As we can see, while the three visual imagery variables are highly correlated, the association between these visual and spatial imagery (OSIQ-S) is inconsistent: VVIQ and OSIQ-S are positively correlated although with anecdotal evidence, SUIS and OSIQ-S have a moderately evidenced positive correlation, while OSIQ-Object and OSIQ-Spatial are negatively correlated. We'll run a Principal Component Analysis to evaluate the possibility of a feature reduction of visual imagery as a single variable.

### Principal Component Analysis

```{r pca}
# --- Principal Component Analysis ---
pca <- 
  principal_components(
    df_questionnaires[,4:7],
    n = "max",
    sort = TRUE,
    standardize = TRUE
    ) 
```

```{r loadings}
#| label: fig-loadings
#| echo: false
#| fig-cap: "Loadings of each variable on the three components extracted by a PCA."

# --- Loadings ---
pca %>% plot + 
  scale_y_discrete(labels = c("OSIQ-S", "OSIQ-O", "VVIQ", "SUIS")) +
  scale_fill_viridis(alpha = .6) +
  labs(title = NULL) +
  theme(text = element_text(size = 14))
```

```{r eigenvalues}
#| label: tbl-eigenvalues
#| echo: false
#| tbl-cap: "Eigenvalues and variance explained by the three components extracted by a PCA."

# --- Eigenvalues and variance ---
pca %>% 
  summary %>% 
  rename(
    "Component 1" = PC1,
    "Component 2" = PC2,
    "Component 3" = PC3,
  ) %>%
  format(digits = 2) %>% 
  display
```

As expected, the visual imagery variables are grouped in a single component ("PC1" in @fig-loadings or "Component 1" in @tbl-eigenvalues) with an Eigenvalue of 2.84, therefore accounting for 71% of the total variance of the data. The second component (PC2 / Component 2) has an Eigenvalue of .97, accounts for 24% of the total variance, and is mostly loaded negatively on the OSIQ-S: this brings the total explained proportion of variance to 95%. Traditionally, the threshold used for selecting a principal component is an Eigenvalue of 1. Nevertheless, given the Eigenvalue of .97 and the properties of this component, i.e. singling out the specificity of the spatial scale, this component will be kept for analysis.

Standardized predicted values for each component will be computed and added to the data, renamed ***Visual Imagery*** (PC1, mostly VVIQ + SUIS + OSIQ-O with an influence of OSIQ-S) and ***Spatial Imagery*** (PC2, mostly OSIQ-S, with an influence of SUIS). In order to align the Spatial Imagery variable with the OSIQ-Spatial, the variable will be reversed (they are correlated negatively as it is, as shown by the -.96 loading on PC2).

```{r pca_components}
pca_components <- pca %>% predict

df_questionnaires_pca <- 
  bind_cols(df_questionnaires, pca_components[,1:2]) %>% 
  mutate(
    PC1 = standardize(PC1),
    PC2 = -standardize(PC2)
    ) %>% 
  rename(
    "visual_imagery" = PC1,
    "spatial_imagery" = PC2
    )
```

### VVIQ, visual and spatial imagery

Now we can see that the main visual imagery variables, namely the (conventional) VVIQ and the *Visual Imagery* component created through PCA are completely decorrelated from the *Spatial Imagery* component, as shown in @fig-spatial_corr.

```{r spatial_correlations}
#| label: fig-spatial_corr
#| echo: false
#| fig-cap: "Correlation between the main visual imagery variables and the spatial imagery one."
#| fig-width: 9
#| fig-height: 4.5

# --- correlation between visual and spatial ---
p_cor_spatial_vis <- 
  df_questionnaires_pca %>% 
  mutate(
    visual_imagery = rescale(visual_imagery),
    spatial_imagery = rescale(spatial_imagery),
    aphantasia = fct_relevel(aphantasia, "yes", "no")
    ) %>%
  ggplot(aes(x = visual_imagery, y = spatial_imagery, color = aphantasia)) +
  geom_point() +
  scale_color_okabeito(name = "Aphantasia", labels = c("Yes", "No")) +
  geom_smooth(
    aes(x = visual_imagery, y = spatial_imagery), 
    color = "black", 
    method = "lm", 
    stat = "smooth") +
  stat_cor(
    aes(x = visual_imagery, 
        y = spatial_imagery), 
    inherit.aes = FALSE, 
    cor.coef.name = "r", 
    label.x.npc = .5,
    label.y.npc = .7) +
  labs(x = "Visual Imagery",
       y = "Spatial Imagery")

# --- correlation between vviq and spatial ---
p_cor_spatial_vviq <- 
  df_questionnaires_pca %>% 
  mutate(
    vviq80 = rescale(vviq80),
    spatial_imagery = rescale(spatial_imagery)
    ) %>%
  ggplot(aes(x = vviq80, y = spatial_imagery, color = aphantasia)) +
  geom_point() +
  scale_color_okabeito(name = "Aphantasia", labels = c("Yes", "No")) +
  geom_smooth(
    aes(x = vviq80, y = spatial_imagery), 
    color = "black", 
    method = "lm", 
    stat = "smooth") +
  stat_cor(
    aes(x = vviq80, 
        y = spatial_imagery), 
    inherit.aes = FALSE, 
    cor.coef.name = "r", 
    label.x.npc = .5,
    label.y.npc = .7) +
  labs(x = "VVIQ",
       y = "Spatial Imagery")

ggarrange(
  p_cor_spatial_vis,
  p_cor_spatial_vviq + rremove("ylab"),
  common.legend = TRUE,
  legend = "bottom"
)

```

The consequence of this analysis is that from this point onwards, for the future models to be fitted, two options are available:

- Binning the participants in two categories based on the VVIQ (cut-off at 32, Aphantasics/Phantasics).

- Using the visual imagery as a continuous variable.

Although we could use the VVIQ both for categorizing and as a classification variable, for the sake of consistency, we are going to use the VVIQ only as a classification variable for defining aphantasia, and the *Visual Imagery* component from the PCA as the continuous variable measuring visual imagery. Therefore two types of models are going to be fitted:

1. Models using **Aphantasia as a categorical variable.**

2. Models using **Visual Imagery as a continuous variable.**

In both cases, we are going to account for the potential effect of spatial imagery by using the eponymous component computed earlier as a predictor in the models.

```{r df_updates}
#| echo: false

# updating all the dataframes with the imagery variables
dfs <- 
  list(df_asso, df_implicit, df_explicit, df_rotation) %>%
  # adding the vviq and group column to every dataframe
  imap(~left_join(
    .x, 
    df_questionnaires_pca %>% 
      select(
        # column to match with the correct participants
        subjectid, 
        # new variables to add
        age,
        sexe,
        vviq80, 
        visual_imagery, 
        spatial_imagery,
        aphantasia), by = "subjectid") %>% 
      rename("sex" = sexe) %>% 
      # reordering the final dfs
      select(
        subjectid, 
        age, sex, aphantasia,
        vviq80, visual_imagery, spatial_imagery,
        everything())
    )

df_asso     <- dfs[[1]]
df_implicit <- dfs[[2]]
df_explicit <- dfs[[3]]
df_rotation <- dfs[[4]]
```

## Outcomes: accuracy and RTs?

### Accuracy

Response time is an obvious outcome to model when it comes to decision tasks. The use of accuracy is more debatable, as the tasks were not specifically designed to be challenging. Traditionally, accuracy is mostly used to remove incorrect trials from RT modelling. We'll describe accuracy data to evaluate its relevance in this analysis. The distribution of the percentages of errors across the three tasks is displayed in @fig-distributions.

```{r distributions}
#| label: fig-distributions
#| echo: false
#| fig-cap: "Distribution of errors between groups in the three main tasks."
#| fig-width: 9
#| fig-height: 11

# --- Number of errors - association task --------------------------------------
p_errors_asso <-
  df_asso %>%
  select(subjectid, correct_association, aphantasia) %>% 
  group_by(subjectid, aphantasia) %>% 
  count(correct_association) %>% 
  filter(correct_association == 1) %>% 
  mutate(n = 100 - n) %>% 
  ggplot(aes(
    x = n, 
    color = aphantasia,
    fill = aphantasia
    )) +
  geom_bar(
    aes(y = after_stat(prop)),
    position = position_dodge(),
    width = .8,
    alpha = .5
    ) +
  scale_x_continuous(
    name = "Percentage of errors",
    breaks = breaks_pretty(n = 20)
    ) +
  scale_y_continuous(
    name = "Proportion of the group",
    breaks = breaks_pretty(n = 10)
    ) +
  coord_cartesian(
    xlim = c(0.5, 24),
    ylim = c(.01,.36)
    ) +
  labs(title = "Association task") +
  scale_color_okabeito(guide = NULL) +
  scale_fill_okabeito(name = "Aphantasia", labels = c("Yes", "No"))

# --- Number of errors - implicit task -----------------------------------------
p_errors_implcit <-
  df_implicit %>%
  select(subjectid, correct_implicit, aphantasia) %>% 
  group_by(subjectid, aphantasia) %>% 
  count(correct_implicit) %>% 
  filter(correct_implicit == 1) %>% 
  mutate(n = (64 - n)/64 * 100) %>% 
  ggplot(aes(
    x = n, 
    color = aphantasia,
    fill = aphantasia
    )) +
  geom_bar(
    aes(y = after_stat(prop)),
    position = position_dodge(),
    width = .6,
    alpha = .6
    ) +
  scale_x_continuous(
    name = "Percentage of errors",
    breaks = breaks_pretty(n = 20)
    ) +
  scale_y_continuous(
    name = "Proportion of the group",
    breaks = breaks_pretty(n = 10)
    ) +
  coord_cartesian(
    xlim = c(1, 40),
    ylim = c(.01,.28)
    ) +
  labs(title = "Implicit task") +
  scale_color_okabeito(guide = NULL) +
  scale_fill_okabeito(name = "Aphantasia", labels = c("Yes", "No"))

# --- Number of errors - explicit task -----------------------------------------
p_errors_explicit <-
  df_explicit %>%
  select(subjectid, correct_explicit, aphantasia) %>% 
  group_by(subjectid, aphantasia) %>% 
  count(correct_explicit) %>% 
  filter(correct_explicit == 1) %>% 
  mutate(n = (64 - n)/64 * 100) %>% 
  ggplot(aes(
    x = n, 
    color = aphantasia,
    fill = aphantasia
    )) +
  geom_bar(
    aes(y = after_stat(prop)),
    position = position_dodge(),
    width = .6,
    alpha = .6
    ) +
  scale_x_continuous(
    name = "Percentage of errors",
    breaks = breaks_pretty(n = 20)
    ) +
  scale_y_continuous(
    name = "Proportion of the group",
    breaks = breaks_pretty(n = 10)
    ) +
  coord_cartesian(
    xlim = c(1, 46),
    ylim = c(.01,.36)
    ) +
  labs(title = "Explicit task") +
  scale_color_okabeito(guide = NULL) +
  scale_fill_okabeito(name = "Aphantasia", labels = c("Yes", "No"))

# --- All distributions --------------------------------------------------------
ggarrange(
  p_errors_asso + rremove("xlab") + rremove("ylab"),
  p_errors_explicit + rremove("xlab") + rremove("ylab"),
  p_errors_implcit + rremove("xlab") + rremove("ylab"),
  ncol = 1,
  common.legend = TRUE,
  legend = "right"
  ) %>% 
  annotate_figure(
    left = text_grob("Proportion of the group", size = 20, rot = 90),
    bottom = text_grob("Percentage of errors", size = 20)
    )
```

We can see that the distributions are skewed yet very similar across groups and tasks: as such, we are going to use accuracy only to remove missed trials in the analyses of the RTs. Nevertheless, the main noticeable aspect of these plots are the obvious outliers in each of the tasks. This information is crucial as it could reflect a wrong understanding of the task, or random responses: in any case, participants that have high error rates would require a deletion of up to 47% of their trials, which could become a bias in the modelling of the overall data. As there appear to be a cut-off of the main distribution around 16% of errors in all tasks, this value will be chosen as threshold. **For each task separately, the results of participants with an error rate superior to 16% will be removed, prior to removing all the missed trials of the remaining participants for modelling RTs.**

### Response times

As a preprocessing, response times below 300ms and above 3000ms will be removed as they could represent false alarms, along with error trials. This amounts to 5.3% of trials in both tasks. The descriptive statistics of the response times for the remaining trials in both tasks are shown in @tbl-rt_stats.

```{r rt_stats}
#| echo: false
#| label: tbl-rt_stats
#| tbl-cap: "Descriptive statistics of all the response times in the explicit and implicit tasks."

# --- RT report tables ---

df_explicit_rt <- 
  df_explicit %>% 
  filter(rt_explicit > 300 & rt_explicit < 3000 & correct_explicit == 1)

df_implicit_rt <- 
  df_implicit %>% 
  filter(rt_implicit > 300 & rt_implicit < 3000 & correct_implicit == 1)

df_rt <- list(
  df_explicit_rt %>% rename("Explicit task RT" = rt_explicit), 
  df_implicit_rt %>% rename("Implicit task RT" = rt_implicit)
  ) %>% 
  imap(
    ~select(.x, contains("RT")) %>%
      report() %>% 
      as.data.frame() %>% 
      select(1:10)
    )

bind_rows(df_rt[[1]], df_rt[[2]]) %>% display
```

```{r}

# --- RT distribution per participant ---
df_explicit_rt %>% 
  ggplot(aes(x = rt_explicit, fill = subjectid, color = subjectid)) +
  geom_density(alpha = .07) +
  scale_x_continuous(name = "Response time", breaks = breaks_pretty()) +
  scale_y_continuous(name = "Density") +
  coord_cartesian(
    xlim = c(380, 2850)
  ) +
  scale_fill_viridis_d(guide = NULL) +
  scale_color_viridis_d(guide = NULL)

# --- Mean RT stats ---
df_explicit_rt %>% 
  group_by(subjectid) %>% 
  summarise(mean_rt = mean(rt_explicit)) %>% 
  select(mean_rt) %>% 
  # filter(mean_rt > 1377)
  report %>% as.data.frame

# --- Mean RT explicit histo ---
df_explicit_rt %>% 
  group_by(subjectid) %>% 
  summarise(mean_rt = mean(rt_explicit)) %>% 
  ggplot(aes(x = mean_rt)) +
  geom_histogram(
    fill = "aquamarine2", 
    color = "aquamarine4", 
    alpha = .3,
    bins = 70
    # adjust = .4
    ) +
  scale_y_continuous(breaks = breaks_pretty(10))

# --- Mean RT implicit histo ---
df_implicit_rt %>% 
  group_by(subjectid) %>% 
  summarise(mean_rt = mean(rt_implicit)) %>% 
  ggplot(aes(x = mean_rt)) +
  geom_histogram(
    fill = "coral", 
    color = "coral4", 
    alpha = .3,
    bins = 70
    # adjust = .4
    ) +
  scale_y_continuous(breaks = breaks_pretty(10))
```
















# Annexes

## Rotation task

Some analyses of the rotation task are summarised as visualizations in @fig-rotation.

```{r rotation}
#| label: fig-rotation
#| echo: false
#| fig-cap: "Analyses of the rotation task, including the distribution of errors between groups and correlations with the imagery variables."
#| fig-width: 11
#| fig-height: 7

# --- Annex: analysis of the rotation task -------------------------------------

# --- Number of errors - rotation task -----------------------------------------
p_rotation_errors <- 
  df_rotation %>%
  select(subjectid, correct_rotation, aphantasia) %>% 
  group_by(subjectid, aphantasia) %>% 
  count(correct_rotation) %>% 
  filter(correct_rotation == 1) %>% 
  mutate(n = 20 - n) %>% 
  ggplot(aes(
    x = n, 
    color = aphantasia,
    fill = aphantasia
    )) +
  geom_bar(
    aes(y = after_stat(prop)),
    position = position_dodge(),
    width = .8,
    alpha = .4
    ) +
  geom_density(aes(y = after_stat(density), color = NULL), alpha = .2) +
  scale_x_continuous(
    name = "Number of errors",
    breaks = breaks_pretty(n = 20)
    ) +
  scale_y_continuous(
    name = "Proportion of the group",
    breaks = breaks_pretty(n = 10)
    ) +
  coord_cartesian(
    xlim = c(0, 14),
    ylim = c(.01,.16)
    ) +
  labs(title = "Rotation task") +
  scale_color_viridis_d(guide = NULL) +
  scale_fill_viridis_d(name = "Aphantasia", labels = c("Yes", "No"), alpha = .6) +
  theme(legend.position = "top")

# --- Correlation between rotation correct and spatial imagery -----------------
p_rotation_cor_spa <- 
  df_rotation %>% 
  select(subjectid, correct_rotation, spatial_imagery) %>% 
  group_by(subjectid) %>% 
  summarise(
    correct_perc = sum(correct_rotation)/20,
    mean_s = mean(spatial_imagery)
  ) %>% 
  standardize(correct_perc) %>% 
  cor_test("mean_s", "correct_perc", bayesian = TRUE) %>% 
  plot +
  labs(x = "Spatial imagery", y = "Correct responses")

# --- Correlation between rotation correct and visual imagery ------------------
p_rotation_cor_vis <- 
  df_rotation %>% 
  select(subjectid, correct_rotation, visual_imagery) %>% 
  group_by(subjectid) %>% 
  summarise(
    correct_perc = sum(correct_rotation)/20,
    mean_v = mean(visual_imagery)
  ) %>% 
  standardize(correct_perc) %>% 
  cor_test("mean_v", "correct_perc", bayesian = TRUE) %>% 
  plot +
  labs(x = "Visual imagery", y = "Correct responses")

# --- Correlation between rotation correct and vviq ----------------------------
p_rotation_cor_vviq <-
  df_rotation %>% 
  select(subjectid, correct_rotation, vviq80) %>% 
  group_by(subjectid) %>% 
  summarise(
    correct_perc = sum(correct_rotation)/20,
    vviq = mean(vviq80)
  ) %>% 
  standardize(select = c("vviq", "correct_perc")) %>% 
  cor_test("vviq", "correct_perc", bayesian = TRUE) %>% 
  plot +
  labs(x = "VVIQ", y = "Correct responses")

ggarrange(
  p_rotation_errors, 
  p_rotation_cor_vis, 
  p_rotation_cor_vviq, 
  p_rotation_cor_spa + rremove("ylab")
  )
```





















