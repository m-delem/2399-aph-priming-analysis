---
title: "Sensory priming in aphantasia - Data analysis"
author: "MaÃ«l Delem"
format: html
editor_options: 
  chunk_output_type: console
toc: true
---

### Preliminary Set-up

<!-- ::: {.callout-tip collapse="true"} -->
#### Datasets and code availability

The folder containing this HTML file also has a "`data/`" folder, wherein can be found the main Excel file from which the datasets analysed here are sourced, i.e. "`aphantasia_priming_tidy_data.xlsx`". It has several sheets:

- `data_asso`/`_implicit`/`_explicit`/`_rotation`/`_questionnaires` are raw datasheets retrieved from old Excels and cleaned up

- `data_processed_explicit`/`_implicit` are the datasets of the two main tasks after being processed here and in their final state after [exploratory analysis](#sec-eda), and before the [inferential analyses conducted afterwards](#sec-inferential).

The code generating all the computations, figures, tables, etc. (only partially exposed here for clarity) can be found in the `aphantasia_priming_analysis.qmd` file, for which the best reading software are coding Integrated Development Environments (IDE) like [RStudio](https://posit.co/download/rstudio-desktop/) or [Visual Studio Code](https://code.visualstudio.com/). The file includes detailed commentaries along with the code to ease understanding, accessibility, and potential (welcome) criticism.
<!-- ::: -->

<!-- :::{.callout-note collapse="true"} -->
#### Software and setup

This analysis was conducted in R language on [RStudio](https://posit.co/download/rstudio-desktop/). This analysis report was written with [Quarto](https://quarto.org/). Just down below is the set-up code, including two essential steps: 

1. Installing the required packages for this data analysis

2. importing data into the dataframes used throughout. 

I left this (usually hidden) step here for reference of the tools used in a view of transparency for the interested reader.

```{r setup}
#| output: false
#| code-summary: "Setup code"

# --- Packages -----------------------------------------------------------------

# The package `librairian` will ease the package management with the "shelf" 
# function, which automatically: 
# 1) checks if a package is installed 
# 2) installs it if need be
# 3) loads the package like the "library()" function would.
if (!require(librarian)) install.packages(librarian)
library(librarian)

# now putting packages on our library's shelves:
shelf(
  rstatix,        # ggplot stat tools
  readxl,         # Excel files management
  openxlsx,       # Excel files management
  easystats,      # collection of data analysis packages
  tidymodels,     # collection of packages for a tidy modelling workflow
  bayesian,       # bayesian modelling with brms and tidymodels
  multilevelmod,  # multilevel modelling with lmer and tidymodels
  mclust,         # mixture clustering
  ggpubr,         # ggplot tools
  ggbeeswarm,     # ggplot tools
  viridis,        # ggplot colour-blind friendly palettes
  tidyverse       # the essentials
)

# --- Global cosmetic theme ---
theme_set(theme_bw(base_size = 14))

# --- Fixing a seed for reproducibility ---
set.seed(14051998)

# --- Importing data -----------------------------------------------------------

# Association task
df_asso <- read_excel("data/aphantasia_priming_tidy_data.xlsx", 
                     sheet = "data_asso")

# Implicit task
df_implicit <- read_excel("data/aphantasia_priming_tidy_data.xlsx", 
                     sheet = "data_implicit")

# Explicit task
df_explicit <- read_excel("data/aphantasia_priming_tidy_data.xlsx", 
                     sheet = "data_explicit")

# Rotation task
df_rotation <- read_excel("data/aphantasia_priming_tidy_data.xlsx", 
                     sheet = "data_rotation")

# Questionnaires
df_questionnaires <- 
  read_excel(
    "data/aphantasia_priming_tidy_data.xlsx",
    sheet = "data_questionnaires"
    ) %>% 
  # creating the a/phantasia groups
  mutate(
    aphantasia = ifelse(vviq80 < 32, "yes", "no"),
    aphantasia = fct_relevel(aphantasia, "yes", "no")
    )
```
<!-- ::: -->

# Exploratory Data Analysis {#sec-eda}

## Questionnaire data and imagery

### Correlations

The four questionnaire variables - VVIQ, OSIQ-Object and Spatial, and SUIS - are meant to be used as predictors (independent variables) for the behavioural outcomes of the experiment (dependent variables, RTs and potentially accuracy). Three of these - VVIQ, OSIQ-Object and SUIS - evaluate visual imagery: as such, in a view of parsimony, we are going to evaluate the correlation between these continuous predictors and judge if they should be merged/omitted. The results of the Bayesian partial correlations between the four variables are displayed in @fig-cor_matrix and @tbl-cor_stats. Partial correlations have been chosen here to account for the (theoretically huge) covariance between visual imagery variables. It will result in more conservative estimations of the correlations, and a better understanding of the relations between visual and spatial imagery measures.

```{r correlation}
#| code-summary: "Computing correlations"

# --- Bayesian partial correlations between questionnaire scores ---
cor_questionnaires <-
  df_questionnaires %>%
  select("vviq80", "suis60","osiq_o75", "osiq_s75") %>% 
  standardise %>% 
  correlation(
    bayesian = TRUE,
    partial = TRUE,
    partial_bayesian = TRUE,
    bayesian_test = "bf"
    )
```

```{r correlation_matrix}
#| label: fig-cor_matrix
#| echo: false
#| fig-cap: "Correlation matrix of the questionnaire variables. The stars indicate the amount of evidence in favour of a correlation, as assessed by the $BF_{10}$: No star = Anecdotal evidence, * = Weak evidence, ** = Moderate evidence, *** = Extreme evidence."

# --- Correlation matrix ---
cor_questionnaires %>%
  mutate(across(c(Parameter1, Parameter2),
    ~ case_when(
    .x == "vviq80" ~ "VVIQ",
    .x == "suis60" ~ "SUIS",
    .x == "osiq_o75" ~ "OSIQ-O",
    .x == "osiq_s75" ~ "OSIQ-S"))
    ) %>% 
  summary(digits = 2) %>% 
  plot(
    text = list(size = 5),
    labs = list(title = "")
    ) +
  scale_fill_viridis(
    option = "D",
    name = expression(rho),
    alpha = .6,
    direction = 1,
    limits = c(-1,1)
    ) +
  theme_bw() +
  theme(
    panel.grid = element_blank(),
    axis.text = element_text(size = 14)
    )
```

```{r correlation_table}
#| label: tbl-cor_stats
#| echo: false
#| tbl-cap: "Detailed correlation table of the questionnaire variables."

# --- Correlation table ---
cor_questionnaires %>%
  format %>% 
  mutate(across(c(Parameter1, Parameter2),
    ~ case_when(
    .x == "vviq80" ~ "VVIQ",
    .x == "suis60" ~ "SUIS",
    .x == "osiq_o75" ~ "OSIQ-O",
    .x == "osiq_s75" ~ "OSIQ-S"))
    ) %>% 
  rename(
    "Variable 1" = Parameter1,
    "Variable 2" = Parameter2,
    "$\\rho$" = rho,
    "$BF_{10}$" = BF
  ) %>% 
  knitr::kable()
```

As we can see, while the three visual imagery variables are highly correlated, the association between these visual and spatial imagery (OSIQ-S) is inconsistent: VVIQ and OSIQ-S are positively correlated although with anecdotal evidence, SUIS and OSIQ-S have a moderately evidenced positive correlation, while OSIQ-Object and OSIQ-Spatial are negatively correlated. We'll run a Principal Component Analysis to evaluate the possibility of a feature reduction of visual imagery as a single variable.

### Principal Component Analysis

```{r pca}
#| code-summary: "Computing PCA"

# --- Principal Component Analysis ---
pca <- 
  principal_components(
    df_questionnaires[,4:7],
    n = "max",
    sort = TRUE,
    standardize = TRUE
    ) 
```

```{r loadings}
#| label: fig-loadings
#| echo: false
#| fig-cap: "Loadings of each variable on the three components extracted by a PCA."

# --- Loadings ---
pca %>% plot + 
  scale_y_discrete(labels = c("OSIQ-S", "OSIQ-O", "VVIQ", "SUIS")) +
  scale_fill_viridis(alpha = .6) +
  labs(title = NULL) +
  theme(text = element_text(size = 14))
```

```{r eigenvalues}
#| label: tbl-eigenvalues
#| echo: false
#| tbl-cap: "Eigenvalues and variance explained by the three components extracted by a PCA."

# --- Eigenvalues and variance ---
pca %>% 
  summary %>% 
  rename(
    "Component 1" = PC1,
    "Component 2" = PC2,
    "Component 3" = PC3,
  ) %>%
  format(digits = 2) %>% 
  display
```

As expected, the visual imagery variables are grouped in a single component ("PC1" in @fig-loadings or "Component 1" in @tbl-eigenvalues) with an Eigenvalue of 2.84, therefore accounting for 71% of the total variance of the data. The second component (PC2 / Component 2) has an Eigenvalue of .97, accounts for 24% of the total variance, and is mostly loaded negatively on the OSIQ-S: this brings the total explained proportion of variance to 95%. Traditionally, the threshold used for selecting a principal component is an Eigenvalue of 1. Nevertheless, given the Eigenvalue of .97 and the properties of this component, i.e. singling out the specificity of the spatial scale, this component will be kept for analysis.

Standardized predicted values for each component will be computed and added to the data, renamed ***Visual Imagery*** (PC1, mostly VVIQ + SUIS + OSIQ-O with an influence of OSIQ-S) and ***Spatial Imagery*** (PC2, mostly OSIQ-S, with an influence of SUIS). In order to align the Spatial Imagery variable with the OSIQ-Spatial, the variable will be reversed (they are correlated negatively as it is, as shown by the -.96 loading on PC2).

```{r pca_components}
#| code-summary: "Adding the predicted PCA components to the data"

pca_components <- pca %>% predict

df_questionnaires <- 
  bind_cols(df_questionnaires, pca_components[,1:2]) %>% 
  mutate(
    PC1 = standardize(PC1),
    PC2 = -standardize(PC2)
    ) %>% 
  rename(
    "visual_imagery" = PC1,
    "spatial_imagery" = PC2
    )

rm(pca, pca_components)
```

### VVIQ, visual and spatial imagery

Now we can see that the main visual imagery variables, namely the (conventional) VVIQ and the *Visual Imagery* component created through PCA are completely decorrelated from the *Spatial Imagery* component, as shown in @fig-spatial_corr.

```{r spatial_correlations}
#| label: fig-spatial_corr
#| echo: false
#| fig-cap: "Correlation between the main visual imagery variables and the spatial imagery one."
#| fig-width: 9
#| fig-height: 4.5

# --- correlation between visual and spatial ---
p_cor_spatial_vis <- 
  df_questionnaires %>% 
  mutate(
    visual_imagery = rescale(visual_imagery),
    spatial_imagery = rescale(spatial_imagery),
    aphantasia = fct_relevel(aphantasia, "yes", "no")
    ) %>%
  ggplot(aes(x = visual_imagery, y = spatial_imagery, color = aphantasia)) +
  geom_point() +
  scale_color_okabeito(name = "Aphantasia", labels = c("Yes", "No")) +
  geom_smooth(
    aes(x = visual_imagery, y = spatial_imagery), 
    color = "black", 
    method = "lm", 
    stat = "smooth") +
  stat_cor(
    aes(x = visual_imagery, 
        y = spatial_imagery), 
    inherit.aes = FALSE, 
    cor.coef.name = "r", 
    label.x.npc = .5,
    label.y.npc = .7) +
  labs(x = "Visual Imagery",
       y = "Spatial Imagery")

# --- correlation between vviq and spatial ---
p_cor_spatial_vviq <- 
  df_questionnaires %>% 
  mutate(
    vviq80 = rescale(vviq80),
    spatial_imagery = rescale(spatial_imagery)
    ) %>%
  ggplot(aes(x = vviq80, y = spatial_imagery, color = aphantasia)) +
  geom_point() +
  scale_color_okabeito(name = "Aphantasia", labels = c("Yes", "No")) +
  geom_smooth(
    aes(x = vviq80, y = spatial_imagery), 
    color = "black", 
    method = "lm", 
    stat = "smooth") +
  stat_cor(
    aes(x = vviq80, 
        y = spatial_imagery), 
    inherit.aes = FALSE, 
    cor.coef.name = "r", 
    label.x.npc = .5,
    label.y.npc = .7) +
  labs(x = "VVIQ",
       y = "Spatial Imagery")

p_spatial_correlations <- 
  ggarrange(
  p_cor_spatial_vis,
  p_cor_spatial_vviq + rremove("ylab"),
  common.legend = TRUE,
  legend = "bottom"
  )

rm(p_cor_spatial_vis, p_cor_spatial_vviq)
p_spatial_correlations
```

The consequence of this analysis is that from this point onwards two options are available to model the data:

1. Using **Aphantasia (i.e. *****Group*****) as a categorical variable** by binning the participants in two categories based on the VVIQ (cut-off at 32, Aphantasics/Phantasics).

2. Using **Visual Imagery as a continuous variable.**

In the main inferential analyses conducted down below, the first option has been selected for its ease of interpretation (and closeness to the results that would be obtained with the continuous variable anyway). Nevertheless, the two continuous variables of visual and spatial imagery defined here will be explored later in further data exploration.

```{r df_updates}
#| echo: false

# updating all the dataframes with the imagery variables
dfs <- 
  list(
    association_task = df_asso, 
    implicit_task = df_implicit, 
    explicit_task = df_explicit, 
    rotation_task = df_rotation
    ) %>%
  # adding the vviq and group column to every dataframe
  imap(~left_join(
    .x, 
    df_questionnaires %>% 
      select(
        # column to match with the correct participants
        subjectid, 
        # new variables to add
        age,
        sexe,
        vviq80, 
        visual_imagery, 
        spatial_imagery,
        aphantasia), by = "subjectid") %>% 
      rename("sex" = sexe) %>% 
      # reordering the final dfs
      select(
        subjectid, 
        age, sex, aphantasia,
        vviq80, visual_imagery, spatial_imagery,
        everything())
    )

df_asso     <- dfs$association_task
df_implicit <- dfs$implicit_task
df_explicit <- dfs$explicit_task
df_rotation <- dfs$rotation_task
rm(dfs)
```

## Outcomes: accuracy and RTs?

### Accuracy

While response time is an obvious outcome to model when it comes to decision tasks, the use of accuracy is more debatable, as the tasks were not specifically designed to be challenging. Traditionally, accuracy is mostly used to remove incorrect trials from RT modelling. We'll describe accuracy data to evaluate its relevance in this analysis. The distribution of the percentages of errors across the three tasks is displayed in @fig-tasks_errors.

```{r tasks_errors}
#| label: fig-tasks_errors
#| echo: false
#| fig-cap: "Distribution of errors between groups in the three main tasks."
#| fig-width: 9
#| fig-height: 11

# --- Number of errors - association task --------------------------------------
p_errors_asso <-
  df_asso %>%
  select(subjectid, correct_association, aphantasia) %>% 
  group_by(subjectid, aphantasia) %>% 
  count(correct_association) %>% 
  filter(correct_association == 1) %>% 
  mutate(n = 100 - n) %>% 
  ggplot(aes(
    x = n, 
    color = aphantasia,
    fill = aphantasia
    )) +
  geom_bar(
    aes(y = after_stat(prop)),
    position = position_dodge(),
    width = .8,
    alpha = .5
    ) +
  scale_x_continuous(
    name = "Percentage of errors",
    breaks = breaks_pretty(n = 20)
    ) +
  scale_y_continuous(
    name = "Proportion of the group",
    breaks = breaks_pretty(n = 10)
    ) +
  coord_cartesian(
    xlim = c(0.5, 24),
    ylim = c(.01,.36)
    ) +
  labs(title = "Association task") +
  scale_color_okabeito(guide = NULL) +
  scale_fill_okabeito(name = "Aphantasia", labels = c("Yes", "No"))

# --- Number of errors - implicit task -----------------------------------------
p_errors_implcit <-
  df_implicit %>%
  select(subjectid, correct_implicit, aphantasia) %>% 
  group_by(subjectid, aphantasia) %>% 
  count(correct_implicit) %>% 
  filter(correct_implicit == 1) %>% 
  mutate(n = (64 - n)/64 * 100) %>% 
  ggplot(aes(
    x = n, 
    color = aphantasia,
    fill = aphantasia
    )) +
  geom_bar(
    aes(y = after_stat(prop)),
    position = position_dodge(),
    width = .6,
    alpha = .6
    ) +
  scale_x_continuous(
    name = "Percentage of errors",
    breaks = breaks_pretty(n = 20)
    ) +
  scale_y_continuous(
    name = "Proportion of the group",
    breaks = breaks_pretty(n = 10)
    ) +
  coord_cartesian(
    xlim = c(1, 40),
    ylim = c(.01,.28)
    ) +
  labs(title = "Implicit task") +
  scale_color_okabeito(guide = NULL) +
  scale_fill_okabeito(name = "Aphantasia", labels = c("Yes", "No"))

# --- Number of errors - explicit task -----------------------------------------
p_errors_explicit <-
  df_explicit %>%
  select(subjectid, correct_explicit, aphantasia) %>% 
  group_by(subjectid, aphantasia) %>% 
  count(correct_explicit) %>% 
  filter(correct_explicit == 1) %>% 
  mutate(n = (64 - n)/64 * 100) %>% 
  ggplot(aes(
    x = n, 
    color = aphantasia,
    fill = aphantasia
    )) +
  geom_bar(
    aes(y = after_stat(prop)),
    position = position_dodge(),
    width = .6,
    alpha = .6
    ) +
  scale_x_continuous(
    name = "Percentage of errors",
    breaks = breaks_pretty(n = 20)
    ) +
  scale_y_continuous(
    name = "Proportion of the group",
    breaks = breaks_pretty(n = 10)
    ) +
  coord_cartesian(
    xlim = c(1, 46),
    ylim = c(.01,.36)
    ) +
  labs(title = "Explicit task") +
  scale_color_okabeito(guide = NULL) +
  scale_fill_okabeito(name = "Aphantasia", labels = c("Yes", "No"))

# --- All distributions --------------------------------------------------------
p_tasks_error_perc <- 
  ggarrange(
  p_errors_asso + rremove("xlab") + rremove("ylab"),
  p_errors_explicit + rremove("xlab") + rremove("ylab"),
  p_errors_implcit + rremove("xlab") + rremove("ylab"),
  ncol = 1,
  common.legend = TRUE,
  legend = "right"
  ) %>% 
  annotate_figure(
    left = text_grob("Proportion of the group", size = 20, rot = 90),
    bottom = text_grob("Percentage of errors", size = 20)
    )

rm(p_errors_asso, p_errors_explicit, p_errors_implcit)
p_tasks_error_perc
```

We can see that the distributions are skewed yet very similar across groups and tasks: as such, we are going to use accuracy only to remove missed trials in the analyses of the RTs. Nonetheless, the main noticeable aspect of these plots are the obvious outliers in each of the tasks. This information is crucial as it could reflect a wrong understanding of the task, or random responses: in any case, participants that have high error rates would require a deletion of up to 47% of their trials, which could become a bias in the modelling of the overall data. As there appear to be a cut-off of the main distribution around 16% of errors in all tasks, this value will be chosen as threshold. **For each task separately, the results of participants with an error rate superior to 16% will be removed ***(i.e., nine participants in the explicit task and four in the implicit task)***, prior to removing all the missed trials of the remaining participants for modelling RTs.**

```{r acc_outliers}
#| code-summary: "Removing incorrect trials and task-wise accuracy outliers"
#| output: false

# --- Accuracy outliers analysis ---
list(df_explicit, df_implicit) %>%
  imap(
    ~.x %>%
      select(subjectid, starts_with("correct"), aphantasia) %>%
      group_by(subjectid) %>%
      count(pick(2)) %>%
      filter(pick(1) == 1) %>%
      ungroup() %>%
      mutate(
        n_tot = max(n),
        prop = (n_tot - n) / n_tot * 100  # analysing the error rate per subject
      ) %>%
      arrange(desc(prop)) %>%
      select(1, 5)
    )
# 9 accuracy outliers in the explicit task, 4 in the implicit one

# --- Removing incorrect trials and task-wise accuracy outliers ---
df_explicit_rt <-
  df_explicit %>%
  # filtering out...
  filter(
    # incorrect trials
    correct_explicit == 1 &
    # participants identified with with high error rates
    !(subjectid %in% c(
      "ldossantos", 
      "aknezevic", 
      "agayou", 
      "bluciani", 
      "lbrunie", 
      "cmarcenytheault", 
      "llhermitte", 
      "jnaruse", 
      "fc"))
    ) %>% 
  # removing irrelevant variables
  select(-c(sex, vviq80, orientation, response, correct_explicit))

df_implicit_rt <- 
  df_implicit %>% 
  filter(
    correct_implicit == 1 &
    !(subjectid %in% c(
      "bdispaux", 
      "eleveque", 
      "aleclaire", 
      "dchimenton"))
      ) %>% 
  select(-c(sex, vviq80, orientation, response, correct_implicit))
```

### Response times

As a preprocessing, response times below 300ms and above 3000ms will be removed as they could represent false alarms. The removal of accuracy outliers, incorrect trials and extreme RTs amounted to 5.3% of trials in both tasks. There could also be outliers with overall abnormally fast or slow RTs. This analysis will be conducted on mean RTs, the distribution of which is displayed in @fig-rt_means, along with the overall RT statistics in @tbl-rt_means. 

```{r first_rt_outliers}
#| code-summary: "Removing extreme RTs"

# --- First broad RT outlier trials removal ---
df_explicit_rt <- 
  df_explicit_rt %>% 
  # filtering out extreme RTs
  filter(rt_explicit > 300 & rt_explicit < 3000)

df_implicit_rt <- 
  df_implicit %>% 
  filter(rt_implicit > 300 & rt_implicit < 3000)
```

```{r rt_means_plot}
#| echo: false
#| label: fig-rt_means
#| fig-cap: "Distribution of the mean RTs of participants in the explicit and implicit tasks (very high RT means have been cut for better readability)."
#| fig-width: 9
#| fig-height: 4

# --- RT outliers visual analysis ---
p_rt_explicit <-
  df_explicit_rt %>% 
  group_by(subjectid) %>% 
  summarise(mean = mean(rt_explicit)) %>% 
  ggplot(aes(x = mean)) +
  geom_histogram(
    fill = "aquamarine2", 
    color = "aquamarine4", 
    alpha = .3,
    bins = 70
    # adjust = .4
    ) +
  labs(x = "Explicit task mean RT", y = "Number of participants") +
  scale_y_continuous(breaks = seq(0, 13, by = 1))

p_rt_implicit <-
  df_implicit_rt %>%
  group_by(subjectid) %>% 
  summarise(mean = mean(rt_implicit)) %>% 
  ggplot(aes(x = mean)) +
  geom_histogram(
    fill = "coral2", 
    color = "coral4", 
    alpha = .3,
    bins = 70
    # adjust = .4
    ) +
  labs(x = "Implicit task mean RT", y = NULL) +
  scale_y_continuous(breaks = seq(0, 9, by = 1))

p_tasks_rt_means <- ggarrange(p_rt_explicit, p_rt_implicit)
rm(p_rt_explicit, p_rt_implicit)
p_tasks_rt_means
```

```{r rt_means_table}
#| echo: false
#| label: tbl-rt_means
#| tbl-cap: "Descriptive statistics of the average RTs across the sample in both tasks."

df_rt <-
  list(
  df_explicit_rt %>% rename("Explicit task mean RTs" = rt_explicit), 
  df_implicit_rt %>% rename("Implicit task mean RTs" = rt_implicit)
  ) %>% 
  imap(
    ~select(.x, contains("RT")) %>%
      report() %>% 
      as.data.frame() %>% 
      select(1, 2, 5:10)
    )

df_rt <- bind_rows(df_rt[[1]], df_rt[[2]])
df_rt %>% display
```

For a more precise analysis of mean RTs, we are going to use an outlier detection method based on the Median Absolute Deviation (MAD). Common thresholds used for outlier detection in Gaussian distributions with MADs are $median \ \pm \ 3 \cdot MAD$ (Hampel filter; see Enderlein, 1987). However, the low boundary of this interval would be aberrant in our case of a skewed distribution, as all the participants with fast RT means stay above the $median \ - \ 1.5 \cdot MAD$. As for the high threshold, the choice the $median \ + \ 3 \cdot MAD$ would set a highly conservative maximum (e.g. 1361ms for the explicit task) and bring the total number of removed trials over 13%. Therefore, after careful examination of the ranges, and in order to keep as many trials as possible, we chose to set the upper threshold at $median \ + \ 5 \cdot MAD$ (i.e. 1797ms for the explicit task, and 1386ms for the implicit task), resulting in an overall deletion of 7.9% of trials in the explicit task and 8.9% of trials in the implicit one in this whole data preprocessing. The resulting distributions of RTs for each participant are represented in @fig-rt_per_participant.

```{r second_rt_outliers}
#| code-summary: "Removing individual outlier trials"
#| output: false

# --- second precise RT outlier trials removal ---
df_explicit_rt <-
  df_explicit_rt %>% 
  filter(rt_explicit < 1797)

df_implicit_rt <-
  df_implicit_rt %>% 
  filter(rt_implicit < 1386)

# --- checking individual participant stats for lone outliers ---
df_explicit_rt %>%
  group_by(subjectid) %>%
  summarise(
    mean = mean(rt_explicit),
    mad = mad(rt_explicit),
    min = min(rt_explicit),
    max = max(rt_explicit),
    obs = length(rt_explicit)
  )

df_implicit_rt %>%
  group_by(subjectid) %>%
  summarise(
    mean = mean(rt_implicit),
    mad = mad(rt_implicit),
    min = min(rt_implicit),
    max = max(rt_implicit),
    obs = length(rt_implicit)
  )

# --- removing the last outlier (unusually high mean RT) ---
df_explicit_rt <- df_explicit_rt %>% filter(subjectid != "dchimenton")
```

```{r rt_per_participant}
#| echo: false
#| label: fig-rt_per_participant
#| fig-cap: "Resulting distribution of RTs in both tasks for each participant. Each colored line represents a single participant."
#| fig-width: 11
#| fig-height: 4

# --- RT distributions per participant ---
p_rt_subject_explicit <- 
  df_explicit_rt %>% 
  ggplot(aes(x = rt_explicit, fill = subjectid, color = subjectid)) +
  geom_density(alpha = .07) +
  scale_x_continuous(name = "Explicit task RT", breaks = breaks_pretty()) +
  scale_y_continuous(name = "Density") +
  coord_cartesian(
    xlim = c(380, 1700),
    ylim = c(0.0005, .01)
  ) +
  scale_fill_viridis_d(guide = NULL) +
  scale_color_viridis_d(guide = NULL)

p_rt_subject_implicit <-
  df_implicit_rt %>% 
  ggplot(aes(x = rt_implicit, fill = subjectid, color = subjectid)) +
  geom_density(alpha = .07) +
  scale_x_continuous(name = "Implicit task RT", breaks = breaks_pretty()) +
  scale_y_continuous(name = NULL) +
  theme(axis.text.y = element_blank()) +
  coord_cartesian(
    xlim = c(350, 1320),
    ylim = c(0.0005, .01)
  ) +
  scale_fill_viridis_d(guide = NULL) +
  scale_color_viridis_d(guide = NULL)

p_tasks_rt_per_subject <-
  ggarrange(p_rt_subject_explicit, p_rt_subject_implicit)
rm(p_rt_subject_explicit, p_rt_subject_implicit)
p_tasks_rt_per_subject
```

# Inferential Analyses {#sec-inferential}

## Model description (Multilevel modelling)

### Predictors and outcome

Our analyses aim to evaluate the predictive abilities of several variables on one outcome, the **Response times** of the participants in the tasks. Our potential predictors are:

- **Group** membership, with two levels: aphantasia/phantasia

- **Congruence** conditions, with two levels: congruent and incongruent

- **Color** conditions, with two levels: colored and uncolored.

Sub-levels of the responses ("random effects") can also be accounted for:

- the dependency between response times for **each participant** (also referred to as *subjects*) caused by repeated measures

- the varying effects of **Congruence for each participant**

- the varying effects of **Color for each participant**.

This structure will be modeled using Multilevel Models (also called hierarchical or mixed models), allowing us to add the sub-levels of the hierarchy within participant measures we described above in the model. **RT data will be transformed using a Box-Cox transformation** to bring the distributions closer to normality and improve the quality of the models.

For a subject $i$ with a given *Group*/visual imagery, in the *Congruence* condition $j$ and the *Color* condition $k$, The maximal model of the resulting response time $RT_{ijk}$ including all the predictors can be specified as such:

$$
\begin{aligned}
RT_{ijk} = \alpha + \alpha_{subject[i]} + \beta_{1} \cdot \ Group_{i} \times (\beta_{2} + \beta_{2_{subject[i]}}) \cdot Congruence_{j} \times (\beta_{3} + \beta_{3_{subject[i]}}) \cdot Color_{k}
\end{aligned}
$$
Where $\alpha$ is the global intercept, $\alpha_{subject[i]}$ is a random intercept by subject accounting for the inherent randomness tied to participants, and $\beta_{1/2/3}$ are the parameters representing the effect of each predictor. The "$\times$" signs represent the potential interactions along with fixed effects. Additionally, as one might expect the effect of the Congruence or Color conditions to have important variations between subjects (tied to cognitive processes and strategies), a slope $\beta_{2/3_{subject[i]}}$ by subject can be added to the Congruence or Color parameters to account for this variance.

### Potential models

**RT data will be standardized before modelling**, therefore the standardized coefficients reported will scale on *standard deviations of the RT variable*. This allows to interpret these parameters (regression coefficients) roughly with the same guidelines as usual indices, e.g., Cohen's *d*. Several models will be fitted in turn. we are not going to fit reduced models that exclude some main effects, as we would like to model all of them in any case to produce inferences (as opposed to raw predictions of future data). We'll specify the following: 

1. The minimal model, accounting only for the random effect of subjects, will serve as a comparison baseline: 

$$
\begin{aligned}
RT_{i} = \alpha + \alpha_{subject[i]}
\end{aligned}
$$

2. A model accounting for the fixed effects only:

$$
\begin{aligned}
RT_{ijk} = \alpha + \alpha_{subject[i]} + \beta_{1} \cdot \ Group_{i} + \beta_{2} \cdot Congruence_{j} + \beta_{3} \cdot Color_{k}
\end{aligned}
$$

3. A model with all interactions:

$$
\begin{aligned}
RT_{ijk} = \alpha + \alpha_{subject[i]} + \beta_{1} \cdot \ Group_{i} \times \beta_{2} \cdot Congruence_{j} \times \beta_{3} \cdot Color_{k}
\end{aligned}
$$

4. A model with a slope by subject on Congruence:

$$
\begin{aligned}
RT_{ijk} = \alpha + \alpha_{subject[i]} + \beta_{1} \cdot \ Group_{i} \times (\beta_{2} + \beta_{2_{subject[i]}}) \cdot Congruence_{j} \times \beta_{3} \cdot Color_{k}
\end{aligned}
$$

5. A model with a slope by subject on Color:

$$
\begin{aligned}
RT_{ijk} = \alpha + \alpha_{subject[i]} + \beta_{1} \cdot \ Group_{i} \times \beta_{2} \cdot Congruence_{j} \times (\beta_{3} + \beta_{3_{subject[i]}})  \cdot Color_{k}
\end{aligned}
$$

6. The maximal model:

$$
\begin{aligned}
RT_{ijk} = \alpha + \alpha_{subject[i]} + \beta_{1} \cdot \ Group_{i} \times (\beta_{2} + \beta_{2_{subject[i]}}) \cdot Congruence_{j} \times (\beta_{3} + \beta_{3_{subject[i]}})  \cdot Color_{k}
\end{aligned}
$$

The significant parameters will thereafter be analysed with **marginal contrasts analyses** (robust model-based analogues of "post-hoc" statistical tests) to evaluate the differences between factor levels.

## Fitting the models

```{r model_recipes_workflows_and_engines}
#| echo: false

# --- Setup ---

# --- preprocessing recipe for explicit data ---
recipe_explicit <- 
  df_explicit_rt %>%
  recipe %>%
  update_role(
    rt_explicit, 
    new_role = "outcome"
    ) %>%
  update_role(
    subjectid, age,
    aphantasia, visual_imagery, spatial_imagery,
    color, congruence,
    new_role = "predictor"
    ) %>%
  add_role(
    subjectid, 
    new_role = "group"
    ) %>%
  step_BoxCox(rt_explicit) %>% 
  step_normalize(rt_explicit, age)

# --- preprocessing recipe for implicit data ---
recipe_implicit <- 
  df_implicit_rt %>%
  recipe %>%
  update_role(
    rt_implicit, 
    new_role = "outcome"
    ) %>%
  update_role(
    subjectid, age,
    aphantasia, visual_imagery, spatial_imagery,
    color, congruence,
    new_role = "predictor"
    ) %>%
  add_role(
    subjectid,
    new_role = "group"
    ) %>%
  step_BoxCox(rt_implicit) %>% 
  step_normalize(rt_implicit, age) 

# --- workflows ---
workflow_explicit <- workflow() %>% add_recipe(recipe_explicit)
workflow_implicit <- workflow() %>% add_recipe(recipe_implicit)

# --- type of bayesian models to be fitted ---
# mod_0_bayesian <-
#   bayesian (
#     family = skew_normal()
#   ) %>%
#   set_engine("brms") %>% 
#   set_mode("regression")

# --- mixed models to be fitted ---
mod_0_lmer <-
  linear_reg() %>% 
  set_engine("lmer")
```

```{r model_specifications}
#| echo: false

# --- Specifying all models ---

# --- Explicit task ---

# model 1: intercepts only
mod_explicit_1 <-
  workflow_explicit %>% add_model(
    mod_0_lmer,
    formula = rt_explicit ~ (1|subjectid)
    )

# model 2: fixed effects
mod_explicit_2 <-
  workflow_explicit %>% add_model(
    mod_0_lmer,
    formula = rt_explicit ~ aphantasia + congruence + color + (1|subjectid)
  )

# model 3: interactions
mod_explicit_3 <- 
  workflow_explicit %>% add_model(
    mod_0_lmer,
    formula = rt_explicit ~ aphantasia * congruence * color + (1|subjectid)
  )

# model 4: slope by subject on congruence
mod_explicit_4 <-
  workflow_explicit %>% add_model(
    mod_0_lmer,
    formula = rt_explicit ~ aphantasia * congruence * color + (1 + congruence|subjectid)
  )

# model 5: slope by subject on color
mod_explicit_5 <-
  workflow_explicit %>% add_model(
    mod_0_lmer,
    formula = rt_explicit ~ aphantasia * congruence * color + (1 + color|subjectid)
  )

# model 6: maximal model
mod_explicit_6 <-
  workflow_explicit %>% add_model(
    mod_0_lmer,
    formula = rt_explicit ~ aphantasia * congruence * color + 
      (1 + congruence|subjectid) + (1 + color|subjectid)
  )

# --- Implicit task ---

# model 1: intercepts only
mod_implicit_1 <-
  workflow_implicit %>% add_model(
    mod_0_lmer,
    formula = rt_implicit ~ (1|subjectid)
    )

# model 2: group effect
mod_implicit_2 <-
  workflow_implicit %>% add_model(
    mod_0_lmer,
    formula = rt_implicit ~ aphantasia + congruence + color + (1|subjectid)
  )

# model 3: congruence effect
mod_implicit_3 <- 
  workflow_implicit %>% add_model(
    mod_0_lmer,
    formula = rt_implicit ~ aphantasia * congruence * color + (1|subjectid)
  )

# model 4: color effect
mod_implicit_4 <-
  workflow_implicit %>% add_model(
    mod_0_lmer,
    formula = rt_implicit ~ aphantasia * congruence * color + (1 + congruence|subjectid)
  )

# model 5: slope by subject on color
mod_implicit_5 <-
  workflow_implicit %>% add_model(
    mod_0_lmer,
    formula = rt_implicit ~ aphantasia * congruence * color + (1 + color|subjectid)
  )

# model 6: maximal model
mod_implicit_6 <-
  workflow_implicit %>% add_model(
    mod_0_lmer,
    formula = rt_implicit ~ aphantasia * congruence * color + 
      (1 + congruence|subjectid) + (1 + color|subjectid)
  )
```

```{r model_fitting}
#| echo: false

# --- Fitting all models ---

# --- Explicit task ---
fit_explicit_mods <-
  list(
    mod_explicit_1 = mod_explicit_1, 
    mod_explicit_2 = mod_explicit_2, 
    mod_explicit_3 = mod_explicit_3,
    mod_explicit_4 = mod_explicit_4,
    mod_explicit_5 = mod_explicit_5#,
    # mod_explicit_6 = mod_explicit_6
    ) %>% 
  imap(~ .x %>% fit(data = df_explicit_rt) %>% extract_fit_engine())

# --- Implicit task ---
fit_implicit_mods <-
  list(
    mod_implicit_1 = mod_implicit_1,
    mod_implicit_2 = mod_implicit_2,
    mod_implicit_3 = mod_implicit_3,
    mod_implicit_4 = mod_implicit_4,
    mod_implicit_5 = mod_implicit_5#,
    # mod_implicit_6 = mod_implicit_6
    ) %>%
  imap(~ .x %>% fit(data = df_implicit_rt) %>% extract_fit_engine())

# nested list of all the lists of models ----
all_models_fitted <-
  list(
    explicit_mods = fit_explicit_mods,
    implicit_mods = fit_implicit_mods
    )
```

All of these models have been fitted for both tasks and their predictive performances compared using the AIC, AICc (Akaike corrected Information Criterion) and BIC (Bayesian Information Criterion). The maximal model did not converge, so only the first five models were evaluated. The results of these analyses are displayed in @tbl-model_perfs.

```{r model_performances}
#| echo: false
#| label: tbl-model_perfs
#| tbl-cap: "Performances of the fitted models for both tasks."
#| tbl-subcap: 
#|   - "Explicit task models."
#|   - "Implicit task models."
#| layout-ncol: 1

# --- Performance of the models ---
all_models_performances <- 
  all_models_fitted %>% 
  imap(
    ~ .x %>% 
      compare_performance(metrics = c("AIC", "AICc", "BIC")) %>% 
      select(-Model) %>%
      display
    )

all_models_performances[["explicit_mods"]]

all_models_performances[["implicit_mods"]]
```

The fourth model including a slope by subject on Congruence is the most supported for the **explicit task**, while the third model including only an intercept by subject has the best performance for the **implicit task**. The parameters of these two models will be analysed in the following.

```{r model_parameters}
#| echo: false

# --- Parameter estimations ---
all_models_parameters <-
  all_models_fitted %>% 
  imap(
    ~ .x %>%
      imap(
        ~ .x %>% 
          model_parameters(effects = "fixed") %>%
          display
        )
    )
```

## Explicit task results

```{r model_explicit_4_contrasts}
#| echo: false

# model 4 contrasts between aphantasia and congruence levels
c_4_gcn <-
  all_models_fitted[[1]][[4]] %>% 
  estimate_contrasts(contrast = c("aphantasia", "congruence")) %>% 
  mutate(across(where(is.numeric), ~ round(.x, digits = 2)))

# model 4 contrasts between color levels
c_4_col <-
  all_models_fitted[[1]][[4]] %>% 
  estimate_contrasts(contrast = c("color")) %>% 
  mutate(across(where(is.numeric), ~ round(.x, digits = 2)))
```

The parameters of the best model for the explicit task are displayed in @tbl-model_explicit_4_params. The significant parameters in the explicit task are the Color and the interaction between the Group and the Congruence conditions. The **main effect of Color** indicate that participants responded quicker in the colored condition (Marginal contrast = `r c_4_col[1,3]`, CI = $[`r c_4_col[1,4]` ; `r c_4_col[1,5]`]$, SE = `r c_4_col[1,6]`, $p < .001$), although this effect has no interaction with the other variables. The **interaction between Group and Congruence** reveals that non-aphantasics responded slower in the uncongruent condition, as this contrast is the only significant one in this interaction (Marginal contrast = `r c_4_gcn[1,3]`, CI = $[`r c_4_gcn[1,4]` ; `r c_4_gcn[1,5]`]$, SE = `r c_4_gcn[1,6]`, $p < .001$). These effects are illustrated in @fig-model_explicit_4_plots. Both estimates are in the $[0.1 ; 0.2]$ range, which denotes a *very small* effect size according to most standardized differences interpretation guidelines (e.g. Cohen, 1988; Gignac & Szodorai, 2016; Lovakov & Agadullina, 2021).

```{r model_explicit_4_params}
#| echo: false
#| label: tbl-model_explicit_4_params
#| tbl-cap: "Parameters of the optimal model for the explicit task including a random intercept and slope by subject on Congruence."

all_models_parameters[["explicit_mods"]][["mod_explicit_4"]]
```

```{r model_explicit_4_plots}
#| echo: false
#| label: fig-model_explicit_4_plots
#| fig-cap: "Visualization of the predictions of the optimal model for the explicit task. The bottom plots are 'zoomed' versions of the top ones on shorter (standard) RT ranges for clearer views of the model. The horizontal colored lines in the 'violins' (colored shapes outlining the distribution of responses) represent quantiles at 25, 50 and 75%. The black dots indicate marginal means predicted by the model whereas the black bars represent the credible intervals of these estimations. **Left:** The *Congruence* plots represent the estimates of the model at each Congruence condition and Group, highlighting the significant interaction between the two variables. **Right**: The *Color* plots represent the estimates at each Color condition and Group, highlighting the main effect of Color and non-significance of the interaction with the Group factor."
#| fig-width: 14
#| fig-height: 10

# setting dodge width for all the geoms
dw <- .75
# stat text size
st <- 7
# legend and axis text size
txt <- 22
  
# ---- Model Explicit 4 Group and Congruence plots ----

# model 4 marginal means predictions
preds_mod_4_g_cng <- 
  all_models_fitted[[1]][[4]] %>% 
  estimate_means(at = c("aphantasia", "congruence"))

# stats for the group congruence interaction
stats_mod_4_g_cng_full <- 
  df_explicit_rt %>% 
  standardize(rt_explicit) %>% 
  group_by(aphantasia) %>% 
  pairwise_wilcox_test(rt_explicit ~ congruence) %>% 
  add_xy_position(x = "congruence", group = "aphantasia", dodge = dw) %>% 
  mutate(y.position = 3.1) %>% 
  filter(aphantasia == "no")

stats_mod_4_g_cng_zoom <- 
  df_explicit_rt %>% 
  standardize(rt_explicit) %>% 
  group_by(aphantasia) %>% 
  pairwise_wilcox_test(rt_explicit ~ congruence) %>% 
  add_xy_position(x = "congruence", group = "aphantasia", dodge = dw) %>% 
  mutate(y.position = c(.22, .3))
  
# ------------------------------------- Full G x Cng plot ----
p_mod_4_g_cng_full <-
  recipe_explicit %>% 
  prep() %>% 
  bake(df_explicit_rt) %>%
  ggplot(aes(
    x = congruence,
    y = rt_explicit,
    fill = aphantasia,
    color = aphantasia
    )
  ) +
  
  # group violin distributions with quantiles
  geom_violin(
    alpha = .2,
    trim = FALSE,
    adjust = .6,
    scale = "count",
    draw_quantiles = c(.25,.5,.75),
    position = position_dodge(width = dw),
    linewidth = .6
    ) +
  
  # participant points
  geom_beeswarm(
    cex = .5,
    dodge.width = dw,
    alpha = 0.25,
    size = .5
  ) +

  # linear modelling of the differences
  geom_line(
    data = preds_mod_4_g_cng,
    aes(
      y = Mean,
      group = aphantasia
    ),
    position = position_dodge(width = dw),
    linewidth = 1,
    linetype = 1,
    show.legend = FALSE
  ) +
   
  # predicted means of the model
  geom_pointrange2(
    data = preds_mod_4_g_cng,
    aes(
      x = congruence,
      y = Mean,
      ymin = CI_low,
      ymax = CI_high,
      group = aphantasia
      ),
    color = "black",
    position = position_dodge(width = dw),
    size = .5,
    linewidth = .5,
    show.legend = FALSE
  ) +
  
  # intercept at 0
  geom_hline(yintercept = 0, linewidth = .05, linetype = 2, alpha = .5) +
  
  # stats display
  stat_pvalue_manual(
    stats_mod_4_g_cng_full, 
    label = "p.adj.signif", 
    # tip.length = 0,
    size = st
    ) +
  
  # color_palettes and options
  labs(x = NULL, y = NULL) +
  # scale_x_discrete(labels = c("Congruent", "Incongruent")) +
  scale_y_continuous(breaks = breaks_pretty(10)) +
  scale_fill_okabeito(name = "Aphantasia: ", labels = c("Yes", "No")) +
  scale_color_okabeito(guide = NULL) +
  theme(
    panel.grid.major.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.text.x = element_blank(),
    legend.title = element_text(size = txt),
    legend.text = element_text(size = 18)
    )

# ----------------------------------- Zoomed G x Cng plot ----
p_mod_4_g_cng_zoom <-
  recipe_explicit %>% 
  prep() %>% 
  bake(df_explicit_rt) %>%
  ggplot(aes(
    x = congruence,
    y = rt_explicit,
    fill = aphantasia,
    color = aphantasia
    )
  ) +
  
  # group violin distributions with quantiles
  geom_violin(
    alpha = .2,
    trim = FALSE,
    adjust = .6,
    scale = "count",
    draw_quantiles = c(.25,.5,.75),
    position = position_dodge(width = dw),
    linewidth = .6
    ) +
  
  # participant points
  geom_beeswarm(
    cex = .5,
    dodge.width = dw,
    alpha = 0.25,
    size = .5
  ) +

  # linear modelling of the differences
  geom_line(
    data = preds_mod_4_g_cng,
    aes(
      y = Mean,
      group = aphantasia
    ),
    position = position_dodge(width = dw),
    linewidth = 1.5,
    linetype = 1,
    show.legend = FALSE
  ) +
   
  # predicted means of the model
  geom_pointrange2(
    data = preds_mod_4_g_cng,
    aes(
      x = congruence,
      y = Mean,
      ymin = CI_low,
      ymax = CI_high,
      group = aphantasia
      ),
    color = "black",
    position = position_dodge(width = dw),
    size = 1,
    linewidth = .75,
    show.legend = FALSE
  ) +
  
  # intercept at 0
  geom_hline(yintercept = 0, linetype = 2) +
  
  # stats display
  stat_pvalue_manual(
    stats_mod_4_g_cng_zoom, 
    label = "p.adj.signif", 
    tip.length = 0,
    size = st
    ) +
  
  # zoom on a shorter y range
  coord_cartesian(ylim = c(-.3,.3)) +
  
  # color_palettes and options
  labs(
    # x = "Congruence condition", 
    x = NULL, 
    y = NULL
    ) +
  scale_x_discrete(labels = c("Congruent", "Incongruent")) +
  scale_y_continuous(breaks = breaks_pretty(8)) +
  scale_fill_okabeito(name = "Aphantasia: ", labels = c("Yes", "No")) +
  scale_color_okabeito(guide = NULL) +
  theme(
    panel.grid.major.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.text.x = element_text(size = txt),
    legend.text = element_text(size = 18),
    # axis.title.x = element_text(size = 18, vjust = -.5),
    legend.title = element_text(size = txt)
    )



# . ----
# ---- Model Explicit 4 Group and Color plots ----

# model 4 marginal means predictions
preds_mod_4_g_col <- 
  all_models_fitted[[1]][[4]] %>% 
  estimate_means(at = c("aphantasia", "color"))

# model 4 contrasts between aphantasia and congruence levels
contrasts_mod_4_col <-
  all_models_fitted[[1]][[4]] %>% 
  estimate_contrasts(contrast = c("color"))

# stats for the group color interaction
stats_mod_4_g_col_full <- 
  df_explicit_rt %>% 
  standardize(rt_explicit) %>%
  group_by(aphantasia) %>% 
  pairwise_wilcox_test(rt_explicit ~ color) %>% 
  add_xy_position(x = "color", dodge = dw) %>% 
  mutate(y.position = 3.1)

# ------------------------------------- Full G x Col plot ----
p_mod_4_g_col_full <-
  recipe_explicit %>% 
  prep() %>% 
  bake(df_explicit_rt) %>%
  ggplot(aes(
    x = color,
    y = rt_explicit,
    fill = aphantasia,
    color = aphantasia
    )
  ) +
  
  # group violin distributions with quantiles
  geom_violin(
    alpha = .2,
    trim = FALSE,
    adjust = .6,
    scale = "count",
    draw_quantiles = c(.25,.5,.75),
    position = position_dodge(width = .8),
    linewidth = .6
    ) +
  
  # participant points
  geom_beeswarm(
    cex = .5,
    dodge.width = .8,
    alpha = 0.25,
    size = .5
  ) +

  # linear modelling of the differences
  geom_line(
    data = preds_mod_4_g_col,
    aes(
      y = Mean,
      group = aphantasia
    ),
    position = position_dodge(width = dw),
    linewidth = 1,
    linetype = 1,
    show.legend = FALSE
  ) +
   
  # predicted means of the model
  geom_pointrange2(
    data = preds_mod_4_g_col,
    aes(
      x = color,
      y = Mean,
      ymin = CI_low,
      ymax = CI_high,
      group = aphantasia
      ),
    color = "black",
    position = position_dodge(width = dw),
    size = .5,
    linewidth = .5,
    show.legend = FALSE
  ) +
  
  # intercept at 0
  geom_hline(yintercept = 0, linewidth = .05, linetype = 2, alpha = .5) +
  
  # stats display
  stat_pvalue_manual(
    stats_mod_4_g_col_full, 
    label = "p.adj.signif", 
    # tip.length = 0,
    size = st
    ) +
  
  # color_palettes and options
  labs(x = NULL, y = NULL) +
  # scale_x_discrete(labels = c("Congruent", "Incongruent")) +
  scale_y_continuous(breaks = breaks_pretty(10)) +
  scale_fill_okabeito(name = "Aphantasia: ", labels = c("Yes", "No")) +
  scale_color_okabeito(guide = NULL) +
  theme(
    panel.grid.major.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.text.x = element_blank(),
    legend.title = element_text(size = txt),
    legend.text = element_text(size = 18)
    )

# ----------------------------------- Zoomed G x Col plot ----

# stat for the color effect
stats_mod_4_g_col_zoom <- 
  df_explicit_rt %>% 
  standardize(rt_explicit) %>%
  group_by(aphantasia) %>%
  pairwise_wilcox_test(rt_explicit ~ color) %>% 
  add_xy_position(x = "color", dodge = dw) %>% 
  mutate(y.position = .3)


p_mod_4_g_col_zoom <-
  recipe_explicit %>% 
  prep() %>% 
  bake(df_explicit_rt) %>%
  ggplot(aes(
    x = color,
    y = rt_explicit,
    fill = aphantasia,
    color = aphantasia
    )
  ) +
  
  # group violin distributions with quantiles
  geom_violin(
    alpha = .2,
    trim = FALSE,
    adjust = .6,
    scale = "count",
    draw_quantiles = c(.25,.5,.75),
    position = position_dodge(width = .8),
    linewidth = .6
    ) +
  
  # participant points
  geom_beeswarm(
    cex = .5,
    dodge.width = .8,
    alpha = 0.25,
    size = .5
  ) +

  # linear modelling of the differences
  geom_line(
    data = preds_mod_4_g_col,
    aes(
      y = Mean,
      group = aphantasia
    ),
    position = position_dodge(width = dw),
    linewidth = 1.5,
    linetype = 1,
    show.legend = FALSE
  ) +
   
  # predicted means of the model
  geom_pointrange2(
    data = preds_mod_4_g_col,
    aes(
      x = color,
      y = Mean,
      ymin = CI_low,
      ymax = CI_high,
      group = aphantasia
      ),
    color = "black",
    position = position_dodge(width = dw),
    size = 1,
    linewidth = .75,
    show.legend = FALSE
  ) +
  
  # intercept at 0
  geom_hline(yintercept = 0, linetype = 2) +
  
  # stats display
  stat_pvalue_manual(
    stats_mod_4_g_col_zoom,
    label = "p.adj.signif",
    tip.length = 0.005,
    size = st
    ) +
    
  # zoom on a shorter y range
  coord_cartesian(ylim = c(-.3,.3)) +
  
  # color_palettes and options
  labs(
    # x = "Color condition", 
    x = NULL,
    y = NULL
    ) +
  scale_x_discrete(labels = c("Colored", "Uncolored")) +
  scale_y_continuous(breaks = breaks_pretty(8)) +
  scale_fill_okabeito(name = "Aphantasia: ", labels = c("Yes", "No")) +
  scale_color_okabeito(guide = NULL) +
  theme(
    panel.grid.major.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.text.x = element_text(size = txt),
    legend.text = element_text(size = 18),
    # axis.title.x = element_text(size = 18, vjust = -.5),
    legend.title = element_text(size = txt)
    )

# . ----
# ---------------------------------- Combined plot ----
p_mod_4 <-
  ggarrange(
    p_mod_4_g_cng_full,
    p_mod_4_g_col_full,
    p_mod_4_g_cng_zoom,
    p_mod_4_g_col_zoom,
    labels = c("Congruence", "Color"),
    label.x = c(-.1,.75),
    vjust = -.1,
    font.label = list(size = 26),
    common.legend = TRUE,
    legend = "top",
    ncol = 2,
    nrow = 2
  ) %>% 
  annotate_figure(
    left = text_grob("Response time (standardized)", size = txt, rot = 90)
    )

p_mod_4
```

## Implicit task results

The parameters of the best model for the **implicit task** are displayed in @tbl-model_implicit_3_params. The significant parameters are the **Group**, the **interaction between Group and Congruence** and the **interaction between Group and Color**. These parameters indicate that: 1) aphantasics responded slower, 2) the uncongruent condition had non-aphantasics becoming slower, and 3) non-aphantasics also responded slower in the uncolored condition. This main effect and the interactions are represented in @fig-model_implicit_3_plots_congruence for the $Group \times Congruence$ interaction, and @fig-model_implicit_3_plots_color for the $Group \times Color$ interaction. 

```{r model_implicit_3_params}
#| echo: false
#| label: tbl-model_implicit_3_params
#| tbl-cap: "Implicit task  - Parameters of the optimal model including a random intercept by subject."

all_models_parameters[["implicit_mods"]][["mod_implicit_3"]]
```

```{r model_implicit_3_plots_congruence}
#| echo: false
#| label: fig-model_implicit_3_plots_congruence
#| fig-cap: "Visualization of the Congruence and Group variables in the optimal model for the implicit task. The bottom plot is a 'zoomed' version of the first one on a shorter (standard) RT range for a clearer view of the model. The horizontal colored lines in the 'violins' represent quantiles at 25, 50 and 75%. The black dots indicate marginal means predicted by the model, whereas the black bars represent the credible intervals of these estimations." 
#| fig-width: 8
#| fig-height: 11

# ---- Model Implicit 3 Congruence view ----

# model 3 marginal means predictions
preds_mod_3_fixed_congruence <- 
  all_models_fitted[[2]][[3]] %>% 
  estimate_means(at = c("aphantasia", "congruence"))

# setting dodge width for all the geoms
dw <-.75

# ------------------------------------- Full plot ----
p_mod_3_congruence_full <-
  recipe_implicit %>% 
  prep() %>% 
  bake(df_implicit_rt) %>%
  ggplot(aes(
    x = congruence,
    y = rt_implicit,
    fill = aphantasia,
    color = aphantasia
    )
  ) +
  
  # group violin distributions with quantiles
  geom_violin(
    alpha = .2,
    trim = FALSE,
    adjust = .6,
    scale = "count",
    draw_quantiles = c(.25,.5,.75),
    position = position_dodge(width = dw),
    linewidth = .6
    ) +
  
  # participant points
  geom_beeswarm(
    cex = .5,
    dodge.width = dw,
    alpha = 0.25,
    size = .5
  ) +

  # linear modelling of the differences
  geom_line(
    data = preds_mod_3_fixed_congruence,
    aes(
      y = Mean,
      group = aphantasia
    ),
    position = position_dodge(width = dw),
    linewidth = 1,
    linetype = 1,
    show.legend = FALSE
  ) +
   
  # predicted means of the model
  geom_pointrange2(
    data = preds_mod_3_fixed_congruence,
    aes(
      x = congruence,
      y = Mean,
      ymin = CI_low,
      ymax = CI_high,
      group = aphantasia
      ),
    color = "black",
    position = position_dodge(width = dw),
    size = .5,
    linewidth = .5,
    show.legend = FALSE
  ) +
  
  # intercept at 0
  geom_hline(yintercept = 0, linewidth = .05, linetype = 2, alpha = .5) +
  
  # color_palettes and options
  labs(x = NULL, y = NULL) +
  # scale_x_discrete(labels = c("Congruent", "Incongruent")) +
  scale_y_continuous(breaks = breaks_pretty(10)) +
  scale_fill_okabeito(name = "Aphantasia", labels = c("Yes", "No")) +
  scale_color_okabeito(guide = NULL) +
  theme(
    panel.grid.major.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.text.x = element_blank()
    )

# ----------------------------------- Zoomed plot ----
p_mod_3_congruence_interaction_zoom <-
  recipe_implicit %>% 
  prep() %>% 
  bake(df_implicit_rt) %>%
  ggplot(aes(
    x = congruence,
    y = rt_implicit,
    fill = aphantasia,
    color = aphantasia
    )
  ) +
  
  # group violin distributions with quantiles
  geom_violin(
    alpha = .2,
    trim = FALSE,
    adjust = .6,
    scale = "count",
    draw_quantiles = c(.25,.5,.75),
    position = position_dodge(width = dw),
    linewidth = .6
    ) +
  
  # participant points
  geom_beeswarm(
    cex = .5,
    dodge.width = dw,
    alpha = 0.25,
    size = .5
  ) +

  # linear modelling of the differences
  geom_line(
    data = preds_mod_3_fixed_congruence,
    aes(
      y = Mean,
      group = aphantasia
    ),
    position = position_dodge(width = dw),
    linewidth = 1.5,
    linetype = 1,
    show.legend = FALSE
  ) +
   
  # predicted means of the model
  geom_pointrange2(
    data = preds_mod_3_fixed_congruence,
    aes(
      x = congruence,
      y = Mean,
      ymin = CI_low,
      ymax = CI_high,
      group = aphantasia
      ),
    color = "black",
    position = position_dodge(width = dw),
    size = 1,
    linewidth = .75,
    show.legend = FALSE
  ) +
  
  # intercept at 0
  geom_hline(yintercept = 0, linetype = 2) +
  
  # zoom on a shorter y range
  coord_cartesian(ylim = c(-.3,.3)) +
  
  # color_palettes and options
  labs(x = NULL, y = NULL) +
  scale_x_discrete(labels = c("Congruent", "Incongruent")) +
  scale_y_continuous(breaks = breaks_pretty(8)) +
  scale_fill_okabeito(name = "Aphantasia", labels = c("Yes", "No")) +
  scale_color_okabeito(guide = NULL) +
  theme(
    panel.grid.major.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.text.x = element_text(size = 18)
    )

# ---------------------------------- Combined plot ----
p_mod_3_congruence_both <-
  ggarrange(
    p_mod_3_congruence_full,
    p_mod_3_congruence_interaction_zoom,
    common.legend = TRUE,
    ncol = 1
  ) %>% 
  annotate_figure(
    left = text_grob("Response time (standardized)", size = 18, rot = 90),
    bottom = text_grob("Congruence condition", size = 20)
    )

p_mod_3_congruence_both
```

```{r model_implicit_3_plots_color}
#| echo: false
#| label: fig-model_implicit_3_plots_color
#| fig-cap: "Visualization of the Color and Group variables in the optimal model for the implicit task. The bottom plot is a 'zoomed' version of the first one on a shorter (standard) RT range for a clearer view of the model. The horizontal colored lines in the 'violins' represent quantiles at 25, 50 and 75%. The black dots indicate marginal means predicted by the model, whereas the black bars represent the credible intervals of these estimations." 
#| fig-width: 8
#| fig-height: 11

# ---- Model Implicit 3 Color view ----

# model 3 marginal means predictions
preds_mod_3_fixed_color <- 
  all_models_fitted[[2]][[3]] %>% 
  estimate_means(at = c("aphantasia", "color"))

# setting dodge width for all the geoms
dw <-.75

# ------------------------------------- Full plot ----
p_mod_3_color_full <-
  recipe_implicit %>% 
  prep() %>% 
  bake(df_implicit_rt) %>%
  ggplot(aes(
    x = color,
    y = rt_implicit,
    fill = aphantasia,
    color = aphantasia
    )
  ) +
  
  # group violin distributions with quantiles
  geom_violin(
    alpha = .2,
    trim = FALSE,
    adjust = .6,
    scale = "count",
    draw_quantiles = c(.25,.5,.75),
    position = position_dodge(width = dw),
    linewidth = .6
    ) +
  
  # participant points
  geom_beeswarm(
    cex = .5,
    dodge.width = dw,
    alpha = 0.25,
    size = .5
  ) +

  # linear modelling of the differences
  geom_line(
    data = preds_mod_3_fixed_color,
    aes(
      y = Mean,
      group = aphantasia
    ),
    position = position_dodge(width = dw),
    linewidth = 1,
    linetype = 1,
    show.legend = FALSE
  ) +
   
  # predicted means of the model
  geom_pointrange2(
    data = preds_mod_3_fixed_color,
    aes(
      x = color,
      y = Mean,
      ymin = CI_low,
      ymax = CI_high,
      group = aphantasia
      ),
    color = "black",
    position = position_dodge(width = dw),
    size = .5,
    linewidth = .5,
    show.legend = FALSE
  ) +
  
  # intercept at 0
  geom_hline(yintercept = 0, linewidth = .05, linetype = 2, alpha = .5) +
  
  # color_palettes and options
  labs(x = NULL, y = NULL) +
  # scale_x_discrete(labels = c("Congruent", "Incongruent")) +
  scale_y_continuous(breaks = breaks_pretty(10)) +
  scale_fill_okabeito(name = "Aphantasia", labels = c("Yes", "No")) +
  scale_color_okabeito(guide = NULL) +
  theme(
    panel.grid.major.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.text.x = element_blank()
    )

# ----------------------------------- Zoomed plot ----
p_mod_3_color_interaction_zoom <-
  recipe_implicit %>% 
  prep() %>% 
  bake(df_implicit_rt) %>%
  ggplot(aes(
    x = color,
    y = rt_implicit,
    fill = aphantasia,
    color = aphantasia
    )
  ) +
  
  # group violin distributions with quantiles
  geom_violin(
    alpha = .2,
    trim = FALSE,
    adjust = .6,
    scale = "count",
    draw_quantiles = c(.25,.5,.75),
    position = position_dodge(width = dw),
    linewidth = .6
    ) +
  
  # participant points
  geom_beeswarm(
    cex = .5,
    dodge.width = dw,
    alpha = 0.25,
    size = .5
  ) +

  # linear modelling of the differences
  geom_line(
    data = preds_mod_3_fixed_color,
    aes(
      y = Mean,
      group = aphantasia
    ),
    position = position_dodge(width = dw),
    linewidth = 1.5,
    linetype = 1,
    show.legend = FALSE
  ) +
   
  # predicted means of the model
  geom_pointrange2(
    data = preds_mod_3_fixed_color,
    aes(
      x = color,
      y = Mean,
      ymin = CI_low,
      ymax = CI_high,
      group = aphantasia
      ),
    color = "black",
    position = position_dodge(width = dw),
    size = 1,
    linewidth = .75,
    show.legend = FALSE
  ) +
  
  # intercept at 0
  geom_hline(yintercept = 0, linetype = 2) +
  
  # zoom on a shorter y range
  coord_cartesian(ylim = c(-.3,.3)) +
  
  # color_palettes and options
  labs(x = NULL, y = NULL) +
  scale_x_discrete(labels = c("Colored", "Uncolored")) +
  scale_y_continuous(breaks = breaks_pretty(8)) +
  scale_fill_okabeito(name = "Aphantasia", labels = c("Yes", "No")) +
  scale_color_okabeito(guide = NULL) +
  theme(
    panel.grid.major.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.text.x = element_text(size = 18)
    )

# ---------------------------------- Combined plot ----
p_mod_3_color_both <-
  ggarrange(
    p_mod_3_color_full,
    p_mod_3_color_interaction_zoom,
    common.legend = TRUE,
    ncol = 1
  ) %>% 
  annotate_figure(
    left = text_grob("Response time (standardized)", size = 18, rot = 90),
    bottom = text_grob("Color condition", size = 20)
    )

p_mod_3_color_both
```









# Annexes

## Rotation task

Some quick analyses of the rotation task are summarized as visualizations in @fig-rotation.

```{r rotation}
#| label: fig-rotation
#| echo: false
#| fig-cap: "Analyses of the rotation task, including the distribution of errors between groups and correlations with the imagery variables."
#| fig-width: 11
#| fig-height: 7

# --- Annex: analysis of the rotation task -------------------------------------

# --- Number of errors - rotation task -----------------------------------------
p_rotation_errors <- 
  df_rotation %>%
  select(subjectid, correct_rotation, aphantasia) %>% 
  group_by(subjectid, aphantasia) %>% 
  count(correct_rotation) %>% 
  filter(correct_rotation == 1) %>% 
  mutate(n = 20 - n) %>% 
  ggplot(aes(
    x = n, 
    color = aphantasia,
    fill = aphantasia
    )) +
  geom_bar(
    aes(y = after_stat(prop)),
    position = position_dodge(),
    width = .8,
    alpha = .4
    ) +
  geom_density(aes(y = after_stat(density), color = NULL), alpha = .2) +
  scale_x_continuous(
    name = "Number of errors",
    breaks = breaks_pretty(n = 20)
    ) +
  scale_y_continuous(
    name = "Proportion of the group",
    breaks = breaks_pretty(n = 10)
    ) +
  coord_cartesian(
    xlim = c(0, 14),
    ylim = c(.01,.16)
    ) +
  labs(title = "Rotation task") +
  scale_color_okabeito(guide = NULL) +
  scale_fill_okabeito(name = "Aphantasia", labels = c("Yes", "No")) +
  theme(legend.position = "top")

# --- Correlation between rotation correct and spatial imagery -----------------
p_rotation_cor_spa <- 
  df_rotation %>% 
  select(subjectid, correct_rotation, spatial_imagery) %>% 
  group_by(subjectid) %>% 
  summarise(
    correct_perc = sum(correct_rotation)/20,
    mean_s = mean(spatial_imagery)
  ) %>% 
  standardize(correct_perc) %>% 
  cor_test("mean_s", "correct_perc", bayesian = TRUE) %>% 
  plot +
  labs(x = "Spatial imagery", y = "Correct responses")

# --- Correlation between rotation correct and visual imagery ------------------
p_rotation_cor_vis <- 
  df_rotation %>% 
  select(subjectid, correct_rotation, visual_imagery) %>% 
  group_by(subjectid) %>% 
  summarise(
    correct_perc = sum(correct_rotation)/20,
    mean_v = mean(visual_imagery)
  ) %>% 
  standardize(correct_perc) %>% 
  cor_test("mean_v", "correct_perc", bayesian = TRUE) %>% 
  plot +
  labs(x = "Visual imagery", y = "Correct responses")

# --- Correlation between rotation correct and vviq ----------------------------
p_rotation_cor_vviq <-
  df_rotation %>% 
  select(subjectid, correct_rotation, vviq80) %>% 
  group_by(subjectid) %>% 
  summarise(
    correct_perc = sum(correct_rotation)/20,
    vviq = mean(vviq80)
  ) %>% 
  standardize(select = c("vviq", "correct_perc")) %>% 
  cor_test("vviq", "correct_perc", bayesian = TRUE) %>% 
  plot +
  labs(x = "VVIQ", y = "Correct responses")

ggarrange(
  p_rotation_errors, 
  p_rotation_cor_vis, 
  p_rotation_cor_vviq, 
  p_rotation_cor_spa + rremove("ylab")
  )
```































































