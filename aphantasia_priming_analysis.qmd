---
title: "Sensory priming in aphantasia - Data analysis"
author: "MaÃ«l Delem"
format: html
editor_options: 
  chunk_output_type: console
toc: true
---

This analysis was conducted in R language through the RStudio Integrated Development Environment. Just down below is the setup code, including two essential steps: 1) installing the required packages for this data analysis, and 2) importing data into the dataframes used throughout. I left this (usually hidden) step there for reference in a view of transparency for the interested reader.

```{r setup}

# --- Packages -----------------------------------------------------------------

# The package `librairian` will ease the package management with the "shelf" 
# function, which automatically: 
# 1) checks if a package is installed 
# 2) installs it if need be
# 3) loads the package like the "library()" function would.
if (!require(librarian)) install.packages(librarian)
library(librarian)

# now putting packages on our library's shelves:
shelf(
  readxl,         # Excel files management
  easystats,      # collection of data analysis packages
  tidymodels,     # collection of packages for a tidy modelling workflow
  bayesian,       # bayesian modelling with brms and tidymodels
  multilevelmod,  # multilevel modelling with lmer
  mclust,         # mixture clustering
  ggpubr,         # ggplot tools
  viridis,        # ggplot colour-blind friendly palettes
  tidyverse       # the essentials
)

# --- Global cosmetic theme ---
theme_set(theme_bw(base_size = 14))

# --- Fixing a seed for reproducibility ---
set.seed(14051998)

# --- Importing data -----------------------------------------------------------

# Association task
df_asso <- read_excel("data/aphantasia_priming_tidy_data.xlsx", 
                     sheet = "data_asso")

# Implicit task
df_implicit <- read_excel("data/aphantasia_priming_tidy_data.xlsx", 
                     sheet = "data_implicit")

# Explicit task
df_explicit <- read_excel("data/aphantasia_priming_tidy_data.xlsx", 
                     sheet = "data_explicit")

# Rotation task
df_rotation <- read_excel("data/aphantasia_priming_tidy_data.xlsx", 
                     sheet = "data_rotation")

# Questionnaires
df_questionnaires <- 
  read_excel(
    "data/aphantasia_priming_tidy_data.xlsx",
    sheet = "data_questionnaires"
    ) %>% 
  # creating the a/phantasia groups
  mutate(
    aphantasia = ifelse(vviq80 < 32, "yes", "no"),
    aphantasia = fct_relevel(aphantasia, "yes", "no")
    )
```

# Exploratory Data Analysis

## Questionnaire data and imagery

### Correlations

The four questionnaire variables - VVIQ, OSIQ-Object and Spatial, and SUIS - are meant to be used as predictors (independent variables) for the behavioural outcomes of the experiment (dependent variables, RTs and potentially accuracy). Three of these - VVIQ, OSIQ-Object and SUIS - evaluate visual imagery: as such, in a view of parsimony, we are going to evaluate the correlation between these continuous predictors and judge if they should be merged/omitted. The results of the Bayesian partial correlations between the four variables are displayed in @fig-cor_matrix and @tbl-cor_stats. Partial correlations have been chosen here to account for the (theoretically huge) covariance between visual imagery variables. It will result in more conservative estimations of the correlations, and a better understanding of the relations between visual and spatial imagery measures.

```{r correlation}

# --- Bayesian Pearson correlation between questionnaire scores ---
cor_questionnaires <-
  df_questionnaires %>%
  select("vviq80", "suis60","osiq_o75", "osiq_s75") %>% 
  standardise %>% 
  correlation(
    bayesian = TRUE,
    partial = TRUE,
    partial_bayesian = TRUE,
    bayesian_test = "bf"
    )
```

```{r correlation_matrix}
#| label: fig-cor_matrix
#| echo: false
#| fig-cap: "Correlation matrix of the questionnaire variables. The stars indicate the amount of evidence in favour of a correlation, as assessed by the $BF_{10}$: No star = Anecdotal evidence, * = Weak evidence, ** = Moderate evidence, *** = Extreme evidence."

# --- Correlation matrix ---
cor_questionnaires %>%
  mutate(across(c(Parameter1, Parameter2),
    ~ case_when(
    .x == "vviq80" ~ "VVIQ",
    .x == "suis60" ~ "SUIS",
    .x == "osiq_o75" ~ "OSIQ-O",
    .x == "osiq_s75" ~ "OSIQ-S"))
    ) %>% 
  summary(digits = 2) %>% 
  plot(
    text = list(size = 5),
    labs = list(title = "")
    ) +
  scale_fill_viridis(
    option = "D",
    name = expression(rho),
    alpha = .6,
    direction = 1,
    limits = c(-1,1)
    ) +
  theme_bw() +
  theme(
    panel.grid = element_blank(),
    axis.text = element_text(size = 14)
    )
```

```{r correlation_table}
#| label: tbl-cor_stats
#| echo: false
#| tbl-cap: "Detailed correlation table of the questionnaire variables."

# --- Correlation table ---
cor_questionnaires %>%
  format %>% 
  mutate(across(c(Parameter1, Parameter2),
    ~ case_when(
    .x == "vviq80" ~ "VVIQ",
    .x == "suis60" ~ "SUIS",
    .x == "osiq_o75" ~ "OSIQ-O",
    .x == "osiq_s75" ~ "OSIQ-S"))
    ) %>% 
  rename(
    "Variable 1" = Parameter1,
    "Variable 2" = Parameter2,
    "$\\rho$" = rho,
    "$BF_{10}$" = BF
  ) %>% 
  knitr::kable()
```

As we can see, while the three visual imagery variables are highly correlated, the association between these visual and spatial imagery (OSIQ-S) is inconsistent: VVIQ and OSIQ-S are positively correlated although with anecdotal evidence, SUIS and OSIQ-S have a moderately evidenced positive correlation, while OSIQ-Object and OSIQ-Spatial are negatively correlated. We'll run a Principal Component Analysis to evaluate the possibility of a feature reduction of visual imagery as a single variable.

### Principal Component Analysis

```{r pca}
# --- Principal Component Analysis ---
pca <- 
  principal_components(
    df_questionnaires[,4:7],
    n = "max",
    sort = TRUE,
    standardize = TRUE
    ) 
```

```{r loadings}
#| label: fig-loadings
#| echo: false
#| fig-cap: "Loadings of each variable on the three components extracted by a PCA."

# --- Loadings ---
pca %>% plot + 
  scale_y_discrete(labels = c("OSIQ-S", "OSIQ-O", "VVIQ", "SUIS")) +
  scale_fill_viridis(alpha = .6) +
  labs(title = NULL) +
  theme(text = element_text(size = 14))
```

```{r eigenvalues}
#| label: tbl-eigenvalues
#| echo: false
#| tbl-cap: "Eigenvalues and variance explained by the three components extracted by a PCA."

# --- Eigenvalues and variance ---
pca %>% 
  summary %>% 
  rename(
    "Component 1" = PC1,
    "Component 2" = PC2,
    "Component 3" = PC3,
  ) %>%
  format(digits = 2) %>% 
  display
```

As expected, the visual imagery variables are grouped in a single component ("PC1" in @fig-loadings or "Component 1" in @tbl-eigenvalues) with an Eigenvalue of 2.84, therefore accounting for 71% of the total variance of the data. The second component (PC2 / Component 2) has an Eigenvalue of .97, accounts for 24% of the total variance, and is mostly loaded negatively on the OSIQ-S: this brings the total explained proportion of variance to 95%. Traditionally, the threshold used for selecting a principal component is an Eigenvalue of 1. Nevertheless, given the Eigenvalue of .97 and the properties of this component, i.e. singling out the specificity of the spatial scale, this component will be kept for analysis.

Standardized predicted values for each component will be computed and added to the data, renamed ***Visual Imagery*** (PC1, mostly VVIQ + SUIS + OSIQ-O with an influence of OSIQ-S) and ***Spatial Imagery*** (PC2, mostly OSIQ-S, with an influence of SUIS). In order to align the Spatial Imagery variable with the OSIQ-Spatial, the variable will be reversed (they are correlated negatively as it is, as shown by the -.96 loading on PC2).

```{r pca_components}
pca_components <- pca %>% predict

df_questionnaires_pca <- 
  bind_cols(df_questionnaires, pca_components[,1:2]) %>% 
  mutate(
    PC1 = standardize(PC1),
    PC2 = -standardize(PC2)
    ) %>% 
  rename(
    "visual_imagery" = PC1,
    "spatial_imagery" = PC2
    )
```

### VVIQ, visual and spatial imagery

Now we can see that the main visual imagery variables, namely the (conventional) VVIQ and the *Visual Imagery* component created through PCA are completely decorrelated from the *Spatial Imagery* component, as shown in @fig-spatial_corr.

```{r spatial_correlations}
#| label: fig-spatial_corr
#| echo: false
#| fig-cap: "Correlation between the main visual imagery variables and the spatial imagery one."
#| fig-width: 9
#| fig-height: 4.5

# --- correlation between visual and spatial ---
p_cor_spatial_vis <- 
  df_questionnaires_pca %>% 
  mutate(
    visual_imagery = rescale(visual_imagery),
    spatial_imagery = rescale(spatial_imagery),
    aphantasia = fct_relevel(aphantasia, "yes", "no")
    ) %>%
  ggplot(aes(x = visual_imagery, y = spatial_imagery, color = aphantasia)) +
  geom_point() +
  scale_color_okabeito(name = "Aphantasia", labels = c("Yes", "No")) +
  geom_smooth(
    aes(x = visual_imagery, y = spatial_imagery), 
    color = "black", 
    method = "lm", 
    stat = "smooth") +
  stat_cor(
    aes(x = visual_imagery, 
        y = spatial_imagery), 
    inherit.aes = FALSE, 
    cor.coef.name = "r", 
    label.x.npc = .5,
    label.y.npc = .7) +
  labs(x = "Visual Imagery",
       y = "Spatial Imagery")

# --- correlation between vviq and spatial ---
p_cor_spatial_vviq <- 
  df_questionnaires_pca %>% 
  mutate(
    vviq80 = rescale(vviq80),
    spatial_imagery = rescale(spatial_imagery)
    ) %>%
  ggplot(aes(x = vviq80, y = spatial_imagery, color = aphantasia)) +
  geom_point() +
  scale_color_okabeito(name = "Aphantasia", labels = c("Yes", "No")) +
  geom_smooth(
    aes(x = vviq80, y = spatial_imagery), 
    color = "black", 
    method = "lm", 
    stat = "smooth") +
  stat_cor(
    aes(x = vviq80, 
        y = spatial_imagery), 
    inherit.aes = FALSE, 
    cor.coef.name = "r", 
    label.x.npc = .5,
    label.y.npc = .7) +
  labs(x = "VVIQ",
       y = "Spatial Imagery")

ggarrange(
  p_cor_spatial_vis,
  p_cor_spatial_vviq + rremove("ylab"),
  common.legend = TRUE,
  legend = "bottom"
)

```

The consequence of this analysis is that from this point onwards, for the future models to be fitted, two options are available:

- Binning the participants in two categories based on the VVIQ (cut-off at 32, Aphantasics/Phantasics).

- Using the visual imagery variable as a continuous predictor.

Although we could use the VVIQ both for categorizing and as a continuous variable, for the sake of consistency, we are going to use the VVIQ only as a classification variable for defining aphantasia, and the *Visual Imagery* component from the PCA as the continuous variable measuring visual imagery. Therefore two types of models are going to be fitted:

1. Models using **Aphantasia as a categorical variable.**

2. Models using **Visual Imagery as a continuous variable.**

In both cases, we are going to account for the potential effect of spatial imagery by using the eponymous component computed earlier as a predictor in the models.

```{r df_updates}
#| echo: false

# updating all the dataframes with the imagery variables
dfs <- 
  list(df_asso, df_implicit, df_explicit, df_rotation) %>%
  # adding the vviq and group column to every dataframe
  imap(~left_join(
    .x, 
    df_questionnaires_pca %>% 
      select(
        # column to match with the correct participants
        subjectid, 
        # new variables to add
        age,
        sexe,
        vviq80, 
        visual_imagery, 
        spatial_imagery,
        aphantasia), by = "subjectid") %>% 
      rename("sex" = sexe) %>% 
      # reordering the final dfs
      select(
        subjectid, 
        age, sex, aphantasia,
        vviq80, visual_imagery, spatial_imagery,
        everything())
    )

df_asso     <- dfs[[1]]
df_implicit <- dfs[[2]]
df_explicit <- dfs[[3]]
df_rotation <- dfs[[4]]
```

## Outcomes: accuracy and RTs?

### Accuracy

While response time is an obvious outcome to model when it comes to decision tasks, the use of accuracy is more debatable, as the tasks were not specifically designed to be challenging. Traditionally, accuracy is mostly used to remove incorrect trials from RT modelling. We'll describe accuracy data to evaluate its relevance in this analysis. The distribution of the percentages of errors across the three tasks is displayed in @fig-distributions.

```{r distributions}
#| label: fig-distributions
#| echo: false
#| fig-cap: "Distribution of errors between groups in the three main tasks."
#| fig-width: 9
#| fig-height: 11

# --- Number of errors - association task --------------------------------------
p_errors_asso <-
  df_asso %>%
  select(subjectid, correct_association, aphantasia) %>% 
  group_by(subjectid, aphantasia) %>% 
  count(correct_association) %>% 
  filter(correct_association == 1) %>% 
  mutate(n = 100 - n) %>% 
  ggplot(aes(
    x = n, 
    color = aphantasia,
    fill = aphantasia
    )) +
  geom_bar(
    aes(y = after_stat(prop)),
    position = position_dodge(),
    width = .8,
    alpha = .5
    ) +
  scale_x_continuous(
    name = "Percentage of errors",
    breaks = breaks_pretty(n = 20)
    ) +
  scale_y_continuous(
    name = "Proportion of the group",
    breaks = breaks_pretty(n = 10)
    ) +
  coord_cartesian(
    xlim = c(0.5, 24),
    ylim = c(.01,.36)
    ) +
  labs(title = "Association task") +
  scale_color_okabeito(guide = NULL) +
  scale_fill_okabeito(name = "Aphantasia", labels = c("Yes", "No"))

# --- Number of errors - implicit task -----------------------------------------
p_errors_implcit <-
  df_implicit %>%
  select(subjectid, correct_implicit, aphantasia) %>% 
  group_by(subjectid, aphantasia) %>% 
  count(correct_implicit) %>% 
  filter(correct_implicit == 1) %>% 
  mutate(n = (64 - n)/64 * 100) %>% 
  ggplot(aes(
    x = n, 
    color = aphantasia,
    fill = aphantasia
    )) +
  geom_bar(
    aes(y = after_stat(prop)),
    position = position_dodge(),
    width = .6,
    alpha = .6
    ) +
  scale_x_continuous(
    name = "Percentage of errors",
    breaks = breaks_pretty(n = 20)
    ) +
  scale_y_continuous(
    name = "Proportion of the group",
    breaks = breaks_pretty(n = 10)
    ) +
  coord_cartesian(
    xlim = c(1, 40),
    ylim = c(.01,.28)
    ) +
  labs(title = "Implicit task") +
  scale_color_okabeito(guide = NULL) +
  scale_fill_okabeito(name = "Aphantasia", labels = c("Yes", "No"))

# --- Number of errors - explicit task -----------------------------------------
p_errors_explicit <-
  df_explicit %>%
  select(subjectid, correct_explicit, aphantasia) %>% 
  group_by(subjectid, aphantasia) %>% 
  count(correct_explicit) %>% 
  filter(correct_explicit == 1) %>% 
  mutate(n = (64 - n)/64 * 100) %>% 
  ggplot(aes(
    x = n, 
    color = aphantasia,
    fill = aphantasia
    )) +
  geom_bar(
    aes(y = after_stat(prop)),
    position = position_dodge(),
    width = .6,
    alpha = .6
    ) +
  scale_x_continuous(
    name = "Percentage of errors",
    breaks = breaks_pretty(n = 20)
    ) +
  scale_y_continuous(
    name = "Proportion of the group",
    breaks = breaks_pretty(n = 10)
    ) +
  coord_cartesian(
    xlim = c(1, 46),
    ylim = c(.01,.36)
    ) +
  labs(title = "Explicit task") +
  scale_color_okabeito(guide = NULL) +
  scale_fill_okabeito(name = "Aphantasia", labels = c("Yes", "No"))

# --- All distributions --------------------------------------------------------
ggarrange(
  p_errors_asso + rremove("xlab") + rremove("ylab"),
  p_errors_explicit + rremove("xlab") + rremove("ylab"),
  p_errors_implcit + rremove("xlab") + rremove("ylab"),
  ncol = 1,
  common.legend = TRUE,
  legend = "right"
  ) %>% 
  annotate_figure(
    left = text_grob("Proportion of the group", size = 20, rot = 90),
    bottom = text_grob("Percentage of errors", size = 20)
    )
```

We can see that the distributions are skewed yet very similar across groups and tasks: as such, we are going to use accuracy only to remove missed trials in the analyses of the RTs. Nevertheless, the main noticeable aspect of these plots are the obvious outliers in each of the tasks. This information is crucial as it could reflect a wrong understanding of the task, or random responses: in any case, participants that have high error rates would require a deletion of up to 47% of their trials, which could become a bias in the modelling of the overall data. As there appear to be a cut-off of the main distribution around 16% of errors in all tasks, this value will be chosen as threshold. **For each task separately, the results of participants with an error rate superior to 16% will be removed, prior to removing all the missed trials of the remaining participants for modelling RTs.**

### Response times

As a preprocessing, response times below 300ms and above 3000ms will be removed as they could represent false alarms, along with error trials. This amounts to 5.3% of trials in both tasks. As specified earlier, the data for each task from outliers that have an error rate above to 16% will be removed as well (9 participants in the explicit task and 4 in the implicit task). There could also be outliers with overall abnormally fast or slow RTs. This analysis will be conducted on mean RTs, the distribution of which is displayed in @fig-rt_outliers, along with their statistics in @tbl-rt_means. 

```{r acc_outliers}
#| echo: false

# --- Accuracy outliers analysis ---
df_outliers <- 
  list(df_explicit, df_implicit) %>%
  imap(
    ~.x %>% 
      select(subjectid, starts_with("correct"), aphantasia) %>%
      group_by(subjectid) %>% 
      count(pick(2)) %>% 
      filter(pick(1) == 1) %>%
      ungroup() %>% 
      mutate(
        n_tot = max(n),
        prop = (n_tot - n) / n_tot * 100
      ) %>%
      arrange(desc(prop)) %>% 
      select(1, 5)
    )
# 9 accuracy outliers in the explicit task, 4 in the implicit one

# --- Tidied RT dataframes -----------------------------------------------------
df_explicit_rt <-
  df_explicit %>% 
  filter(
    rt_explicit > 300 & 
      rt_explicit < 3000 & 
      correct_explicit == 1 &
      !(subjectid %in% c(
        "ldossantos", 
        "aknezevic", 
        "agayou", 
        "bluciani", 
        "lbrunie", 
        "cmarcenytheault", 
        "llhermitte", 
        "jnaruse", 
        "fc"))
    ) %>% 
  select(-c(response, correct_explicit))

df_implicit_rt <- 
  df_implicit %>% 
  filter(
    rt_implicit > 300 & 
      rt_implicit < 3000 & 
      correct_implicit == 1 &
      !(subjectid %in% c(
        "bdispaux", 
        "eleveque", 
        "aleclaire", 
        "dchimenton"))
      ) %>% 
  select(-c(response, correct_implicit))
```

```{r rt_outliers}
#| echo: false
#| label: fig-rt_outliers
#| fig-cap: "Distribution of the mean RTs of participants in the explicit and implicit tasks."
#| fig-width: 9
#| fig-height: 4

df_stats_rt_explicit <-
  df_explicit_rt %>% 
  group_by(subjectid) %>% 
  summarise(
    mean = mean(rt_explicit),
    mad = mad(rt_explicit),
    min = min(rt_explicit),
    max = max(rt_explicit)
  )

df_stats_rt_implicit <-
  df_implicit_rt %>% 
  group_by(subjectid) %>% 
  summarise(
    mean = mean(rt_implicit),
    mad = mad(rt_implicit),
    min = min(rt_implicit),
    max = max(rt_implicit)
  )

# --- RT outliers analysis ---
p_rt_explicit <-
  df_stats_rt_explicit %>%
  ggplot(aes(x = mean)) +
  geom_histogram(
    fill = "aquamarine2", 
    color = "aquamarine4", 
    alpha = .3,
    bins = 70
    # adjust = .4
    ) +
  labs(x = "Explicit task mean RT", y = "Number of participants") +
  scale_y_continuous(breaks = seq(0, 13, by = 1))

p_rt_implicit <-
  df_stats_rt_implicit %>%
  ggplot(aes(x = mean)) +
  geom_histogram(
    fill = "coral2", 
    color = "coral4", 
    alpha = .3,
    bins = 70
    # adjust = .4
    ) +
  labs(x = "Implicit task mean RT", y = NULL) +
  scale_y_continuous(breaks = seq(0, 9, by = 1))

ggarrange(p_rt_explicit, p_rt_implicit)
```

```{r rt_means_table}
#| echo: false
#| label: tbl-rt_means
#| tbl-cap: "Descriptive statistics of the average RTs across the sample in both tasks."

df_rt <-
  list(
  df_explicit_rt %>% rename("Explicit task mean RTs" = rt_explicit), 
  df_implicit_rt %>% rename("Implicit task mean RTs" = rt_implicit)
  ) %>% 
  imap(
    ~select(.x, contains("RT")) %>%
      report() %>% 
      as.data.frame() %>% 
      select(1, 2, 5:10)
    )

bind_rows(df_rt[[1]], df_rt[[2]]) %>% display
```

For this more precise analysis of mean RTs, we are going to use an outlier detection method based on the Median Absolute Deviation (MAD). Common thresholds used for outlier detection with MADs are $median \ \pm \ 3 \cdot MAD$ (Hampel filter; see Enderlein, 1987). However, the low boundary of this interval would be aberrant in our case, as all the participants with fast RT means stay above the $median \ - \ 1.5 \cdot MAD$. As for the high threshold, the choice the $median \ + \ 3 \cdot MAD$ would set a highly conservative maximum (e.g. 1361ms for the explicit task) and bring the total number of removed trials over 13%. Therefore, after careful examination of the ranges, and in order to keep as many trials as possible, we chose to set the upper threshold at $median \ + \ 5 \cdot MAD$ (i.e. 1797ms for the explicit task, and 1386ms for the implicit task), resulting in an overall deletion of 7.9% of trials in the explicit task and 8.9% of trials in the implicit one in this whole data preprocessing. The resulting distributions of RTs for each participant are represented in @fig-rt_per_participant.

```{r rt_per_participant}
#| echo: false
#| label: fig-rt_per_participant
#| fig-cap: "Distribution of RTs in both tasks for each participant. Each colored line represents a single participant."
#| fig-width: 11
#| fig-height: 4

# --- second tidying ---
df_explicit_rt <-
  df_explicit_rt %>% 
  filter(rt_explicit < 1797)

df_implicit_rt <-
  df_implicit_rt %>% 
  filter(rt_implicit < 1386)

# --- checking individual stats again ---
df_stats_rt_explicit <-
  df_explicit_rt %>% 
  group_by(subjectid) %>% 
  summarise(
    mean = mean(rt_explicit),
    mad = mad(rt_explicit),
    min = min(rt_explicit),
    max = max(rt_explicit),
    obs = length(rt_explicit)
  )

df_stats_rt_implicit <-
  df_implicit_rt %>% 
  group_by(subjectid) %>% 
  summarise(
    mean = mean(rt_implicit),
    mad = mad(rt_implicit),
    min = min(rt_implicit),
    max = max(rt_implicit),
    obs = length(rt_implicit)
  )

# --- removing the last outlier ---
df_explicit_rt <- df_explicit_rt %>% filter(subjectid != "dchimenton")

# --- RT distributions per participant ---
p_rt_subject_explicit <- 
  df_explicit_rt %>% 
  ggplot(aes(x = rt_explicit, fill = subjectid, color = subjectid)) +
  geom_density(alpha = .07) +
  scale_x_continuous(name = "Explicit task RT", breaks = breaks_pretty()) +
  scale_y_continuous(name = "Density") +
  coord_cartesian(
    xlim = c(380, 1700),
    ylim = c(0.0005, .01)
  ) +
  scale_fill_viridis_d(guide = NULL) +
  scale_color_viridis_d(guide = NULL)

p_rt_subject_implicit <-
  df_implicit_rt %>% 
  ggplot(aes(x = rt_implicit, fill = subjectid, color = subjectid)) +
  geom_density(alpha = .07) +
  scale_x_continuous(name = "Implicit task RT", breaks = breaks_pretty()) +
  scale_y_continuous(name = NULL) +
  theme(axis.text.y = element_blank()) +
  coord_cartesian(
    xlim = c(350, 1320),
    ylim = c(0.0005, .01)
  ) +
  scale_fill_viridis_d(guide = NULL) +
  scale_color_viridis_d(guide = NULL)

ggarrange(p_rt_subject_explicit, p_rt_subject_implicit)
```

# Inferential Analyses

## Model description (Multilevel modelling)

Our analyses aim to evaluate the predictive abilities of several variables on one outcome, the **response times** in the tasks. Our potential predictors are:

- **Group** membership, with two levels: aphantasia/phantasia

- Alternatively, **Visual imagery**, a standardized continuous variable

- **Spatial imagery**, a standardized continuous variable

- **Congruence** conditions, with two levels: congruent and incongruent

- **Color** conditions, with two levels: colored and uncolored.

- **Age**, a continuous variable ranging from 18 to 65 (M = `r mean(df_questionnaires$age) %>% round(digits = 2)`, SD = `r sd(df_questionnaires$age) %>% round(digits = 2)`)

Two sub-levels of the responses can also be evaluated:

- the dependency between response times for **each participant** caused by repeated measures

- the dependency between response times for **each orientation** caused by the repetition of stimuli

This structure will be modelled using Multilevel Models (also called hierarchical or mixed models), allowing us to add the sub-levels of the hierarchy of predictors we described above in the model. RT data will be transformed using a Box-Cox transformation to bring the distributions closer to normality and improve the quality of the models.

For a participant $i$ with a given Group, age, spatial imagery and a specific orientation, in the Congruency condition $j$ and the Color condition $k$, The maximal model of the resulting $RT_{ijk}$ based on the ***Group*** and including all the predictors can be specified as such (in a simplified form omitting the interaction parameters for clarity):

$$
\begin{aligned}
RT_{ijk} = \alpha + \alpha_{subject[i]} + \alpha_{orientation[i]} + \beta_{1} \times Group_{i} + \beta_{2} \times Spatial \ Imagery_{i}+ \beta_{3} \times Congruence_{j} + \beta_{4} \times Color_{k} + \beta_{5} \times Age_{i}
\end{aligned}
$$

Likewise, the maximal model based on ***Visual Imagery*** as a continuous predictor can be specified as such:

$$
\begin{aligned}
RT_{ijk} = \alpha + \alpha_{subject[i]} + \alpha_{orientation[i]} + \beta_{1} \times Visual \ Imagery_{i} + \beta_{2} \times Spatial \ Imagery_{i}+ \beta_{3} \times Congruence_{j} + \beta_{4} \times Color_{k} + \beta_{5} \times Age_{i}
\end{aligned}
$$

## Fitting the models

The mixed models will be fitted using `tidymodels` workflows.

```{r}
#| eval: false
#| include: false

# --- Setup --------------------------------------------------------------------

# --- preprocessing recipe for explicit data ---
rt_recipe_explicit <- 
  df_explicit_rt %>%
  select(-vviq80) %>% 
  recipe() %>%
  update_role(rt_explicit, new_role = "outcome") %>%
  update_role(
    subjectid, age, sex,
    aphantasia, visual_imagery, spatial_imagery,
    color, congruence, orientation,
    new_role = "predictor"
    ) %>%
  add_role(subjectid, orientation, new_role = "group") %>%
  step_normalize(age) %>% 
  step_BoxCox(rt_explicit)

# --- preprocessing recipe for implicit data ---
rt_recipe_implicit <- 
  df_implicit_rt %>%
  select(-vviq80) %>% 
  recipe %>%
  update_role(rt_implicit, new_role = "outcome") %>%
  update_role(
    subjectid, age, sex,
    aphantasia, visual_imagery, spatial_imagery,
    color, congruence, orientation,
    new_role = "predictor"
    ) %>%
  add_role(subjectid, orientation, new_role = "group") %>%
  step_normalize(age) %>% 
  step_BoxCox(rt_implicit)

# --- type of bayesian models to be fitted ---
# rt_model_bayes <-
#   bayesian (
#     family = skew_normal()
#   ) %>%
#   set_engine("brms") %>% 
#   set_mode("regression")

# ---type of mixed models to be fitted ---
rt_model_lmer <-
  linear_reg() %>% 
  set_engine("lmer")

# --- Specifying the models ----------------------------------------------------

# --- Group analyses ---
# 
# Explicit task

# model 1: maximal model specs
rt_ex_modg1 <-
  workflow () %>%
  add_recipe(rt_recipe_explicit) %>%
  add_model(
    spec = rt_model_lmer,
    formula = rt_explicit ~ aphantasia * congruence * color * spatial_imagery * age + (1|subjectid) + (1|orientation)
    )

# fitting
rt_ex_modg1_fit <- rt_ex_modg1 %>% fit(df_explicit_rt) %>% extract_fit_engine
# summary df
# rt_ex_modg1_fit %>% extract_fit_engine %>% report %>% as.data.frame %>% summary
# assumptions check
rt_ex_modg1_fit %>% check_model()

# model 2: intercepts
# rt_ex_modg2 <-
#   rt_ex_mod1 %>% 
#   update_model(
#     spec = rt_model_lmer,
#     formula = rt_explicit ~ aphantasia * congruence * color + (1|subjectid))

# --- Results ---
```








# Annexes

## Rotation task

Some quick analyses of the rotation task are summarised as visualizations in @fig-rotation.

```{r rotation}
#| label: fig-rotation
#| echo: false
#| fig-cap: "Analyses of the rotation task, including the distribution of errors between groups and correlations with the imagery variables."
#| fig-width: 11
#| fig-height: 7

# --- Annex: analysis of the rotation task -------------------------------------

# --- Number of errors - rotation task -----------------------------------------
p_rotation_errors <- 
  df_rotation %>%
  select(subjectid, correct_rotation, aphantasia) %>% 
  group_by(subjectid, aphantasia) %>% 
  count(correct_rotation) %>% 
  filter(correct_rotation == 1) %>% 
  mutate(n = 20 - n) %>% 
  ggplot(aes(
    x = n, 
    color = aphantasia,
    fill = aphantasia
    )) +
  geom_bar(
    aes(y = after_stat(prop)),
    position = position_dodge(),
    width = .8,
    alpha = .4
    ) +
  geom_density(aes(y = after_stat(density), color = NULL), alpha = .2) +
  scale_x_continuous(
    name = "Number of errors",
    breaks = breaks_pretty(n = 20)
    ) +
  scale_y_continuous(
    name = "Proportion of the group",
    breaks = breaks_pretty(n = 10)
    ) +
  coord_cartesian(
    xlim = c(0, 14),
    ylim = c(.01,.16)
    ) +
  labs(title = "Rotation task") +
  scale_color_okabeito(guide = NULL) +
  scale_fill_okabeito(name = "Aphantasia", labels = c("Yes", "No")) +
  theme(legend.position = "top")

# --- Correlation between rotation correct and spatial imagery -----------------
p_rotation_cor_spa <- 
  df_rotation %>% 
  select(subjectid, correct_rotation, spatial_imagery) %>% 
  group_by(subjectid) %>% 
  summarise(
    correct_perc = sum(correct_rotation)/20,
    mean_s = mean(spatial_imagery)
  ) %>% 
  standardize(correct_perc) %>% 
  cor_test("mean_s", "correct_perc", bayesian = TRUE) %>% 
  plot +
  labs(x = "Spatial imagery", y = "Correct responses")

# --- Correlation between rotation correct and visual imagery ------------------
p_rotation_cor_vis <- 
  df_rotation %>% 
  select(subjectid, correct_rotation, visual_imagery) %>% 
  group_by(subjectid) %>% 
  summarise(
    correct_perc = sum(correct_rotation)/20,
    mean_v = mean(visual_imagery)
  ) %>% 
  standardize(correct_perc) %>% 
  cor_test("mean_v", "correct_perc", bayesian = TRUE) %>% 
  plot +
  labs(x = "Visual imagery", y = "Correct responses")

# --- Correlation between rotation correct and vviq ----------------------------
p_rotation_cor_vviq <-
  df_rotation %>% 
  select(subjectid, correct_rotation, vviq80) %>% 
  group_by(subjectid) %>% 
  summarise(
    correct_perc = sum(correct_rotation)/20,
    vviq = mean(vviq80)
  ) %>% 
  standardize(select = c("vviq", "correct_perc")) %>% 
  cor_test("vviq", "correct_perc", bayesian = TRUE) %>% 
  plot +
  labs(x = "VVIQ", y = "Correct responses")

ggarrange(
  p_rotation_errors, 
  p_rotation_cor_vis, 
  p_rotation_cor_vviq, 
  p_rotation_cor_spa + rremove("ylab")
  )
```





















