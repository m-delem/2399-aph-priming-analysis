
```{r importing_data}

# ═══ Importing and keeping only "extreme" VVIQs ═══════════════════════════════

# Implicit task
df_implicit <- 
  read_excel(
    "data/aphantasia_priming_tidy_data.xlsx",
    sheet = "data_implicit"
    ) |> 
  rename("rt" = rt_implicit) |> 
  # convert to seconds
  mutate(rt = rt/1000)

# Explicit task
df_explicit <- 
  read_excel(
    "data/aphantasia_priming_tidy_data.xlsx",
    sheet = "data_explicit"
    ) |> 
  rename("rt" = rt_explicit) |> 
  # convert to seconds
  mutate(rt = rt/1000)

# Questionnaires
df_questionnaires <- 
  read_excel(
    "data/aphantasia_priming_tidy_data.xlsx",
    sheet = "data_questionnaires"
    ) |>  
  # creating the a/phantasia groups
  mutate(
    aphantasia = ifelse(vviq80 < 32, "yes", "no"),
    aphantasia = fct_relevel(aphantasia, "yes", "no")
    ) |>
  filter(vviq80 <= 16.5 | vviq80 >= 42)

# updating all the dataframes with the questionnaires data
dfs <- 
  list(
    implicit_task = df_implicit, 
    explicit_task = df_explicit
    ) |> 
  # adding the vviq and group column to every dataframe
  imap(~right_join(
    .x, 
    df_questionnaires |>  
      select(
        # column to match with the correct participants
        subjectid, 
        # new variables to add
        age,
        sexe,
        vviq80,
        aphantasia), by = "subjectid") |>  
      rename("sex" = sexe) |>  
      # reordering the final dfs
      select(
        subjectid, 
        age, sex, aphantasia,
        vviq80,
        everything())
    )

df_implicit <- dfs$implicit_task
df_explicit <- dfs$explicit_task
rm(dfs)
```

```{r finding_and_removing_accuracy_outliers}
#| code-summary: "Removing incorrect trials and task-wise accuracy outliers"
#| echo: true
#| output: false

# ═══ Accuracy outliers analysis ═══════════════════════════════════════════════

# ─── Listing error rates per subject ───
list(df_explicit, df_implicit) |> 
  imap(
    ~.x |> 
      select(subjectid, starts_with("correct"), aphantasia) |> 
      group_by(subjectid) |> 
      count(pick(2)) |> 
      filter(pick(1) == 1) |> 
      ungroup() |> 
      mutate(
        n_tot = max(n),
        prop = (n_tot - n) / n_tot * 100  # analyzing the error rate per subject
      ) %>%
      arrange(desc(prop)) |> 
      select(1, 5)
    )
# 5 accuracy outliers in the explicit task, 4 in the implicit one

# ─── Removing incorrect trials and task-wise accuracy outliers ───
df_explicit_rt <-
  df_explicit |> 
  # filtering out...
  filter(
    # incorrect trials
    correct_explicit == 1 &
    # participants identified with with high error rates
    !(subjectid %in% c( 
      "aknezevic",
      "lbrunie", 
      "agayou", 
      "bluciani",
      "ldossantos"))
    ) |>  
  # removing irrelevant variables
  select(-c(sex, vviq80, orientation, response, correct_explicit))

# percentage of trials removed in the explicit task
(count(df_explicit) - count(df_explicit_rt)) / count(df_explicit)
# 9091 trials left = 5.9% removed

df_implicit_rt <- 
  df_implicit |>  
  filter(
    correct_implicit == 1 &
    !(subjectid %in% c( 
      "bdispaux", 
      "eleveque", 
      "aleclaire", 
      "dchimenton"))
      ) |>  
  select(-c(sex, vviq80, orientation, response, correct_implicit))

# percentage of trials removed in the implicit task
(count(df_implicit) - count(df_implicit_rt)) / count(df_implicit) 
# 9078 trials left = 6.1% removed
```

```{r}
#| code-summary: "Removing extreme RTs"
#| echo: true
#| output: false

# ═══ First broad RT outlier trials removal ════════════════════════════════════

df_explicit_rt <- 
  df_explicit_rt |>  
  # filtering out extreme RTs
  filter(rt > .25 & rt < 2)

# total percentage of trials removed in the explicit task
(count(df_explicit) - count(df_explicit_rt)) / count(df_explicit)
# 8812 trials left = 8.8% removed

df_implicit_rt <- 
  df_implicit_rt |>  
  filter(rt > .25 & rt < 2)

# total percentage of trials removed in the implicit task
(count(df_implicit) - count(df_implicit_rt)) / count(df_implicit)
# 8963 left = 7.3% removed
```

```{r fitting_glmms}
#| output: false
 
# ═══ Fitting Generalized Linear Mixed Models in parallel ══════════════════════

# ─── Preparing variable roles ─────────────────────────────────────────────────
model_recipe_glmm_ex <- 
  df_explicit_rt |> 
  recipe() |> 
  update_role(rt, new_role = "outcome") %>%
  update_role(
    subjectid, age, aphantasia, color, congruence, 
    new_role = "predictor"
  ) |> 
  add_role(subjectid, new_role = "group")

model_recipe_glmm_im <- 
  df_implicit_rt |> 
  recipe() |> 
  update_role(rt, new_role = "outcome") %>%
  update_role(
    subjectid, age, aphantasia, color, congruence, 
    new_role = "predictor"
  ) |> 
  add_role(subjectid, new_role = "group")

# ─── Specifying the distributions for the models ──────────────────────────────

# GLMM, Gamma distribution, identity link
glmm_gamma_id <-
  linear_reg() |> 
  set_engine(
    "glmer",
    family = Gamma(link = "identity")
  )

# GLMM, Inverse Gaussian distribution, identity link
glmm_inverse_id <-
  linear_reg() |> 
  set_engine(
    "glmer",
    family = inverse.gaussian(link = "identity")
  )

# GLMM, Inverse Gaussian distribution, log link
glmm_inverse_log <-
  linear_reg() |> 
  set_engine(
    "glmer",
    family = inverse.gaussian(link = "log")
  )

# LMM = GLMM with a Gaussian distribution and identity link
glmm_gaussian <-
  linear_reg() |> 
  set_engine("lmer")

# Listing these models
# GLMMs
model_specs_glmm <- list(
  # glmm_gamma_id    = glmm_gamma_id,
  glmm_inverse_id  = glmm_inverse_id,
  glmm_inverse_log = glmm_inverse_log
  # glmm_gaussian    = glmm_gaussian
)

# ─── Writing down the formulas of our models ──────────────────────────────────
# null model
formula_0 <- rt ~ (1|subjectid)
# intercept by-participant only
formula_1 <- rt ~ (aphantasia + congruence + color)^3 + (1|subjectid)
# intercept and slope on congruence by-participant
formula_2 <- rt ~ (aphantasia + congruence + color)^3 + (congruence|subjectid)
# intercept and slope on color by-participant
formula_3 <- rt ~ (aphantasia + congruence + color)^3 + (color|subjectid)
# intercept and slope on congruence and color by-participant
formula_4 <- rt ~ (aphantasia + congruence + color)^3 + (congruence + color|subjectid)

# Listing these formulas
model_formulas <- list(
  # formula_0 = formula_0,
  # formula_1 = formula_1,
  # formula_2 = formula_2,
  # formula_3 = formula_3,
  formula_4 = formula_4
  )

# ─── Table to combine everything in workflows and fit the models ──────────────
# (
model_all_workflows_fitted <- 
  tribble(       ~recipe,     ~ task,           ~model,       ~formula,
    model_recipe_glmm_ex, "explicit", model_specs_glmm, model_formulas,
    model_recipe_glmm_im, "implicit", model_specs_glmm, model_formulas
  ) |> 
  # combining recipes with models
  unnest_longer(model) |> 
  # combining them with formulas
  unnest_longer(formula) |>
  rowwise() |>
  mutate(
    # creating workflows
    workflow = list(
      workflow() |>
      add_recipe(recipe) |> 
      add_model(model, formula = formula)  
      )
  )

# ─── Fitting the models with parallel processing ──────────────────────────────

# finding the available cores for parallel processing
n_cores <- parallel::detectCores() - 1

# creating the cluster of cores
parallel_cluster <- 
  parallel::makeCluster(
    n_cores,
    type = "PSOCK"
  )

# registering the cluster for `foreach`
doParallel::registerDoParallel(cl = parallel_cluster)
# checking
# foreach::getDoParRegistered()
# foreach::getDoParWorkers()

# creating a new list-column with all the models fitted in parallel
(model_all_workflows_fitted$fitted_model <-
  foreach(
    workflow = model_all_workflows_fitted$workflow,
    task     = model_all_workflows_fitted$task,
    .combine  = "c",
    .packages = c("tidymodels", "multilevelmod")
) %dopar% {
  if(task == "explicit"){
    model_fit <-
      list(
        workflow |> 
        fit(data = df_explicit_rt) |> 
        extract_fit_engine()
      )
  }
  
  else{
    model_fit <-
      list(
        workflow |> 
        fit(data = df_implicit_rt) |> 
        extract_fit_engine()
      )
  }
  
  return(model_fit)
# measuring runtime for benchmarking
}) |> system.time() -> time_parallel

model_all_workflows_fitted <-  
  model_all_workflows_fitted |> 
  select(-c(recipe, model, formula, workflow))

# ─── Examining the quality of the models, estimating the parameters ───────────
model_all_workflows_fitted$parameters <-
  foreach(
    fitted_model = model_all_workflows_fitted$fitted_model,
    .combine  = "c",
    .packages = c("parameters")
) %dopar% {
  parameters <- list(model_parameters(fitted_model))
  return(parameters)
}

model_all_workflows_fitted$convergence <-
  foreach(
    fitted_model = model_all_workflows_fitted$fitted_model,
    .combine  = "c",
    .packages = c("performance")
) %dopar% {
  convergence <- check_convergence(fitted_model)
  return(convergence)
}

model_all_workflows_fitted$model_perf <-
  foreach(
    fitted_model = model_all_workflows_fitted$fitted_model,
    .combine  = "c",
    .packages = c("performance")
) %dopar% {
  model_perf <- list(model_performance(fitted_model))
  return(model_perf)
}

model_all_workflows_fitted <-
  model_all_workflows_fitted |>
  mutate(
    # extracting model quality indices
    AIC  = model_perf[[1]],
    AICc = model_perf[[2]],
    BIC  = model_perf[[3]]
  ) |>
  ungroup() |> 
  select(-model_perf)

# stopping the cluster when we're done
parallel::stopCluster(cl = parallel_cluster)

# 214 seconds (3min30s)

# ─── Comparing the models' quality among those that converged ─────────────────
model_selection <-
  model_all_workflows_fitted |> 
  filter(
    formula_id != "formula_0" #& 
    # convergence == TRUE
  ) |> 
  group_by(task, model_id) |> 
  mutate(best_model = ifelse(AICc == min(AICc), TRUE, FALSE)) |> 
  filter(best_model == TRUE)
```

```{r}
# best_glmm_explicit <- model_selection$fitted_model[[2]]
# best_glmm_implicit <- model_selection$fitted_model[[6]]

# saveRDS(
#   best_glmm_explicit, 
#   "analyses-results/glmm_floor_inverse_id_explicit.RDS") # readRDS to import
# saveRDS(
#   best_glmm_implicit, 
#   "analyses-results/glmm_floor_inverse_id_implicit.RDS")
```

```{r}
# ═══ Post-hoc tests: unstandardized effect sizes ══════════════════════════════

# glmm_ex <- readRDS(file = "analyses-results/02-glmm-floor-inverse-id-explicit.RDS")

# glmm_floor_explicit_contrasts <-
#   emmeans(
#     glmm_ex, 
#     ~color, 
#     adjust = "tukey"
#   ) |> 
#   pairs()
  # plot()

# saveRDS(
#   glmm_floor_explicit_contrasts,
#   "analyses-results/02-glmm-floor-explicit-contrasts.RDS") # readRDS to import

```



























