---
title: "Sensory priming in aphantasia - Data analysis report"
author: "Maël Delem"
date: 2023-11-03
date-modified: last-modified
date-format: "D/MM/YYYY"
format: html
editor: source
editor_options: 
  
  chunk_output_type: inline
toc: true
toc-depth: 3
toc-expand: 2
number-sections: true
number-depth: 2
---

<!-- CSS options for custom title numbers styling-->

```{=html}
<style>
.header-section-number:after {
  content: ". ";
}
</style>
```
### Preliminary Set-up {.unnumbered}

::: {.callout-note collapse="true" appearance="simple"}
#### Datasets, code availability, software and setup

The code generating all the computations, figures, tables, etc. (only partially exposed here for clarity) can be found in the `analysis_report.qmd` file, for which the best reading software are coding Integrated Development Environments (IDE) like [RStudio](https://posit.co/download/rstudio-desktop/) or [Visual Studio Code](https://code.visualstudio.com/). The file includes detailed commentaries along with the code to ease understanding, accessibility, and potential (welcome) criticism.

This analysis was conducted in R language on [RStudio](https://posit.co/download/rstudio-desktop/). This analysis report was written with [Quarto](https://quarto.org/). Down below is the set-up code, including two essential steps:

1.  Installing the required packages for this data analysis

2.  importing data into the dataframes used throughout.

```{r setup}
#| echo: true
#| output: false
#| code-summary: "Packages"

# ═══ Packages ═════════════════════════════════════════════════════════════════

# The package `librairian` will ease the package management with the "shelf" 
# function, which automatically: 
# 1) checks if a package is installed 
# 2) installs it if need be
# 3) loads the package like the "library()" function would.
if (!require(librarian)) install.packages(librarian)
library(librarian)

# now putting packages on our library's shelves:
shelf(
  # ─── essential package collections ───
  tidyverse,      # modern R ecosystem
  easystats,      # data analysis framework
  tidymodels,     # modelling framework
  doParallel,     # parallel execution
  
  # ─── tidymodels friends ──────────────
  corrr,          # correlational analyses
  tidybayes,      # bayesian inference
  multilevelmod,  # multilevel modelling with lmer and tidymodels
  
  # ─── modelling ───────────────────────
  lme4,           # mixed models
  mclust,         # mixture clustering
  rstanarm,       # bayesian models
  BayesFactor,    # BFs
  emmeans,        # marginal estimates
  statmod,        # easystats dependency
  
  # ─── data management ─────────────────
  readxl,         # importing xlsx
  openxlsx,       # exporting xlsx
  
  #  data visualization ──────────────
  # plot types and geoms
  ricardo-bion/ggradar,  # radar plots
  ggbeeswarm,            # scatter violin plots
  GGally,         # complex plots
  # layout and options
  ggpubr,         # publication plots
  patchwork,      # layout control
  rstatix,        # ggplot stat tools
  # palettes
  ggsci,          # scientific palettes
  viridis,        # colour-blind friendly palettes
  # interactive
  plotly         # interactive plots
)

# ─── Global cosmetic theme ───q
theme_set(theme_bw(base_size = 14))

# ─── Fixing a seed for reproducibility ───
set.seed(14051998)
```

```{r importing_data}
#| echo: true
#| output: false
#| code-summary: "Importing data"

# Implicit task
df_implicit <- 
  read_excel(
    "data/aphantasia_priming_tidy_data.xlsx",
    sheet = "data_implicit"
    ) |> 
  rename("rt" = rt_implicit)

# Explicit task
df_explicit <- 
  read_excel(
    "data/aphantasia_priming_tidy_data.xlsx",
    sheet = "data_explicit"
    ) |> 
  rename("rt" = rt_explicit)

# Questionnaires
df_questionnaires <- 
  read_excel(
    "data/aphantasia_priming_tidy_data.xlsx",
    sheet = "data_questionnaires"
    ) %>% 
  # creating the a/phantasia groups
  mutate(
    aphantasia = ifelse(vviq80 < 32, "yes", "no"),
    aphantasia = fct_relevel(aphantasia, "yes", "no")
    )

# updating all the dataframes with the questionnaires data
dfs <- 
  list(
    implicit_task = df_implicit, 
    explicit_task = df_explicit
    ) |> 
  # adding the vviq and group column to every dataframe
  imap(~left_join(
    .x, 
    df_questionnaires |>  
      select(
        # column to match with the correct participants
        subjectid, 
        # new variables to add
        age,
        sexe,
        vviq80,
        aphantasia), by = "subjectid") |>  
      rename("sex" = sexe) |>  
      # reordering the final dfs
      select(
        subjectid, 
        age, sex, aphantasia,
        vviq80,
        everything())
    )

df_implicit <- dfs$implicit_task
df_explicit <- dfs$explicit_task
rm(dfs)
```
:::

::: {.callout-tip collapse="true" appearance="simple"}
#### Interactive figures

Many figures in this report are interactive: hover over the plots to see some of the tools available. You can select a zone to zoom on a plot, hover over bars to see details about data, select only specific groups in the legend, among many other features.
:::

# Exploratory Data Analysis (EDA) {#sec-eda}

## Accuracy

The distribution of the percentages of errors across the two tasks is displayed in @fig-tasks_errors, and [-@fig-tasks_errors2].

::: panel-tabset
#### Explicit task accuracy

```{r tasks_errors_plotly_explicit}
#| label: fig-tasks_errors
#| fig-cap: "Distribution of errors between groups in the explicit task."
#| out-width: 100%
#| fig-height: 4

# ═══ Percentage of errors plot - Explicit task ════════════════════════════════

(df_explicit |> 
  select(subjectid, correct_explicit, aphantasia) |> 
  group_by(subjectid, aphantasia) |>  
  count(correct_explicit) |>  
  filter(correct_explicit == 1) |> 
  mutate(n = (64 - n)/64 * 100) |>  
  ggplot(aes(
    x = n, 
    color = aphantasia,
    fill = aphantasia
    )) +
  geom_bar(
    aes(y = after_stat(prop)),
    position = position_dodge(),
    width = .6,
    alpha = .6
    ) +
  scale_x_continuous(
    name = "Percentage of errors",
    breaks = breaks_pretty(n = 20)
    ) +
  scale_y_continuous(
    name = "Proportion of the group",
    breaks = breaks_pretty(n = 10)
    ) +
  coord_cartesian(
    xlim = c(1, 46),
    ylim = c(.01,.36)
    ) +
  # labs(title = "Explicit task") +
  scale_color_okabeito(guide = NULL) +
  scale_fill_okabeito(name = "Aphantasia", labels = c("Yes", "No"))) |>  
  # plotly-ing it
  ggplotly()
```

#### Implicit task accuracy

```{r tasks_errors_plotly_implicit}
#| label: fig-tasks_errors2
#| fig-cap: "Distribution of errors between groups in the implicit task."
#| out-width: 100%
#| fig-height: 4

# ═══ Percentage of errors plot - Implicit task ════════════════════════════════

(df_implicit |> 
  select(subjectid, correct_implicit, aphantasia) |>  
  group_by(subjectid, aphantasia) |>  
  count(correct_implicit) |>  
  filter(correct_implicit == 1) |>  
  mutate(n = (64 - n)/64 * 100) |>  
  ggplot(aes(
    x = n, 
    color = aphantasia,
    fill = aphantasia
    )) +
  geom_bar(
    aes(y = after_stat(prop)),
    position = position_dodge(),
    width = .6,
    alpha = .6
    ) +
  scale_x_continuous(
    name = "Percentage of errors",
    breaks = breaks_pretty(n = 20)
    ) +
  scale_y_continuous(
    name = "Proportion of the group",
    breaks = breaks_pretty(n = 10)
    ) +
  coord_cartesian(
    xlim = c(1, 40),
    ylim = c(.01,.28)
    ) +
  # labs(title = "Implicit task") +
  scale_color_okabeito(guide = NULL) +
  scale_fill_okabeito(name = "Aphantasia", labels = c("Yes", "No"))) |>  
  # plotly-ing it
  ggplotly()
```
:::

We are going to remove missed trials in the analyses of the RTs. Nonetheless, the main noticeable aspect of these plots are the obvious outliers in each of the tasks. This information is crucial as it could reflect a wrong understanding of the task, or random responses: in any case, participants that have high error rates would require a deletion of up to 47% of their trials, which could become a bias in the modelling of the overall data. As there appear to be a cut-off of the main distribution around 16% of errors in all tasks, this value will be chosen as threshold. **For each task separately, the results of participants with an error rate superior to 16% will be removed** *(i.e., five participants in the explicit task and four in the implicit task)***, prior to removing all the missed trials of the remaining participants for modelling RTs.**

```{r finding_and_removing_accuracy_outliers}
#| code-summary: "Removing incorrect trials and task-wise accuracy outliers"
#| echo: true
#| output: false

# ═══ Accuracy outliers analysis ═══════════════════════════════════════════════

# ─── Listing error rates per subject ───
list(df_explicit, df_implicit) |> 
  imap(
    ~.x |> 
      select(subjectid, starts_with("correct"), aphantasia) |> 
      group_by(subjectid) |> 
      count(pick(2)) |> 
      filter(pick(1) == 1) |> 
      ungroup() |> 
      mutate(
        n_tot = max(n),
        prop = (n_tot - n) / n_tot * 100  # analyzing the error rate per subject
      ) %>%
      arrange(desc(prop)) |> 
      select(1, 5)
    )
# 5 accuracy outliers in the explicit task, 4 in the implicit one

# ─── Removing incorrect trials and task-wise accuracy outliers ───
df_explicit_rt <-
  df_explicit |> 
  # filtering out...
  filter(
    # incorrect trials
    correct_explicit == 1 &
    # participants identified with with high error rates
    !(subjectid %in% c( 
      "aknezevic",
      "bdispaux", 
      "lbrunie", 
      "eleveque", 
      "agayou", 
      "bluciani",
      "ldossantos", 
      "aleclaire", 
      "dchimenton"))
    ) |>  
  # removing irrelevant variables
  select(-c(sex, vviq80, orientation, response, correct_explicit))

# percentage of trials removed in the explicit task
(count(df_explicit) - count(df_explicit_rt)) / count(df_explicit)
# 8842 trials left = 8.5% removed

df_implicit_rt <- 
  df_implicit |>  
  filter(
    correct_implicit == 1 &
    !(subjectid %in% c( 
      "aknezevic",
      "bdispaux", 
      "lbrunie", 
      "eleveque", 
      "agayou", 
      "bluciani",
      "ldossantos", 
      "aleclaire", 
      "dchimenton"))
      ) |>  
  select(-c(sex, vviq80, orientation, response, correct_implicit))

# percentage of trials removed in the implicit task
(count(df_implicit) - count(df_implicit_rt)) / count(df_implicit) 
# 8765 trials left = 9.3% removed
```

## Response times

### Extreme RTs

As a preprocessing, response times below 300ms and above 3000ms will be removed as they could represent false alarms.

```{r removing_extreme_rt_outlier_trials}
#| code-summary: "Removing extreme RTs"
#| echo: true
#| output: false

# ═══ First broad RT outlier trials removal ════════════════════════════════════

df_explicit_rt <- 
  df_explicit_rt |>  
  # filtering out extreme RTs
  filter(rt > 300 & rt < 3000)

# total percentage of trials removed in the explicit task
(count(df_explicit) - count(df_explicit_rt)) / count(df_explicit)
# 8753 trials left = 9.4% removed

df_implicit_rt <- 
  df_implicit_rt |>  
  filter(rt > 300 & rt < 3000)

# total percentage of trials removed in the implicit task
(count(df_implicit) - count(df_implicit_rt)) / count(df_implicit)
# 8706 left = 9.9% removed
```

### Aberrant RT means

A first level of the RT outliers analysis is based on the overall mean RT of the participants. Participants with abnormally high RT means could represent various specific situations out of the range of our study: pathological conditions, attention deficits, or even more trivially low attention to the task. Such participants could bias both the overall results *and the analysis of the individual trials*: just like the accuracy outliers, the removal of their slow trials could result in a deletion of a large part of their responses, thus biasing the distributions. Let's visualize the distribution of the RT means in @fig-rt_means1 and [-@fig-rt_means2]

::: panel-tabset
#### Explicit task RT means

```{r explicit_task_rt_means_plotly}
#| label: fig-rt_means1
#| fig-cap: "Distribution of the mean RTs of participants in the explicit task (very high RT means have been cut for better readability)."
#| fig-height: 4

# ═══ RT means plot - Explicit task ════════════════════════════════════════════

(df_explicit_rt |>  
  group_by(subjectid) |>  
  summarise(mean = mean(rt)) |>  
  ggplot(aes(x = mean)) +
  geom_histogram(
    fill = "aquamarine2", 
    color = "aquamarine4", 
    alpha = .3,
    bins = 70
    # adjust = .4
    ) +
  labs(x = "Mean RT", y = "Number of participants") +
  scale_y_continuous(breaks = seq(0, 13, by = 1))) |>  
  ggplotly()
```

#### Implicit task RT means

```{r implicit_task_rt_means_plotly}
#| label: fig-rt_means2
#| fig-cap: "Distribution of the mean RTs of participants in the implicit task (very high RT means have been cut for better readability)."
#| fig-height: 4

# ═══ RT means plot - Implicit task ════════════════════════════════════════════

(df_implicit_rt |> 
  group_by(subjectid) |>  
  summarise(mean = mean(rt)) |>  
  ggplot(aes(x = mean)) +
  geom_histogram(
    fill = "coral2", 
    color = "coral4", 
    alpha = .3,
    bins = 70
    # adjust = .4
    ) +
  labs(x = "Mean RT", y = "Number of participants") +
  scale_y_continuous(breaks = seq(0, 9, by = 1))) |>  
  ggplotly()
```

#### RT means table

```{r rt_means_table}
#| label: tbl-rt_means
#| tbl-cap: "Descriptive statistics of the average RTs across the sample in both tasks."

# ═══ RT means table - Both tasks ══════════════════════════════════════════════

df_rt <- 
  list(
  df_explicit_rt |>  rename("Explicit task mean RTs" = rt), 
  df_implicit_rt |>  rename("Implicit task mean RTs" = rt)
  ) |>  
  imap(
    ~select(.x, contains("RT")) |> 
      report() |>  
      as.data.frame() |>  
      select(1:10)
    )

df_rt <- bind_rows(df_rt[[1]], df_rt[[2]])
df_rt |>  display()
```
:::

The median RT mean among participants is `r df_rt$Median[1]` in the explicit task, and `r df_rt$Median[2]` in the implicit one. Using an outlier detection procedure based on MADs, a common scaling factor to determine acceptable values is $\pm 3 \times MAD$: as 300ms is our chosen minimal value, this would result in our case in an acceptable range (in ms) of \[300,`r round(df_rt$Median[1] + 3*df_rt$MAD[1])`\] for the explicit task and \[300,`r round(df_rt$Median[2] + 3*df_rt$MAD[2])`\] for the implicit task.

```{r removing_rt_means_outliers}
#| code-summary: "Removing outliers with aberrant RT means"
#| echo: true
#| output: false

# ═══ Aberrant RT means outliers removal ═══════════════════════════════════════

# ─── Finding outliers ───

df_explicit_rt |> 
  group_by(subjectid) |> 
  summarise(mean_rt_explicit = mean(rt)) |> 
  ungroup() |> 
  filter(mean_rt_explicit > 1373) |> 
  arrange(desc(mean_rt_explicit))
# 7 outliers in the explicit task

df_implicit_rt |> 
  group_by(subjectid) |> 
  summarise(mean_rt_implicit = mean(rt)) |> 
  ungroup() |> 
  filter(mean_rt_implicit > 1063) |> 
  arrange(desc(mean_rt_implicit))
# 4 outliers in the implicit task

# ─── Removing specific outliers ───

df_explicit_rt <- 
  df_explicit_rt |> 
  filter(
    !(subjectid %in% c(
      "fc",
      "mbilodeau",
      "llhermitte",
      "hmassot",
      "mbillon",
      "nnguyenphuoc",
      "rcarnez",
      "cbertrand",
      "omeyer"
    ))
  )

# 133 participants and 8229 trials left
# (9664-8229)/9664 # 14.8% out
# alternative point of view: 18 participants excluded in the explicit task due to high error rates or overall abnormally slow RTs.

df_implicit_rt <-
  df_implicit_rt |> 
  filter(
    !(subjectid %in% c(
      "fc",
      "mbilodeau",
      "llhermitte",
      "hmassot",
      "mbillon",
      "nnguyenphuoc",
      "rcarnez",
      "cbertrand",
      "omeyer"
    ))
  )

# 133 partcipants and 8166 trials left
# (9664-8166)/9664 # 15.5% out
# alternative point of view: 18 participants excluded in the implicit task due to high error rates or overall abnormally slow RTs.
```

In the end, 18 participants have been excluded due to high error rates or overall abnormally slow RTs. Let's visualize the RT means distributions again in @fig-rt_means3 and [-@fig-rt_means4].

::: panel-tabset
#### Tidied explicit task RT means

```{r final_explicit_task_rt_means_plotly}
#| label: fig-rt_means3
#| fig-cap: "Distribution of the mean RTs of participants in the explicit task after outlier removal."
#| fig-height: 4

# ═══ RT means final plot - Explicit task ══════════════════════════════════════

(df_explicit_rt |>  
  group_by(subjectid) |>  
  summarise(mean = mean(rt)) |>  
  ggplot(aes(x = mean)) +
  geom_histogram(
    fill = "aquamarine2", 
    color = "aquamarine4", 
    alpha = .3,
    bins = 70
    # adjust = .4
    ) +
  labs(x = "Mean RT", y = "Number of participants") +
  scale_y_continuous(breaks = seq(0, 13, by = 1))) |>  
  ggplotly()
```

#### Tidied implicit task RT means

```{r final_implicit_task_rt_means_plotly}
#| label: fig-rt_means4
#| fig-cap: "Distribution of the mean RTs of participants in the implicit task after outlier removal."
#| fig-height: 4

# ═══ RT means final plot - Implicit task ══════════════════════════════════════

(df_implicit_rt |> 
  group_by(subjectid) |>  
  summarise(mean = mean(rt)) |>  
  ggplot(aes(x = mean)) +
  geom_histogram(
    fill = "coral2", 
    color = "coral4", 
    alpha = .3,
    bins = 70
    # adjust = .4
    ) +
  labs(x = "Mean RT", y = "Number of participants") +
  scale_y_continuous(breaks = seq(0, 9, by = 1))) |>  
  ggplotly()
```
:::

The distributions are still positively skewed, yet in more acceptable ranges for the phenomena we are investigating.

### Outlier trials per participant

We will conduct a more detailed inspection of the RTs on a by-participant level. The RT distributions per participant in each task are presented in @fig-rt_per_participant_1 and [-@fig-rt_per_participant_2].

::: {.panel-tabset .column-page-inset-right}
#### Explicit task RT per participant

```{r explicit_rt_per_participant_plotly}
#| label: fig-rt_per_participant_1
#| fig-cap: "Distribution of RTs in the explicit task for each participant. Each colored distribution represents a single participant. *Hover to see details on the individual distributions*."
#| fig-height: 5

# ═══ RTs per participant plot - Explicit task ═════════════════════════════════

(df_explicit_rt |>  
  ggplot(aes(x = rt, fill = subjectid)) +
  geom_density(alpha = .25, color = "black") +
  scale_x_continuous(name = "Response time", breaks = breaks_pretty(10)) +
  scale_y_continuous(name = "Density") +
  theme(
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank()
    ) +
  # coord_cartesian(
  #   xlim = c(380, 1700),
  #   ylim = c(0.0005, .01)
  # ) +
  scale_fill_viridis_d(guide = NULL) +
  scale_color_viridis_d(guide = NULL)) |>  
  ggplotly() |>  
  style(showlegend = FALSE)
```

#### Implicit task RT per participant

```{r implicit_rt_per_participant_plotly}
#| label: fig-rt_per_participant_2
#| fig-cap: "Distribution of RTs in the implicit task for each participant. Each colored distribution represents a single participant. *Hover to see details on the individual distributions*."
#| fig-height: 5

# ═══ RTs per participant plot - Implicit task ═════════════════════════════════

(df_implicit_rt |>  
  ggplot(aes(x = rt, fill = subjectid)) +
  geom_density(alpha = .25, color = "black") +
  scale_x_continuous(name = "Response time", breaks = breaks_pretty(5)) +
  scale_y_continuous(name = "Density") +
  theme(
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank()
    ) +
  # coord_cartesian(
  #   xlim = c(350, 1320),
  #   ylim = c(0.0005, .01)
  # ) +
  scale_fill_viridis_d(guide = NULL) +
  scale_color_viridis_d(guide = NULL)) |>  
  ggplotly() |>  
  style(showlegend = FALSE)
```
:::

As expected, most of the participants have a small amount of very slow outlier trials, even by their own standards of RT. Once again, we are going to detect these outliers using MAD thresholds. The RTs have been group by subsets of conditions, as we know that our experimental conditions could have affected them: thus, using a global median would necessarily flatten within-participant outcomes and have a major impact on the analyses.

```{r removing_rt_outlier_trials_per_participant}
#| code-summary: "Removing outlier trials by-participant"
#| echo: true
#| output: false

# ═══ By-participant MAD outlier detection ═════════════════════════════════════

# ─── Explicit task: ───
# From 8229 observations
# 3 MADs threshold
df_explicit_rt <-
  df_explicit_rt |> 
  group_by(subjectid, congruence) |> 
  mutate(
    rt_median = median(rt),
    rt_mad = mad(rt)
    ) |> 
  filter(
    rt < rt_median + 3 * rt_mad &
    rt > rt_median - 3 * rt_mad
  ) |>
  ungroup()
# 7687 trials left
# (8229-7687)/8229 # 6.6% trials out

# ─── Implicit task: ───
# From 8166 observations
# 3 MADs threshold
df_implicit_rt <-
  df_implicit_rt |> 
  group_by(subjectid, congruence) |> 
  mutate(
    rt_median = median(rt),
    rt_mad = mad(rt)
    ) |> 
  filter(
    rt < rt_median + 3 * rt_mad &
    rt > rt_median - 3 * rt_mad
  ) |>
  ungroup()
# 7489 trials left
# (8166-7489)/8166 # 8.2% trials out
```

The range defined by $\pm 3 \times MAD$ resulted in a deletion of 6.6% of trials in the explicit task and 8.2% of trials in the implicit task. Let's visualize the final distribution of RTs for each participant in @fig-rt_per_participant_3 and [-@fig-rt_per_participant_4]

::: {.panel-tabset .column-page-inset-right}
#### Tidied explicit task RT per participant

```{r final_explicit_rt_per_participant_plotly}
#| label: fig-rt_per_participant_3
#| fig-cap: "Resulting distribution of RTs in the explicit task for each participant. Each colored distribution represents a single participant. *Hover to see details on the individual distributions*."
#| fig-height: 5

# ═══ RTs per participant final plot - Explicit task ═══════════════════════════

(df_explicit_rt |>  
  ggplot(aes(x = rt, fill = subjectid)) +
  geom_density(alpha = .25, color = "black") +
  scale_x_continuous(name = "Response time", breaks = breaks_pretty(10)) +
  scale_y_continuous(name = "Density") +
  theme(
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank()
    ) +
  # coord_cartesian(
  #   xlim = c(380, 1700),
  #   ylim = c(0.0005, .01)
  # ) +
  scale_fill_viridis_d(guide = NULL) +
  scale_color_viridis_d(guide = NULL)) |>  
  ggplotly() |>  
  style(showlegend = FALSE)
```

#### Tidied implicit task RT per participant

```{r final_implicit_rt_per_participant_plotly}
#| label: fig-rt_per_participant_4
#| fig-cap: "Resulting distribution of RTs in the implicit task for each participant. Each colored distribution represents a single participant. *Hover to see details on the individual distributions*."
#| fig-height: 5

# ═══ RTs per participant final plot - Implicit task ═══════════════════════════

(df_implicit_rt |>  
  ggplot(aes(x = rt, fill = subjectid)) +
  geom_density(alpha = .25, color = "black") +
  scale_x_continuous(name = "Response time", breaks = breaks_pretty(5)) +
  scale_y_continuous(name = "Density") +
  theme(
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank()
    ) +
  # coord_cartesian(
  #   xlim = c(350, 1320),
  #   ylim = c(0.0005, .01)
  # ) +
  scale_fill_viridis_d(guide = NULL) +
  scale_color_viridis_d(guide = NULL)) |>  
  ggplotly() |>  
  style(showlegend = FALSE)
```
:::

We now have distributions in way more sensible ranges, what's more defined by the characteristics of the participants, as opposed to the broad arbitrary RT thresholds we chose at the beginning.

# Inferential analyses

## Generalized Linear Mixed Models

### Rationale

We are going to fit Generalized Linear Mixed Models (GLMM) on the RT data. As opposed to Linear Mixed Models (LMM), GLMMs are able to accommodate the shape of the skewed RT distribution, thus removing the need to transform the dependent variable. This will allow us to work with raw RT data: GLMMs allow assumptions regarding the relationship between the predictors and the dependent variable (i.e. RT here) to be tested independently of assumptions regarding the distribution of dependent variable (i.e. skewed in our case). In LMMs, the two are confounded because the relationship between the predictors and the dependent variable is dictated by the transformation selected to normalize the distribution of the dependent variable (e.g. log transformation, Box-Cox transformation, etc.). By contrast, GLMMs allows the form of the link function to be determined by the theoretical issues under consideration (Lo & Andrews, 2015).

### Model fitting

The predictors of the RT outcomes in the models are the **Group**, the **Congruence** condition and the **Color** condition. The random factors here are participants. The models could account for the varying RT means of each participant with a *random intercept per participant*, the varying effect of **Congruence** for each participant with a *slope on Congruence per participant*, and the varying effect of **Color** for each participant with a *slope on Color per participant*. These random effects will be added if they contribute significantly to the quality of the models. To accomodate the RTs, several models and distributions will be tested and compared using model quality indices: Gamma distribution with an identity link function.

Alternatively, we could also transform our data using a Box-Cox transformation to bring the RTs closer to normality and fit LMMs. Using the `tidymodels` workflows, we can easily fit all of these models and compare their quality.

Only two-way interactions between the three factors have been kept, as three-way interactions were not improving the quality of the models, and were sometimes even preventing the models from converging at all.

```{r fitting_glmms_and_lmms}
#| code-summary: "Fitting all the models with `tidymodels` (Warning: long code chunk)"
#| echo: true
#| output: false
 
# ═══ Fitting Generalized Linear Mixed Models ══════════════════════════════════

# ─── Preparing variable roles ─────────────────────────────────────────────────
model_recipe_glmm_ex <- 
  df_explicit_rt |> 
  recipe() |> 
  update_role(rt, new_role = "outcome") %>%
  update_role(
    subjectid, age, aphantasia, color, congruence, 
    new_role = "predictor"
  ) |> 
  add_role(subjectid, new_role = "group")

model_recipe_glmm_im <- 
  df_implicit_rt |> 
  recipe() |> 
  update_role(rt, new_role = "outcome") %>%
  update_role(
    subjectid, age, aphantasia, color, congruence, 
    new_role = "predictor"
  ) |> 
  add_role(subjectid, new_role = "group")

# Adding pre-processing steps to Box-Cox and normalize RTs in LMMs
model_recipe_lmm_ex <- 
  model_recipe_glmm_ex |> 
  step_BoxCox(rt) |> 
  step_normalize(rt)

model_recipe_lmm_im <- 
  model_recipe_glmm_im |> 
  step_BoxCox(rt) |> 
  step_normalize(rt)

# ─── Specifying the distributions for the models ──────────────────────────────

# GLMM, Gamma distribution, identity link
glmm_gamma_id <-
  linear_reg() |> 
  set_engine(
    "glmer",
    family = Gamma(link = "identity")
  )

# GLMM, Inverse Gaussian distribution, identity link
glmm_inverse_id <-
  linear_reg() |> 
  set_engine(
    "glmer",
    family = inverse.gaussian(link = "identity")
  )

# GLMM, Inverse Gaussian distribution, log link
glmm_inverse_log <-
  linear_reg() |> 
  set_engine(
    "glmer",
    family = inverse.gaussian(link = "log")
  )

# LMM = GLMM with a Gaussian distribution and identity link
glmm_gaussian <-
  linear_reg() |> 
  set_engine("lmer")

# Listing these models
# GLMMs
model_specs_glmm <- list(
  glmm_gamma_id    = glmm_gamma_id,
  glmm_inverse_id  = glmm_inverse_id,
  glmm_inverse_log = glmm_inverse_log,
  glmm_gaussian    = glmm_gaussian
)
# LMM spec for transformed data
model_spec_lmm <- list(lmm_boxcox = glmm_gaussian)

# ─── Writing down the formulas of our models ──────────────────────────────────
# null model
formula_0 <- rt ~ (1|subjectid)
# intercept by-participant only
formula_1 <- rt ~ (aphantasia + congruence + color)^2 + (1|subjectid)
# intercept and slope on congruence by-participant
formula_2 <- rt ~ (aphantasia + congruence + color)^2 + (congruence|subjectid)
# intercept and slope on color by-participant
formula_3 <- rt ~ (aphantasia + congruence + color)^2 + (color|subjectid)
# intercept and slope on congruence and color by-participant
formula_4 <- rt ~ (aphantasia + congruence + color)^2 + (congruence|subjectid) + (color|subjectid)

# Listing these formulas
model_formulas <- list(
  formula_0 = formula_0,
  formula_1 = formula_1,
  formula_2 = formula_2,
  formula_3 = formula_3,
  formula_4 = formula_4
  )

# ─── Table to combine everything in workflows and fit the models ──────────────
(
model_all_workflows_fitted_sequential <- 
  tribble(       ~recipe,     ~ task,           ~model,       ~formula,
    model_recipe_glmm_ex, "explicit", model_specs_glmm, model_formulas,
    model_recipe_glmm_im, "implicit", model_specs_glmm, model_formulas,
     model_recipe_lmm_ex, "explicit",   model_spec_lmm, model_formulas,
     model_recipe_lmm_im, "implicit",   model_spec_lmm, model_formulas,
  ) |> 
  # combining recipes with models
  unnest_longer(model) |> 
  # combining them with formulas
  unnest_longer(formula) |>
  rowwise() |>
  mutate(
    # creating workflows
    workflow = list(
      workflow() |>
      add_recipe(recipe) |> 
      add_model(model, formula = formula)  
      ),
    # fitting all the workflows (models) for each task
    fitted_model = ifelse(
      task == "explicit",
      list(workflow |> fit(data = df_explicit_rt) |> extract_fit_engine()),
      list(workflow |> fit(data = df_implicit_rt) |> extract_fit_engine())
    ),
    # extracting the parameters of the models
    parameters = list(model_parameters(fitted_model)),
    # checking the convergence of the models
    convergence = check_convergence(fitted_model),
    # model quality indices
    model_perf = list(model_performance(fitted_model)),
    AIC  = model_perf[[1]],
    AICc = model_perf[[2]],
    BIC  = model_perf[[3]]
  ) |>
  ungroup() |> 
  select(-c(recipe, model, formula, workflow, model_perf))
) |> 
  system.time() -> time_sequential 

# 841 seconds (14min)

# ─── Comparing the models' quality among those that converged ─────────────────
model_selection <-
  model_all_workflows_fitted_sequential |> 
  filter(
    formula_id != "formula_0" & 
    convergence == TRUE
  ) |> 
  group_by(task, model_id) |> 
  mutate(best_model = ifelse(AICc == min(AICc), TRUE, FALSE)) |> 
  filter(best_model == TRUE)

# inverse log models with random intercepts per-participant are the best GLMMs 
# for both tasks
```

# Testing foreach --------------------------------------------------------------

```{r fitting_glmms_and_lmms_parallel}
#| output: false
 
# ═══ Fitting Generalized Linear Mixed Models in parallel ══════════════════════

# ─── Preparing variable roles ─────────────────────────────────────────────────
model_recipe_glmm_ex <- 
  df_explicit_rt |> 
  recipe() |> 
  update_role(rt, new_role = "outcome") %>%
  update_role(
    subjectid, age, aphantasia, color, congruence, 
    new_role = "predictor"
  ) |> 
  add_role(subjectid, new_role = "group")

model_recipe_glmm_im <- 
  df_implicit_rt |> 
  recipe() |> 
  update_role(rt, new_role = "outcome") %>%
  update_role(
    subjectid, age, aphantasia, color, congruence, 
    new_role = "predictor"
  ) |> 
  add_role(subjectid, new_role = "group")

# Adding pre-processing steps to Box-Cox and normalize RTs in LMMs
model_recipe_lmm_ex <- 
  model_recipe_glmm_ex |> 
  step_BoxCox(rt) |> 
  step_normalize(rt)

model_recipe_lmm_im <- 
  model_recipe_glmm_im |> 
  step_BoxCox(rt) |> 
  step_normalize(rt)

# ─── Specifying the distributions for the models ──────────────────────────────

# GLMM, Gamma distribution, identity link
glmm_gamma_id <-
  linear_reg() |> 
  set_engine(
    "glmer",
    family = Gamma(link = "identity")
  )

# GLMM, Inverse Gaussian distribution, identity link
glmm_inverse_id <-
  linear_reg() |> 
  set_engine(
    "glmer",
    family = inverse.gaussian(link = "identity")
  )

# GLMM, Inverse Gaussian distribution, log link
glmm_inverse_log <-
  linear_reg() |> 
  set_engine(
    "glmer",
    family = inverse.gaussian(link = "log")
  )

# LMM = GLMM with a Gaussian distribution and identity link
glmm_gaussian <-
  linear_reg() |> 
  set_engine("lmer")

# Listing these models
# GLMMs
model_specs_glmm <- list(
  glmm_gamma_id    = glmm_gamma_id,
  glmm_inverse_id  = glmm_inverse_id,
  glmm_inverse_log = glmm_inverse_log,
  glmm_gaussian    = glmm_gaussian
)
# LMM spec for transformed data
model_spec_lmm <- list(lmm_boxcox = glmm_gaussian)

# ─── Writing down the formulas of our models ──────────────────────────────────
# null model
formula_0 <- rt ~ (1|subjectid)
# intercept by-participant only
formula_1 <- rt ~ (aphantasia + congruence + color)^2 + (1|subjectid)
# intercept and slope on congruence by-participant
formula_2 <- rt ~ (aphantasia + congruence + color)^2 + (congruence|subjectid)
# intercept and slope on color by-participant
formula_3 <- rt ~ (aphantasia + congruence + color)^2 + (color|subjectid)
# intercept and slope on congruence and color by-participant
formula_4 <- rt ~ (aphantasia + congruence + color)^2 + (congruence|subjectid) + (color|subjectid)

# Listing these formulas
model_formulas <- list(
  formula_0 = formula_0,
  formula_1 = formula_1,
  formula_2 = formula_2,
  formula_3 = formula_3,
  formula_4 = formula_4
  )

# ─── Table to combine everything in workflows and fit the models ──────────────
# (
model_all_workflows_fitted_parallel <- 
  tribble(       ~recipe,     ~ task,           ~model,       ~formula,
    model_recipe_glmm_ex, "explicit", model_specs_glmm, model_formulas,
    model_recipe_glmm_im, "implicit", model_specs_glmm, model_formulas,
     model_recipe_lmm_ex, "explicit",   model_spec_lmm, model_formulas,
     model_recipe_lmm_im, "implicit",   model_spec_lmm, model_formulas,
  ) |> 
  # combining recipes with models
  unnest_longer(model) |> 
  # combining them with formulas
  unnest_longer(formula) |>
  rowwise() |>
  mutate(
    # creating workflows
    workflow = list(
      workflow() |>
      add_recipe(recipe) |> 
      add_model(model, formula = formula)  
      )
  )

# ─── Fitting the models with parallel processing ──────────────────────────────

# finding the available cores for parallel processing
n_cores <- parallel::detectCores() - 1

# creating the cluster of cores
parallel_cluster <- 
  parallel::makeCluster(
    n_cores,
    type = "PSOCK"
  )

# registering the cluster for `foreach`
doParallel::registerDoParallel(cl = parallel_cluster)
# checking
# foreach::getDoParRegistered()
# foreach::getDoParWorkers()

# creating a new list-column with all the models fitted in parallel
# (+ measuring runtime)
(model_all_workflows_fitted_parallel$fitted_models <-
  foreach(
    workflow = model_all_workflows_fitted_parallel$workflow,
    task     = model_all_workflows_fitted_parallel$task,
    .combine  = "c",
    .packages = c("tidymodels", "multilevelmod")
) %dopar% {
  if(task == "explicit"){
    model_fit <-
      list(
        workflow |> 
        fit(data = df_explicit_rt) |> 
        extract_fit_engine()
      )
  }
  
  else{
    model_fit <-
      list(
        workflow |> 
        fit(data = df_implicit_rt) |> 
        extract_fit_engine()
      )
  }
  
  return(model_fit)
}) |> system.time() -> time_parallel

model_all_workflows_fitted_parallel <-  
  model_all_workflows_fitted_parallel |> 
  select(-c(recipe, model, formula, workflow))

# stopping the cluster when we're done
parallel::stopCluster(cl = parallel_cluster)

# 214 seconds (3min30s)
```


```{r faster}
# registerDoParallel(cores = 20)
# getDoParWorkers # -> Checks how many parallel cores foreach will use
# registerDoSEQ() # -> switches back to sequential
```

# ------------------------------------------------------------------------------

```{r check_the_best_models}
#| fig-label: fig-model_checks
#| fig-cap: "Checking the assumptions of all the models for both tasks."
#| fig-subcap: true
#| layout-ncol: 1

best_glmm_explicit <- model_selection$fitted_model[[1]]
best_glmm_implicit <- model_selection$fitted_model[[4]]

# ─── Model checks ───────────────────────────
best_glmm_explicit |>
  check_model(
    # check = c(
    #   "homogeneity",
    #   "outliers",
    #   "vif",
    #   "qq",
    #   "reqq"
    #   )
  )

best_glmm_implicit |>
  check_model(
    # check = c(
    #   "homogeneity",
    #   "outliers",
    #   "vif",
    #   "qq",
    #   "reqq"
    #   )
  )
```

::: {.panel-tabset .column-page-inset-right}
#### Explicit task

```{r model_plots_ex}
#| label: fig-model_plots_ex
#| fig-cap: "Plots for the effects of interest in the explicit task."
#| fig-subcap:
#|   - "Group x Congruence interaction in the GLMM for the explicit task."
#|   - "Group x Congruence interaction in the LMM for the explicit task."

# ─── Model effects plots ───────────────────────────

# setting dodge width for all the geoms
dw <- .75
# stat text size
st <- 7
# legend and axis text size
txt <- 32

# marginal means predictions
best_glmm_explcit_preds <-
  best_glmm_explicit |>
  estimate_means(at = c("aphantasia", "congruence"))

best_glmm_implcit_preds <-
  best_glmm_implicit |>
  estimate_means(at = c("aphantasia", "congruence"))
  
# overall means
rt_mean_explicit <- df_explicit_rt$rt |> mean()
rt_mean_implicit <- df_implicit_rt$rt |> mean()

# plot
df_explicit_rt |>
  ggplot(aes(
    x = congruence,
    y = rt,
    fill = aphantasia,
    color = aphantasia
  )) +
  # linear modelling of the differences
  geom_line(
    data = best_glmm_explcit_preds,
    aes(
      y = Mean,
      group = aphantasia
    ),
    position = position_dodge(width = dw),
    linewidth = 1.5,
    linetype = 1,
    show.legend = FALSE
  ) +
  # predicted means of the model
  geom_pointrange2(
    data = best_glmm_explcit_preds,
    aes(
      x = congruence,
      y = Mean,
      ymin = CI_low,
      ymax = CI_high,
      group = aphantasia
      ),
    color = "black",
    position = position_dodge(width = dw),
    size = 1,
    linewidth = .75,
    show.legend = FALSE
  ) +
  # intercept
  geom_hline(yintercept = rt_mean_explicit, linetype = 2) +
  labs(
    x = NULL,
    y = "Response time (ms)"
    ) +
  scale_x_discrete(labels = c("Congruent", "Incongruent")) +
  scale_fill_okabeito(name = "Aphantasia: ", labels = c("Yes", "No")) +
  scale_color_okabeito(guide = NULL)
```

#### Implicit task

```{r model_plots_im}
#| label: fig-model_plots_im
#| fig-cap: "Plots for the effects of interest in the implicit task."
#| fig-subcap:
#|   - "Group x Congruence interaction in the GLMM for the implicit task."
#|   - "Group x Congruence interaction in the LMM for the implicit task."

# ─── Model effects plot ───────────────────────────
df_implicit_rt |>
  ggplot(aes(
    x = congruence,
    y = rt,
    fill = aphantasia,
    color = aphantasia
  )) +
  # linear modelling of the differences
  geom_line(
    data = best_glmm_implcit_preds,
    aes(
      y = Mean,
      group = aphantasia
    ),
    position = position_dodge(width = dw),
    linewidth = 1.5,
    linetype = 1,
    show.legend = FALSE
  ) +
  # predicted means of the model
  geom_pointrange2(
    data = best_glmm_implcit_preds,
    aes(
      x = congruence,
      y = Mean,
      ymin = CI_low,
      ymax = CI_high,
      group = aphantasia
      ),
    color = "black",
    position = position_dodge(width = dw),
    size = 1,
    linewidth = .75,
    show.legend = FALSE
  ) +
  # intercept
  geom_hline(yintercept = rt_mean_implicit, linetype = 2) +
  labs(
    x = NULL,
    y = "Response time (ms)"
    ) +
  scale_x_discrete(labels = c("Congruent", "Incongruent")) +
  scale_fill_okabeito(name = "Aphantasia: ", labels = c("Yes", "No")) +
  scale_color_okabeito(guide = NULL)

```
:::
