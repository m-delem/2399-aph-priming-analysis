---
title: "Sensory priming in aphantasia - Data analysis report"
author: "Maël Delem, Eddy Cavalli, Gaën Plancher"
date: 2023-09-13
date-modified: last-modified
date-format: "D/MM/YYYY"
format: html
execute: 
  echo: false
editor_options: 
  chunk_output_type: inline
toc: true
toc-depth: 3
toc-expand: 2
number-sections: true
number-depth: 2
fig-width: 6
fig-asp: .618
---

<!-- CSS options for custom title numbers styling-->
<style>
.header-section-number:after {
  content: ". ";
}
</style>

### Preliminary Set-up {.unnumbered}

::: {.callout-note collapse="true" appearance="simple"}

#### Datasets, code availability, software and setup

The code generating all the computations, figures, tables, etc. (only partially exposed here for clarity) can be found in the `analysis_report_osf.qmd` file, for which the best reading software are coding Integrated Development Environments (IDE) like [RStudio](https://posit.co/download/rstudio-desktop/) or [Visual Studio Code](https://code.visualstudio.com/). The file includes detailed commentaries along with the code to ease understanding, accessibility, and potential (welcome) criticism.

This analysis was conducted in R language on [RStudio](https://posit.co/download/rstudio-desktop/). This analysis report was written with [Quarto](https://quarto.org/). Down below is the set-up code, including two essential steps: 

1. Installing the required packages for this data analysis

2. importing data into the dataframes used throughout. 

```{r setup}
#| output: false
#| echo: true
#| code-summary: "Packages"

# ═══ Packages ═════════════════════════════════════════════════════════════════

# The package `librairian` will ease the package management with the "shelf" 
# function, which automatically: 
# 1) checks if a package is installed 
# 2) installs it if need be
# 3) loads the package like the "library()" function would.
if (!require(librarian)) install.packages(librarian)
library(librarian)

# now putting packages on our library's shelves:
shelf(
  # ─── essential package collections ───
  tidyverse,      # modern R ecosystem
  easystats,      # data analysis framework
  tidymodels,     # modelling framework
  
  # ─── tidymodels friends ──────────────
  corrr,          # correlational analyses
  tidybayes,      # bayesian inference
  multilevelmod,  # multilevel modelling with lmer and tidymodels
  
  # ─── modelling ───────────────────────
  lme4,           # mixed models
  mclust,         # mixture clustering
  rstanarm,       # bayesian models
  BayesFactor,    # BFs
  
  # ─── data management ─────────────────
  readxl,         # importing xlsx
  openxlsx,       # exporting xlsx
  
  #  data visualization ──────────────
  # plot types and geoms
  ricardo-bion/ggradar,  # radar plots
  ggbeeswarm,            # scatter violin plots
  GGally,         # complex plots
  # layout and options
  ggpubr,         # publication plots
  patchwork,      # layout control
  rstatix,        # ggplot stat tools
  # palettes
  ggsci,          # scientific palettes
  viridis,        # colour-blind friendly palettes
  # interactive
  plotly         # interactive plots
)

# ─── Global cosmetic theme ───q
theme_set(theme_bw(base_size = 14))

# ─── Fixing a seed for reproducibility ───
set.seed(14051998)
```

```{r importing_data}
#| echo: true
#| code-summary: "Importing data"

# Association task
df_asso <- read_excel("data/aphantasia_priming_tidy_data.xlsx", 
                     sheet = "data_asso")

# Implicit task
df_implicit <- read_excel("data/aphantasia_priming_tidy_data.xlsx", 
                     sheet = "data_implicit")

# Explicit task
df_explicit <- read_excel("data/aphantasia_priming_tidy_data.xlsx", 
                     sheet = "data_explicit")

# Rotation task
df_rotation <- read_excel("data/aphantasia_priming_tidy_data.xlsx", 
                     sheet = "data_rotation")

# Questionnaires
df_questionnaires <- 
  read_excel(
    "data/aphantasia_priming_tidy_data.xlsx",
    sheet = "data_questionnaires"
    ) %>% 
  # creating the a/phantasia groups
  mutate(
    aphantasia = ifelse(vviq80 < 32, "yes", "no"),
    aphantasia = fct_relevel(aphantasia, "yes", "no")
    )

# updating all the dataframes with the questionnaires data
dfs <- 
  list(
    association_task = df_asso, 
    implicit_task = df_implicit, 
    explicit_task = df_explicit, 
    rotation_task = df_rotation
    ) %>%
  # adding the vviq and group column to every dataframe
  imap(~left_join(
    .x, 
    df_questionnaires %>% 
      select(
        # column to match with the correct participants
        subjectid, 
        # new variables to add
        age,
        sexe,
        vviq80,
        aphantasia), by = "subjectid") %>% 
      rename("sex" = sexe) %>% 
      # reordering the final dfs
      select(
        subjectid, 
        age, sex, aphantasia,
        vviq80,
        everything())
    )

df_asso     <- dfs$association_task
df_implicit <- dfs$implicit_task
df_explicit <- dfs$explicit_task
df_rotation <- dfs$rotation_task
rm(dfs)
```

:::

:::{.callout-tip collapse="true" appearance="simple"}

#### Interactive figures

Many figures in this report are interactive: hover over the plots to see some of the tools available. You can select a zone to zoom on a plot, hover over bars to see details about data, select only specific groups in the legend, among many other features.

:::

# Exploratory Data Analysis (EDA) {#sec-eda}

## Outcomes: accuracy and RTs?

### Accuracy

While response time is an obvious outcome to model when it comes to decision tasks, the use of accuracy is more debatable, as the tasks were not specifically designed to be challenging. Traditionally, accuracy is mostly used to remove incorrect trials from RT modelling. We'll describe accuracy data to evaluate its relevance in this analysis. The distribution of the percentages of errors across the three tasks is displayed in @fig-tasks_errors, [-@fig-tasks_errors2], and [-@fig-tasks_errors3].

:::{.panel-tabset}

#### Association task
<!-- Percentage of errors -->

```{r tasks_errors_plotly_asso}
#| echo: false
#| label: fig-tasks_errors
#| fig-cap: "Distribution of errors between groups in the association task."
#| out-width: 100%
#| fig-height: 4

(df_asso %>%
  select(subjectid, correct_association, aphantasia) %>% 
  group_by(subjectid, aphantasia) %>% 
  count(correct_association) %>% 
  filter(correct_association == 1) %>% 
  mutate(n = 100 - n) %>% 
  ggplot(aes(
    x = n,
    fill = aphantasia,
    
    )) +
  geom_bar(
    aes(
    y = after_stat(prop), 
    color = aphantasia),
    position = position_dodge(),
    width = .8,
    alpha = .5
    ) +
  scale_x_continuous(
    name = "Percentage of errors",
    breaks = breaks_pretty(n = 20)
    ) +
  scale_y_continuous(
    name = "Proportion of the group",
    breaks = breaks_pretty(n = 10)
    ) +
  coord_cartesian(
    xlim = c(0.5, 24),
    ylim = c(.01,.36)
    ) +
  # labs(title = "Association task") +
  scale_color_okabeito(guide = NULL) +
  scale_fill_okabeito(name = "Aphantasia", labels = c("Yes", "No"))) %>% 
  # ggplotly-ing it
  ggplotly
```

#### Explicit task
<!-- Percentage of errors -->

```{r tasks_errors_plotly_explicit}
#| echo: false
#| label: fig-tasks_errors2
#| fig-cap: "Distribution of errors between groups in the explicit task."
#| out-width: 100%
#| fig-height: 4


(df_explicit %>%
  select(subjectid, correct_explicit, aphantasia) %>% 
  group_by(subjectid, aphantasia) %>% 
  count(correct_explicit) %>% 
  filter(correct_explicit == 1) %>% 
  mutate(n = (64 - n)/64 * 100) %>% 
  ggplot(aes(
    x = n, 
    color = aphantasia,
    fill = aphantasia
    )) +
  geom_bar(
    aes(y = after_stat(prop)),
    position = position_dodge(),
    width = .6,
    alpha = .6
    ) +
  scale_x_continuous(
    name = "Percentage of errors",
    breaks = breaks_pretty(n = 20)
    ) +
  scale_y_continuous(
    name = "Proportion of the group",
    breaks = breaks_pretty(n = 10)
    ) +
  coord_cartesian(
    xlim = c(1, 46),
    ylim = c(.01,.36)
    ) +
  # labs(title = "Explicit task") +
  scale_color_okabeito(guide = NULL) +
  scale_fill_okabeito(name = "Aphantasia", labels = c("Yes", "No"))) %>% 
  # plotly-ing it
  ggplotly
```

#### Implicit task
<!-- Percentage of errors -->

```{r tasks_errors_plotly_implicit}
#| echo: false
#| label: fig-tasks_errors3
#| fig-cap: "Distribution of errors between groups in the implicit task."
#| out-width: 100%
#| fig-height: 4

(df_implicit %>%
  select(subjectid, correct_implicit, aphantasia) %>% 
  group_by(subjectid, aphantasia) %>% 
  count(correct_implicit) %>% 
  filter(correct_implicit == 1) %>% 
  mutate(n = (64 - n)/64 * 100) %>% 
  ggplot(aes(
    x = n, 
    color = aphantasia,
    fill = aphantasia
    )) +
  geom_bar(
    aes(y = after_stat(prop)),
    position = position_dodge(),
    width = .6,
    alpha = .6
    ) +
  scale_x_continuous(
    name = "Percentage of errors",
    breaks = breaks_pretty(n = 20)
    ) +
  scale_y_continuous(
    name = "Proportion of the group",
    breaks = breaks_pretty(n = 10)
    ) +
  coord_cartesian(
    xlim = c(1, 40),
    ylim = c(.01,.28)
    ) +
  # labs(title = "Implicit task") +
  scale_color_okabeito(guide = NULL) +
  scale_fill_okabeito(name = "Aphantasia", labels = c("Yes", "No"))) %>% 
  # plotly-ing it
  ggplotly
```

:::

We can see that the distributions are skewed yet very similar across groups and tasks: as such, we are going to use accuracy only to remove missed trials in the analyses of the RTs. Nonetheless, the main noticeable aspect of these plots are the obvious outliers in each of the tasks. This information is crucial as it could reflect a wrong understanding of the task, or random responses: in any case, participants that have high error rates would require a deletion of up to 47% of their trials, which could become a bias in the modelling of the overall data. As there appear to be a cut-off of the main distribution around 16% of errors in all tasks, this value will be chosen as threshold. **For each task separately, the results of participants with an error rate superior to 16% will be removed ***(i.e., five participants in the explicit task and four in the implicit task)***, prior to removing all the missed trials of the remaining participants for modelling RTs.**

<!-- Finding and removing accuracy outliers -->
```{r acc_outliers}
#| code-summary: "Removing incorrect trials and task-wise accuracy outliers"
#| output: false

# --- Accuracy outliers analysis ---
list(df_explicit, df_implicit) %>%
  imap(
    ~.x %>%
      select(subjectid, starts_with("correct"), aphantasia) %>%
      group_by(subjectid) %>%
      count(pick(2)) %>%
      filter(pick(1) == 1) %>%
      ungroup() %>%
      mutate(
        n_tot = max(n),
        prop = (n_tot - n) / n_tot * 100  # analysing the error rate per subject
      ) %>%
      arrange(desc(prop)) %>%
      select(1, 5)
    )
# 5 accuracy outliers in the explicit task, 4 in the implicit one

# --- Removing incorrect trials and task-wise accuracy outliers ---
df_explicit_rt <-
  df_explicit %>%
  # filtering out...
  filter(
    # incorrect trials
    correct_explicit == 1 &
    # participants identified with with high error rates
    !(subjectid %in% c( 
      "aknezevic", 
      "lbrunie",  
      "agayou", 
      "bluciani",
      "ldossantos"))
    ) %>% 
  # removing irrelevant variables
  select(-c(sex, vviq80, orientation, response, correct_explicit))

# percentage of trials removed in the explicit task
(count(df_explicit) - count(df_explicit_rt)) / count(df_explicit)
# 9091 trials left, 573 = 5.9% removed

df_implicit_rt <- 
  df_implicit %>% 
  filter(
    correct_implicit == 1 &
    !(subjectid %in% c(
      "bdispaux", 
      "eleveque", 
      "aleclaire", 
      "dchimenton"))
      ) %>% 
  select(-c(sex, vviq80, orientation, response, correct_implicit))

# percentage of trials removed in the implicit task
(count(df_implicit) - count(df_implicit_rt)) / count(df_implicit) 
# 9078 left, 586 = 6% removed

```

### Response times

As a preprocessing, response times below 300ms and above 3000ms will be removed as they could represent false alarms. The removal of accuracy outliers, incorrect trials and extreme RTs amounted to 6.9% of trials in the explicit and 6.7 in the implicit task. 

<!-- Removing extreme RT outlier trials -->
```{r removing_first_rt_outliers}
#| code-summary: "Removing extreme RTs"
#| echo: true
#| output: false

# ─── First broad RT outlier trials removal ────────────────────────────────────
df_explicit_rt <- 
  df_explicit_rt %>% 
  # filtering out extreme RTs
  filter(rt_explicit > 300 & rt_explicit < 3000)

# total percentage of trials removed in the explicit task
(count(df_explicit) - count(df_explicit_rt)) / count(df_explicit) 
# 9000 trials left, 664 = 6.9% removed

df_implicit_rt <- 
  df_implicit_rt %>% 
  filter(rt_implicit > 300 & rt_implicit < 3000)

# total percentage of trials removed in the implicit task
(count(df_implicit) - count(df_implicit_rt)) / count(df_implicit) 
# 9017 left, 647 = 6.7% removed
```

:::{.panel-tabset .column-page-inset-right}

#### Explicit task
<!-- RT means -->

```{r explicit_task_rt_means_plotly}
#| label: fig-rt_means1
#| fig-cap: "Distribution of the mean RTs of participants in the explicit task (very high RT means have been cut for better readability)."
#| fig-height: 4

(df_explicit_rt %>% 
  group_by(subjectid) %>% 
  summarise(mean = mean(rt_explicit)) %>% 
  ggplot(aes(x = mean)) +
  geom_histogram(
    fill = "aquamarine2", 
    color = "aquamarine4", 
    alpha = .3,
    bins = 70
    # adjust = .4
    ) +
  labs(x = "Mean RT", y = "Number of participants") +
  scale_y_continuous(breaks = seq(0, 13, by = 1))) %>% 
  ggplotly
```

#### Implicit task
<!-- RT means -->

```{r implicit_task_rt_means_plotly}
#| label: fig-rt_means2
#| fig-cap: "Distribution of the mean RTs of participants in the implicit task (very high RT means have been cut for better readability)."
#| fig-height: 4

(df_implicit_rt %>%
  group_by(subjectid) %>% 
  summarise(mean = mean(rt_implicit)) %>% 
  ggplot(aes(x = mean)) +
  geom_histogram(
    fill = "coral2", 
    color = "coral4", 
    alpha = .3,
    bins = 70
    # adjust = .4
    ) +
  labs(x = "Mean RT", y = "Number of participants") +
  scale_y_continuous(breaks = seq(0, 9, by = 1))) %>% 
  ggplotly
```

#### RT means table
<!-- RT means table -->

```{r rt_means_table}
#| label: tbl-rt_means
#| tbl-cap: "Descriptive statistics of the average RTs across the sample in both tasks."

df_rt <-
  list(
  df_explicit_rt %>% rename("Explicit task mean RTs" = rt_explicit), 
  df_implicit_rt %>% rename("Implicit task mean RTs" = rt_implicit)
  ) %>% 
  imap(
    ~select(.x, contains("RT")) %>%
      report() %>% 
      as.data.frame() %>% 
      select(1, 2, 5:10)
    )

df_rt <- bind_rows(df_rt[[1]], df_rt[[2]])
df_rt %>% display
```

:::

A more detailed inspection of the RTs on a by-participant level was carried-out using median absolute deviations (MAD) from their RT average. The number of MADs to use as a threshold to detect outliers was chosen after meticulous inspection of individual distributions to keep as many trials as possible. RTs below 2.5 $\times$ MADs and above 7 $\times$ MADs for the explicit task or 8 $\times$ MADs for the implicit task were removed, resulting in total deletion of 8\% of observations in each task. The resulting distributions of RTs for each participant are represented in @fig-rt_per_participant_1 and [-@fig-rt_per_participant_2]. As we are going to transform the data before modelling it, we also visualized the resulting distributions after having undergone a Box-Cox transformation and a normalization in @fig-rt_per_participant_3 and [-@fig-rt_per_participant_4].

<!-- Removing second step RT outlier trials -->
```{r removing_second_rt_outliers}
#| code-summary: "Removing individual outlier trials"
#| echo: true
#| output: false

# ═══ By-participant MAD outlier detection ═════════════════════════════════════

# 2.5 MADs low threshold for both tasks
# For upper threshold:

# ─── Explicit task: ────────────────────────────────
# 3 MADs threshold = 8572 trials --> 11.3% trials out
# 5 MADs threshold = 8835 trials --> 8.6% trials out
# 6 MADs threshold = 8903 trials --> 7.9% trials out --> sensible compromise
# 7 MADs threshold = 8938 trials --> 7.5% trials out

df_explicit_rt <- 
  df_explicit_rt |> 
  group_by(subjectid) |> 
  mutate(
    rt_mean = mean(rt_explicit),
    rt_mad = mad(rt_explicit)
    ) |> 
  filter(
    rt_explicit < rt_mean + 6 * rt_mad &
    rt_explicit > rt_mean - 2.5 * rt_mad
  ) |>
  ungroup()

# ─── Implicit task: ────────────────────────────────
# 3 MADs threshold = 8455 trials --> 12.5% trials out
# 5 MADs threshold = 8730 trials --> 9.7% trials out
# 6 MADs threshold = 8801 trials --> 8.9% trials out 
# 7 MADs threshold = 8850 trials --> 8.4% trials out 
# 8 MADs threshold = 8889 trials --> 8% trials out --> best retention

df_implicit_rt <-
  df_implicit_rt |> 
  group_by(subjectid) |> 
  mutate(
    rt_mean = mean(rt_implicit),
    rt_mad = mad(rt_implicit)
    ) |> 
  filter(
    rt_implicit < rt_mean + 8 * rt_mad &
    rt_implicit > rt_mean - 2.5 * rt_mad
  ) |>
  ungroup()

# ─── additional code to explore the dataset ─── 
# df_explicit_rt |>
#   group_by(subjectid) |>
#   count() # 146 participants left
#   # get_summary_stats(rt_explicit) |> 
#   # select(subjectid, n, mean, median, min, max) |> 
#   # arrange(desc(mean))
# 
# df_implicit_rt |>
#   group_by(subjectid) |>
#   count() # 147 participants left
```

:::{.panel-tabset .column-page-inset-right}

#### Explicit task
<!-- RT distribution for each participant -->

```{r explicit_rt_per_participant_plotly}
#| label: fig-rt_per_participant_1
#| fig-cap: "Resulting distribution of RTs in the explicit task for each participant. Each colored distribution represents a single participant. *Hover to see details on the individual distributions*."
#| fig-height: 4

(df_explicit_rt %>% 
  ggplot(aes(x = rt_explicit, fill = subjectid)) +
  geom_density(alpha = .25, color = "black") +
  scale_x_continuous(name = "Response time", breaks = breaks_pretty(10)) +
  scale_y_continuous(name = "Density") +
  theme(
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank()
    ) +
  # coord_cartesian(
  #   xlim = c(380, 1700),
  #   ylim = c(0.0005, .01)
  # ) +
  scale_fill_viridis_d(guide = NULL) +
  scale_color_viridis_d(guide = NULL)) %>% 
  ggplotly %>% 
  style(showlegend = FALSE)
```

#### Implicit task
<!-- RT distribution for each participant -->

```{r implicit_rt_per_participant_plotly}
#| label: fig-rt_per_participant_2
#| fig-cap: "Resulting distribution of RTs in the implicit task for each participant. Each colored distribution represents a single participant. *Hover to see details on the individual distributions*."
#| fig-height: 4

(df_implicit_rt %>% 
  ggplot(aes(x = rt_implicit, fill = subjectid)) +
  geom_density(alpha = .25, color = "black") +
  scale_x_continuous(name = "Response time", breaks = breaks_pretty(5)) +
  scale_y_continuous(name = "Density") +
  theme(
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank()
    ) +
  # coord_cartesian(
  #   xlim = c(350, 1320),
  #   ylim = c(0.0005, .01)
  # ) +
  scale_fill_viridis_d(guide = NULL) +
  scale_color_viridis_d(guide = NULL)) %>% 
  ggplotly %>% 
  style(showlegend = FALSE)
```

```{r recipes}
# --- preprocessing recipe for explicit data ---
recipe_explicit <- 
  df_explicit_rt %>%
  recipe %>%
  update_role(
    rt_explicit, 
    new_role = "outcome"
    ) %>%
  update_role(
    subjectid, age,
    aphantasia,
    color, congruence,
    new_role = "predictor"
    ) %>%
  add_role(
    subjectid, 
    new_role = "group"
    ) %>%
  step_BoxCox(rt_explicit) %>% 
  step_normalize(rt_explicit, age)

# --- preprocessing recipe for implicit data ---
recipe_implicit <- 
  df_implicit_rt %>%
  recipe %>%
  update_role(
    rt_implicit, 
    new_role = "outcome"
    ) %>%
  update_role(
    subjectid, age,
    aphantasia,
    color, congruence,
    new_role = "predictor"
    ) %>%
  add_role(
    subjectid,
    new_role = "group"
    ) %>%
  step_BoxCox(rt_implicit) %>% 
  step_normalize(rt_implicit, age)
```

#### Box-Cox - Explicit

```{r box_cox_explicit}
#| label: fig-rt_per_participant_3
#| fig-cap: "Resulting transformed distribution of RTs in the explicit task for each participant. Each colored distribution represents a single participant. *Hover to see details on the individual distributions*."
#| fig-height: 4

(recipe_explicit %>% 
  prep() %>% 
  bake(df_explicit_rt) %>% 
  ggplot(aes(x = rt_explicit, fill = subjectid)) +
  geom_density(alpha = .25, color = "black") +
  scale_x_continuous(name = "Response time", breaks = breaks_pretty(10)) +
  scale_y_continuous(name = "Density") +
  theme(
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank()
    ) +
  # coord_cartesian(
  #   xlim = c(380, 1700),
  #   ylim = c(0.0005, .01)
  # ) +
  scale_fill_viridis_d(guide = NULL) +
  scale_color_viridis_d(guide = NULL)) %>% 
  ggplotly %>% 
  style(showlegend = FALSE)
```

#### Box-Cox - Implicit

```{r box_cox_implicit}
#| label: fig-rt_per_participant_4
#| fig-cap: "Resulting transformed distribution of RTs in the implicit task for each participant. Each colored distribution represents a single participant. *Hover to see details on the individual distributions*."
#| fig-height: 4

(recipe_implicit %>% 
  prep() %>% 
  bake(df_implicit_rt) %>% 
  ggplot(aes(x = rt_implicit, fill = subjectid)) +
  geom_density(alpha = .25, color = "black") +
  scale_x_continuous(name = "Response time", breaks = breaks_pretty(10)) +
  scale_y_continuous(name = "Density") +
  theme(
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank()
    ) +
  # coord_cartesian(
  #   xlim = c(380, 1700),
  #   ylim = c(0.0005, .01)
  # ) +
  scale_fill_viridis_d(guide = NULL) +
  scale_color_viridis_d(guide = NULL)) %>% 
  ggplotly %>% 
  style(showlegend = FALSE)
```

:::

# Inferential Analyses {#sec-inferential}

## Model description (Multilevel modelling)

### Predictors and outcome

Our analyses aim to evaluate the predictive abilities of several variables on one outcome, the **Response times** of the participants in the tasks. Our potential predictors are:

- **Group** membership, with two levels: aphantasia/phantasia

- **Congruence** conditions, with two levels: congruent and incongruent

- **Color** conditions, with two levels: colored and uncolored.

Sub-levels of the responses ("random effects") can also be accounted for:

- the dependency between response times for **each participant** (also referred to as *subjects*) caused by repeated measures

- the varying effects of **Congruence for each participant**

- the varying effects of **Color for each participant**.

This structure will be modeled using Multilevel Models (also called hierarchical or mixed models), allowing us to add the sub-levels of the hierarchy within participant measures we described above in the model. **RT data will be transformed using a Box-Cox transformation** to bring the distributions closer to normality and improve the quality of the models.

For a subject $i$ with a given *Group*/visual imagery, in the *Congruence* condition $j$ and the *Color* condition $k$, the maximal model of the resulting response time $RT_{ijk}$ including all the predictors can be specified as such:

$$
\begin{aligned}
RT_{ijk} = \alpha + \alpha_{subject[i]} + \beta_{1} \cdot \ Group_{i} \times (\beta_{2} + \beta_{2_{subject[i]}}) \cdot Congruence_{j} \times (\beta_{3} + \beta_{3_{subject[i]}}) \cdot Color_{k}
\end{aligned}
$$
Where $\alpha$ is the global intercept, $\alpha_{subject[i]}$ is a random intercept by subject accounting for the inherent randomness tied to participants, and $\beta_{1/2/3}$ are the parameters representing the effect of each predictor. The "$\times$" signs represent all the potential interactions along with fixed effects. Additionally, as one might expect the effect of the Congruence or Color conditions to have important variations between subjects (tied to cognitive processes and strategies), a slope $\beta_{2/3_{subject[i]}}$ by subject can be added to the Congruence or Color parameters to account for this variance.

### Potential models

**RT data will be standardized before modelling**, therefore the standardized coefficients reported will scale on *standard deviations of the RT variable*. This allows to interpret these parameters (regression coefficients) roughly with the same guidelines as usual indices, e.g., Cohen's *d*. Several models will be fitted in turn. We are not going to fit reduced models that exclude some main effects, as we would like to model all of them in any case to produce inferences (as opposed to raw predictions of future data). We'll specify the following: 

1. The minimal model, accounting only for the random effect of subjects, will serve as a comparison baseline: 

$$
\begin{aligned}
RT_{i} = \alpha + \alpha_{subject[i]}
\end{aligned}
$$

2. A model accounting for the fixed effects only:

$$
\begin{aligned}
RT_{ijk} = \alpha + \alpha_{subject[i]} + \beta_{1} \cdot \ Group_{i} + \beta_{2} \cdot Congruence_{j} + \beta_{3} \cdot Color_{k}
\end{aligned}
$$

3. A model with all interactions:

$$
\begin{aligned}
RT_{ijk} = \alpha + \alpha_{subject[i]} + \beta_{1} \cdot \ Group_{i} \times \beta_{2} \cdot Congruence_{j} \times \beta_{3} \cdot Color_{k}
\end{aligned}
$$

4. A model with a slope by subject on Congruence:

$$
\begin{aligned}
RT_{ijk} = \alpha + \alpha_{subject[i]} + \beta_{1} \cdot \ Group_{i} \times (\beta_{2} + \beta_{2_{subject[i]}}) \cdot Congruence_{j} \times \beta_{3} \cdot Color_{k}
\end{aligned}
$$

5. A model with a slope by subject on Color:

$$
\begin{aligned}
RT_{ijk} = \alpha + \alpha_{subject[i]} + \beta_{1} \cdot \ Group_{i} \times \beta_{2} \cdot Congruence_{j} \times (\beta_{3} + \beta_{3_{subject[i]}})  \cdot Color_{k}
\end{aligned}
$$

6. The maximal model:

$$
\begin{aligned}
RT_{ijk} = \alpha + \alpha_{subject[i]} + \beta_{1} \cdot \ Group_{i} \times (\beta_{2} + \beta_{2_{subject[i]}}) \cdot Congruence_{j} \times (\beta_{3} + \beta_{3_{subject[i]}})  \cdot Color_{k}
\end{aligned}
$$

The significant parameters will thereafter be analysed with **marginal contrasts analyses** (robust model-based analogues of "post-hoc" statistical tests) to evaluate the differences between factor levels.

## Fitting the models

```{r model_workflows_and_engines}

# --- workflows ---
workflow_explicit <- workflow() %>% add_recipe(recipe_explicit)
workflow_implicit <- workflow() %>% add_recipe(recipe_implicit)

# --- type of bayesian models to be fitted ---
# mod_0_bayesian <-
#   bayesian (
#     family = skew_normal()
#   ) %>%
#   set_engine("brms") %>% 
#   set_mode("regression")

# --- mixed models to be fitted ---
mod_0_lmer <-
  linear_reg() %>% 
  set_engine("lmer")

# --- bayesian hierarchical models ---
# mod_0_bayes <-
#   linear_reg() %>% 
#   set_engine("stan_glmer")
```

```{r model_specifications}
# --- Specifying all models ---

# --- Explicit task ---

# model 1: intercepts only
mod_explicit_1 <-
  workflow_explicit %>% add_model(
    mod_0_lmer,
    formula = rt_explicit ~ (1|subjectid)
    )

# model 2: fixed effects
mod_explicit_2 <-
  workflow_explicit %>% add_model(
    mod_0_lmer,
    formula = rt_explicit ~ aphantasia + congruence + color + (1|subjectid)
  )

# model 3: interactions
mod_explicit_3 <- 
  workflow_explicit %>% add_model(
    mod_0_lmer,
    formula = rt_explicit ~ aphantasia * congruence * color + (1|subjectid)
  )

# model 4: slope by subject on congruence
mod_explicit_4 <-
  workflow_explicit %>% add_model(
    mod_0_lmer,
    formula = rt_explicit ~ aphantasia * congruence * color + (1 + congruence|subjectid)
  )

# model 5: slope by subject on color
mod_explicit_5 <-
  workflow_explicit %>% add_model(
    mod_0_lmer,
    formula = rt_explicit ~ aphantasia * congruence * color + (1 + color|subjectid)
  )

# model 6: maximal model
mod_explicit_6 <-
  workflow_explicit %>% add_model(
    mod_0_lmer,
    formula = rt_explicit ~ aphantasia * congruence * color + 
      (1 + congruence|subjectid) + (1 + color|subjectid)
  )

# --- Implicit task ---

# model 1: intercepts only
mod_implicit_1 <-
  workflow_implicit %>% add_model(
    mod_0_lmer,
    formula = rt_implicit ~ (1|subjectid)
    )

# model 2: group effect
mod_implicit_2 <-
  workflow_implicit %>% add_model(
    mod_0_lmer,
    formula = rt_implicit ~ aphantasia + congruence + color + (1|subjectid)
  )

# model 3: congruence effect
mod_implicit_3 <- 
  workflow_implicit %>% add_model(
    mod_0_lmer,
    formula = rt_implicit ~ aphantasia * congruence * color + (1|subjectid)
  )

# model 4: color effect
mod_implicit_4 <-
  workflow_implicit %>% add_model(
    mod_0_lmer,
    formula = rt_implicit ~ aphantasia * congruence * color + (1 + congruence|subjectid)
  )

# model 5: slope by subject on color
mod_implicit_5 <-
  workflow_implicit %>% add_model(
    mod_0_lmer,
    formula = rt_implicit ~ aphantasia * congruence * color + (1 + color|subjectid)
  )

# model 6: maximal model
mod_implicit_6 <-
  workflow_implicit %>% add_model(
    mod_0_lmer,
    formula = rt_implicit ~ aphantasia * congruence * color + 
      (1 + congruence|subjectid) + (1 + color|subjectid)
  )
```

```{r model_bayes_test}
# model 4 bayesian
# mod_explicit_bayes <-
#   workflow_explicit %>% add_model(
#     mod_0_bayes,
#     formula = rt_explicit ~ aphantasia * congruence * color + (1 + congruence|subjectid)
#   )
# 
# fit_bayes <- mod_explicit_bayes %>% fit(data = df_explicit_rt)
# fit_bayes %>%
#   extract_fit_engine %>%
  # broom.mixed::tidy()
  # bayesfactor_parameters
  # model_performance
  # model_parameters
  # describe_posterior(test = c("pd", "bf"))
```

```{r model_fitting}

# --- Fitting all models ---

# --- Explicit task ---
fit_explicit_mods <-
  list(
    mod_explicit_1 = mod_explicit_1, 
    mod_explicit_2 = mod_explicit_2, 
    mod_explicit_3 = mod_explicit_3,
    mod_explicit_4 = mod_explicit_4,
    mod_explicit_5 = mod_explicit_5#,
    # mod_explicit_6 = mod_explicit_6
    ) %>% 
  imap(~ .x %>% fit(data = df_explicit_rt) %>% extract_fit_engine())

# --- Implicit task ---
fit_implicit_mods <-
  list(
    mod_implicit_1 = mod_implicit_1,
    mod_implicit_2 = mod_implicit_2,
    mod_implicit_3 = mod_implicit_3,
    mod_implicit_4 = mod_implicit_4,
    mod_implicit_5 = mod_implicit_5#,
    # mod_implicit_6 = mod_implicit_6
    ) %>%
  imap(~ .x %>% fit(data = df_implicit_rt) %>% extract_fit_engine())

# --- nested list of all the lists of models ---
all_models_fitted <-
  list(
    explicit_mods = fit_explicit_mods,
    implicit_mods = fit_implicit_mods
    )
```

All of these models have been fitted for both tasks and their predictive performances compared using the AIC, AICc (Akaike corrected Information Criterion). The maximal model did not converge, so only the first five models were evaluated. The results of these analyses are displayed in @tbl-model_perfs-1 and @tbl-model_perfs-2.

```{r model_performances}
#| label: tbl-model_perfs
#| tbl-cap: "Performances of the fitted models for both tasks."
#| tbl-subcap: 
#|   - "**Explicit** task models."
#|   - "**Implicit** task models."
#| layout-ncol: 1

# --- Performance of the models ---
all_models_performances <- 
  all_models_fitted %>% 
  imap(
    ~ .x %>% 
      compare_performance(metrics = c("AIC", "AICc")) %>% 
      select(-Model) %>%
      display
    )

all_models_performances[["explicit_mods"]]

all_models_performances[["implicit_mods"]]


```

The fifth model including a slope by subject on Congruence is the most supported for the **explicit task**, while the fourth model including only an intercept by subject has the best performance among models for the **implicit task**. The parameters of these two models will be analysed in the following.

```{r model_parameters}

# --- Parameter estimations ---
all_models_parameters <-
  all_models_fitted %>% 
  imap(
    ~ .x %>%
      imap(
        ~ .x %>% 
          model_parameters(effects = "fixed") %>%
          display
        )
    )
```

## Explicit task results

```{r model_explicit_contrasts}

# model 5 contrasts between aphantasia and congruence levels
c_ex_gcn <-
  all_models_fitted[[1]][[5]] %>% 
  estimate_contrasts(
    contrast = c("aphantasia", "congruence"), 
    lmerTest.limit = 9000, 
    pbkrtest.limit = 9000,
    p_adjust = "fdr"
  ) %>% 
  mutate(across(where(is.numeric), ~ round(.x, digits = 2)))

# model 5 contrasts between color levels
c_ex_col <-
  all_models_fitted[[1]][[5]] %>% 
  estimate_contrasts(
    contrast = c("color"), 
    lmerTest.limit = 9000, 
    pbkrtest.limit = 9000,
    p_adjust = "fdr"
  ) %>% 
  mutate(across(where(is.numeric), ~ round(.x, digits = 2)))
```

The parameters of the best model for the explicit task are displayed in @tbl-model_explicit_params_table. The significant parameters in the explicit task are the Color and the interaction between the Group and the Congruence conditions. The **main effect of Color** indicate that participants responded quicker in the colored condition (Marginal contrast (colored - uncolored) = `r c_ex_col[1,3]`, CI = $[`r c_ex_col[1,4]` ; `r c_ex_col[1,5]`]$, SE = `r c_ex_col[1,6]`, $p < .001$), although this effect has no interaction with the other variables. The **interaction between Group and Congruence** reveals that non-aphantasics responded slower in the uncongruent condition, as this contrast is the only significant one in this interaction (Marginal contrast (non-aphantasic congruent - incongruent) = `r c_ex_gcn[1,3]`, CI = $[`r c_ex_gcn[1,4]` ; `r c_ex_gcn[1,5]`]$, SE = `r c_ex_gcn[1,6]`, $p < .001$). These effects are illustrated in @fig-model_explicit_ggarrange. Both estimates are $\lt 0.2$, which denotes a *very small* effect size according to most standardized differences interpretation guidelines (e.g. Cohen, 1988; Gignac & Szodorai, 2016; Lovakov & Agadullina, 2021).

:::{.column-page-inset-right}

```{r model_explicit_params_table}
#| label: tbl-model_explicit_params_table
#| tbl-cap: "Parameters of the optimal model for the explicit task including a random intercept and slope by subject on Congruence."

all_models_parameters[["explicit_mods"]][["mod_explicit_5"]]
```

:::

<!-- Plot settings -->
```{r model_plots_general_settings}

# setting dodge width for all the geoms
dw <- .75
# stat text size
st <- 7
# legend and axis text size
txt <- 32
```

<!-- GCN -->

<!-- Explicit model means and stats for congruence and group -->
```{r model_explicit_gcn_plot_stats}

# model explicit gcn marginal means predictions
preds_mod_4_g_cng <- 
  all_models_fitted[[1]][[5]] %>% 
  estimate_means(
    at = c("aphantasia", "congruence"), 
    lmerTest.limit = 9000, 
    pbkrtest.limit = 9000
    )

# stats for the gcn interaction
stats_mod_4_g_cng_full <- 
  df_explicit_rt %>% 
  standardize(rt_explicit) %>% 
  group_by(aphantasia) %>% 
  pairwise_wilcox_test(rt_explicit ~ congruence) %>% 
  add_xy_position(x = "congruence", group = "aphantasia", dodge = dw) %>% 
  mutate(y.position = 3.1) %>% 
  filter(aphantasia == "no")

stats_mod_4_g_cng_zoom <- 
  df_explicit_rt %>% 
  standardize(rt_explicit) %>% 
  group_by(aphantasia) %>% 
  pairwise_wilcox_test(rt_explicit ~ congruence) %>% 
  add_xy_position(x = "congruence", group = "aphantasia", dodge = dw) %>% 
  mutate(y.position = c(.22, .3))
```

<!-- Explicit model full group and congruence plot -->
```{r model_explicit_gcn_full_plot}
p_mod_ex_gcn_full <-
  recipe_explicit %>% 
  prep() %>% 
  bake(df_explicit_rt) %>%
  ggplot(aes(
    x = congruence,
    y = rt_explicit,
    fill = aphantasia,
    color = aphantasia
    )
  ) +
  
  # group violin distributions with quantiles
  geom_violin(
    alpha = .2,
    trim = FALSE,
    adjust = .6,
    scale = "count",
    draw_quantiles = c(.25,.5,.75),
    position = position_dodge(width = dw),
    linewidth = .6
    ) +
  
  # participant points
  # geom_beeswarm(
  #   cex = .5,
  #   dodge.width = dw,
  #   alpha = 0.25,
  #   size = .5
  # ) +

  # linear modelling of the differences
  geom_line(
    data = preds_mod_4_g_cng,
    aes(
      y = Mean,
      group = aphantasia
    ),
    position = position_dodge(width = dw),
    linewidth = 1,
    linetype = 1,
    show.legend = FALSE
  ) +
   
  # predicted means of the model
  geom_pointrange2(
    data = preds_mod_4_g_cng,
    aes(
      x = congruence,
      y = Mean,
      ymin = CI_low,
      ymax = CI_high,
      group = aphantasia
      ),
    color = "black",
    position = position_dodge(width = dw),
    size = .5,
    linewidth = .5,
    show.legend = FALSE
  ) +
  
  # intercept at 0
  geom_hline(yintercept = 0, linewidth = .05, linetype = 2, alpha = .5) +
  
  # stats display
  stat_pvalue_manual(
    stats_mod_4_g_cng_full, 
    label = "p.adj.signif", 
    # tip.length = 0,
    size = st
    ) +
  
  # color_palettes and options
  labs(x = NULL, y = NULL) +
  # scale_x_discrete(labels = c("Congruent", "Incongruent")) +
  scale_y_continuous(breaks = breaks_pretty(10)) +
  scale_fill_okabeito(name = "Aphantasia: ", labels = c("Yes", "No")) +
  scale_color_okabeito(guide = NULL) +
  theme(
    panel.grid.major.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.text.x = element_blank(),
    legend.title = element_text(size = txt),
    legend.text = element_text(size = txt)
    )
```

<!-- Explicit model zoomed group and congruence plot -->
```{r model_explicit_gcn_zoomed_plot}
p_mod_ex_gcn_zoom <-
  recipe_explicit %>% 
  prep() %>% 
  bake(df_explicit_rt) %>%
  ggplot(aes(
    x = congruence,
    y = rt_explicit,
    fill = aphantasia,
    color = aphantasia
    )
  ) +
  
  # group violin distributions with quantiles
  geom_violin(
    alpha = .1,
    trim = FALSE,
    adjust = .6,
    scale = "count",
    draw_quantiles = c(.25,.5,.75),
    position = position_dodge(width = dw),
    linewidth = .6
    ) +
  
  # participant points
  # geom_beeswarm(
  #   cex = .5,
  #   dodge.width = dw,
  #   alpha = 0.25,
  #   size = .5
  # ) +

  # linear modelling of the differences
  geom_line(
    data = preds_mod_4_g_cng,
    aes(
      y = Mean,
      group = aphantasia
    ),
    position = position_dodge(width = dw),
    linewidth = 1.5,
    linetype = 1,
    show.legend = FALSE
  ) +
   
  # predicted means of the model
  geom_pointrange2(
    data = preds_mod_4_g_cng,
    aes(
      x = congruence,
      y = Mean,
      ymin = CI_low,
      ymax = CI_high,
      group = aphantasia
      ),
    color = "black",
    position = position_dodge(width = dw),
    size = 1,
    linewidth = .75,
    show.legend = FALSE
  ) +
  
  # intercept at 0
  geom_hline(yintercept = 0, linetype = 2) +
  
  # stats display
  stat_pvalue_manual(
    stats_mod_4_g_cng_zoom, 
    label = "p.adj.signif", 
    tip.length = 0,
    size = st
    ) +
  
  # zoom on a shorter y range
  coord_cartesian(ylim = c(-.3,.3)) +
  
  # color_palettes and options
  labs(
    # x = "Congruence condition", 
    x = NULL, 
    y = NULL
    ) +
  scale_x_discrete(labels = c("Congruent", "Incongruent")) +
  scale_y_continuous(breaks = breaks_pretty(8)) +
  scale_fill_okabeito(name = "Aphantasia: ", labels = c("Yes", "No")) +
  scale_color_okabeito(guide = NULL) +
  theme(
    panel.grid.major.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.text.x = element_text(size = txt),
    legend.text = element_text(size = txt),
    # axis.title.x = element_text(size = 18, vjust = -.5),
    legend.title = element_text(size = txt)
    )
```

<!-- GCOL -->

<!-- Explicit model means and stats for color and group -->
```{r model_explicit_gcol_plot_stats}
# model explicit gcol marginal means predictions
preds_mod_4_g_col <- 
  all_models_fitted[[1]][[5]] %>% 
  estimate_means(
    at = c("aphantasia", "color"), 
    lmerTest.limit = 9000, 
    pbkrtest.limit = 9000
    )

# stats for the gcol interaction
stats_mod_4_g_col_full <- 
  df_explicit_rt %>% 
  standardize(rt_explicit) %>%
  group_by(aphantasia) %>% 
  pairwise_wilcox_test(rt_explicit ~ color) %>% 
  add_xy_position(x = "color", dodge = dw) %>% 
  mutate(y.position = 3.1)

# stat for the color effect
stats_mod_4_g_col_zoom <- 
  df_explicit_rt %>% 
  standardize(rt_explicit) %>%
  group_by(aphantasia) %>%
  pairwise_wilcox_test(rt_explicit ~ color) %>% 
  add_xy_position(x = "color", dodge = dw) %>% 
  mutate(y.position = .3)
```

<!-- Explicit model full group and color plot -->
```{r model_explicit_gcol_full_plot}
p_mod_ex_gcol_full <-
  recipe_explicit %>% 
  prep() %>% 
  bake(df_explicit_rt) %>%
  ggplot(aes(
    x = color,
    y = rt_explicit,
    fill = aphantasia,
    color = aphantasia
    )
  ) +
  
  # group violin distributions with quantiles
  geom_violin(
    alpha = .2,
    trim = FALSE,
    adjust = .6,
    scale = "count",
    draw_quantiles = c(.25,.5,.75),
    position = position_dodge(width = .8),
    linewidth = .6
    ) +
  
  # participant points
  # geom_beeswarm(
  #   cex = .5,
  #   dodge.width = .8,
  #   alpha = 0.25,
  #   size = .5
  # ) +

  # linear modelling of the differences
  geom_line(
    data = preds_mod_4_g_col,
    aes(
      y = Mean,
      group = aphantasia
    ),
    position = position_dodge(width = dw),
    linewidth = 1,
    linetype = 1,
    show.legend = FALSE
  ) +
   
  # predicted means of the model
  geom_pointrange2(
    data = preds_mod_4_g_col,
    aes(
      x = color,
      y = Mean,
      ymin = CI_low,
      ymax = CI_high,
      group = aphantasia
      ),
    color = "black",
    position = position_dodge(width = dw),
    size = .5,
    linewidth = .5,
    show.legend = FALSE
  ) +
  
  # intercept at 0
  geom_hline(yintercept = 0, linewidth = .05, linetype = 2, alpha = .5) +
  
  # stats display
  stat_pvalue_manual(
    stats_mod_4_g_col_full, 
    label = "p.adj.signif", 
    # tip.length = 0,
    size = st
    ) +
  
  # color_palettes and options
  labs(x = NULL, y = NULL) +
  # scale_x_discrete(labels = c("Congruent", "Incongruent")) +
  scale_y_continuous(breaks = breaks_pretty(10)) +
  scale_fill_okabeito(name = "Aphantasia: ", labels = c("Yes", "No")) +
  scale_color_okabeito(guide = NULL) +
  theme(
    panel.grid.major.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.text.x = element_blank(),
    legend.title = element_text(size = txt),
    legend.text = element_text(size = txt)
    )
```

<!-- Explicit model zoomed group and color plot -->
```{r model_explicit_gcol_zoomed_plot}
p_mod_ex_gcol_zoom <-
  recipe_explicit %>% 
  prep() %>% 
  bake(df_explicit_rt) %>%
  ggplot(aes(
    x = color,
    y = rt_explicit,
    fill = aphantasia,
    color = aphantasia
    )
  ) +
  
  # group violin distributions with quantiles
  geom_violin(
    alpha = .1,
    trim = FALSE,
    adjust = .6,
    scale = "count",
    draw_quantiles = c(.25,.5,.75),
    position = position_dodge(width = .8),
    linewidth = .6
    ) +
  
  # participant points
  # geom_beeswarm(
  #   cex = .5,
  #   dodge.width = .8,
  #   alpha = 0.25,
  #   size = .5
  # ) +

  # linear modelling of the differences
  geom_line(
    data = preds_mod_4_g_col,
    aes(
      y = Mean,
      group = aphantasia
    ),
    position = position_dodge(width = dw),
    linewidth = 1.5,
    linetype = 1,
    show.legend = FALSE
  ) +
   
  # predicted means of the model
  geom_pointrange2(
    data = preds_mod_4_g_col,
    aes(
      x = color,
      y = Mean,
      ymin = CI_low,
      ymax = CI_high,
      group = aphantasia
      ),
    color = "black",
    position = position_dodge(width = dw),
    size = 1,
    linewidth = .75,
    show.legend = FALSE
  ) +
  
  # intercept at 0
  geom_hline(yintercept = 0, linetype = 2) +
  
  # stats display
  stat_pvalue_manual(
    stats_mod_4_g_col_zoom,
    label = "p.adj.signif",
    tip.length = 0.005,
    size = st
    ) +
    
  # zoom on a shorter y range
  coord_cartesian(ylim = c(-.3,.3)) +
  
  # color_palettes and options
  labs(
    # x = "Color condition", 
    x = NULL,
    y = NULL
    ) +
  scale_x_discrete(labels = c("Colored", "Uncolored")) +
  scale_y_continuous(breaks = breaks_pretty(8)) +
  scale_fill_okabeito(name = "Aphantasia: ", labels = c("Yes", "No")) +
  scale_color_okabeito(guide = NULL) +
  theme(
    panel.grid.major.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.text.x = element_text(size = txt),
    legend.text = element_text(size = txt),
    # axis.title.x = element_text(size = 18, vjust = -.5),
    legend.title = element_text(size = txt)
    )
```

:::{.column-page-inset-right}

<!-- GCN and GCOL -->

```{r model_explicit_ggarrange}
#| label: fig-model_explicit_ggarrange
#| fig-cap: "Visualization of the predictions of the optimal model for the explicit task. The bottom plots are 'zoomed' versions of the top ones on shorter (standard) RT ranges for clearer views of the model. The horizontal colored lines in the 'violins' (colored shapes outlining the distribution of responses) represent quantiles at 25, 50 and 75%. The black dots indicate marginal means predicted by the model whereas the black bars represent the credible intervals of these estimations. **Left:** The *Congruence* plots represent the estimates of the model at each Congruence condition and Group, highlighting the significant interaction between the two variables. **Right**: The *Color* plots represent the estimates at each Color condition and Group, highlighting the main effect of Color and non-significance of the interaction with the Group factor."
#| fig-width: 24
#| fig-height: 16

p_mod_explicit_ggarrange <-
  ggarrange(
    p_mod_ex_gcn_full,
    p_mod_ex_gcol_full,
    p_mod_ex_gcn_zoom,
    p_mod_ex_gcol_zoom,
    labels = c("Congruence", "Color"),
    label.x = c(-.1,.7),
    vjust = -.2,
    font.label = list(size = 38),
    common.legend = TRUE,
    legend = "top",
    ncol = 2,
    nrow = 2,
    heights = c(1.3,1),
    align = "v"
  ) %>%
  annotate_figure(
    left = text_grob("Response time (standardized)", size = txt, rot = 90)
    )

p_mod_explicit_ggarrange
```

:::
  
## Implicit task results

```{r model_implicit_contrasts}

# model 4 contrasts between aphantasia and congruence levels
c_im_gcn <-
  all_models_fitted[[2]][[4]] %>% 
  estimate_contrasts(
    contrast = c("aphantasia", "congruence"), 
    lmerTest.limit = 9000, 
    pbkrtest.limit = 9000,
    p_adjust = "fdr"
  ) %>% 
  mutate(across(where(is.numeric), ~ round(.x, digits = 2)))

# model 4 contrasts between group levels
c_im_group <-
  all_models_fitted[[2]][[4]] %>% 
  estimate_contrasts(
    contrast = c("aphantasia"), 
    lmerTest.limit = 9000, 
    pbkrtest.limit = 9000,
    p_adjust = "fdr"
  ) %>% 
  mutate(across(where(is.numeric), ~ round(.x, digits = 2)))
```

The parameters of the best model for the **implicit task** are displayed in @tbl-model_implicit_params_table. The only significant parameter is the **interaction between Group and Congruence**. This interaction shows that non-aphantasics only responded slower in the incongruent condition, which is the only significant contrast (Marginal contrast (non-aphantasic congruent - incongruent) = `r c_im_gcn[1,3]`, CI = $[`r c_im_gcn[1,4]`;`r c_im_gcn[1,5]`]$, SE = `r c_im_gcn[1,6]`, $p = `r c_im_gcn[1,9]`$). This effect is represented in @fig-model_implicit_ggarrange. This estimate $\lt 0.2$, which denotes a *very small* effect size.

:::{.column-page-inset-right}

```{r model_implicit_params_table}
#| label: tbl-model_implicit_params_table
#| tbl-cap: "Implicit task  - Parameters of the optimal model including a random intercept by subject."

all_models_parameters[["implicit_mods"]][["mod_implicit_4"]]
```

:::

<!-- Implicit model stats -->
```{r model_implicit_gcn_plot_stats}

# model 3 marginal means predictions
# interaction ______________________________
preds_mod_3_fixed_congruence <- 
  all_models_fitted[[2]][[4]] %>% 
  estimate_means(
    at = c("aphantasia", "congruence"), 
    lmerTest.limit = 9000, 
    pbkrtest.limit = 9000,
    p_adjust = "fdr"
  )

# group ________________________________
preds_mod_3_fixed_group <- 
  all_models_fitted[[2]][[4]] %>% 
  estimate_means(
    at = c("aphantasia"), 
    lmerTest.limit = 9000, 
    pbkrtest.limit = 9000,
    p_adjust = "fdr"
  )

# stats for the gcn interaction _________________________________________

# controls comparisons between conditions on full plot
stats_mod_3_g_cng_full <-
  df_implicit_rt %>% 
  standardize(rt_implicit) %>% 
  group_by(aphantasia) %>% 
  pairwise_wilcox_test(rt_implicit ~ congruence) %>% 
  add_xy_position(x = "congruence", group = "aphantasia", dodge = dw) %>% 
  mutate(y.position = 3.6) %>% 
  filter(aphantasia == "no")

# controls and aph comparisons between conditions on zoomed plot
stats_mod_3_g_cng_zoom <-
  df_implicit_rt %>% 
  standardize(rt_implicit) %>% 
  group_by(aphantasia) %>% 
  pairwise_wilcox_test(rt_implicit ~ congruence) %>% 
  add_xy_position(x = "congruence", group = "aphantasia", dodge = dw) %>% 
  mutate(y.position = c(.28, .2))

stats_mod_3_g_cng_full2 <-
  df_implicit_rt %>% 
  standardize(rt_implicit) %>% 
  group_by(congruence) %>% 
  pairwise_wilcox_test(rt_implicit ~ aphantasia) %>% 
  add_xy_position(x = "congruence", group = "aphantasia", dodge = dw) %>% 
  mutate(y.position = 3.2)

# stats for group _____________________________________________
stats_mod_3_group_full <-
  df_implicit_rt %>% 
  standardize(rt_implicit) %>%
  group_by(congruence) |> 
  pairwise_wilcox_test(rt_implicit ~ aphantasia) %>% 
  add_xy_position(x = "aphantasia", dodge = dw) %>% 
  mutate(y.position = 3.2)

stats_mod_3_group_zoom <-
  df_implicit_rt %>% 
  standardize(rt_implicit) %>%
  pairwise_wilcox_test(rt_implicit ~ aphantasia) %>% 
  add_xy_position(x = "aphantasia", dodge = dw) %>% 
  mutate(y.position = .2)
```

<!-- Implicit model full group and congruence plot -->
```{r model_implicit_gcn_full_plot}
p_mod_im_gcn_full <-
  recipe_implicit %>% 
  prep() %>% 
  bake(df_implicit_rt) %>%
  ggplot(aes(
    x = congruence,
    y = rt_implicit
    )
  ) +
  
  # group violin distributions with quantiles
  geom_violin(
    aes(
    fill = aphantasia,
    color = aphantasia),
    alpha = .2,
    trim = FALSE,
    adjust = .6,
    scale = "count",
    draw_quantiles = c(.25,.5,.75),
    position = position_dodge(width = dw),
    linewidth = .6
    ) +
  
  # participant points
  # geom_beeswarm(
  #   cex = .5,
  #   dodge.width = dw,
  #   alpha = 0.25,
  #   size = .5
  # ) +

  # linear modelling of the differences
  geom_line(
    data = preds_mod_3_fixed_congruence,
    aes(
      y = Mean,
      group = aphantasia,
      color = aphantasia
    ),
    position = position_dodge(width = dw),
    linewidth = 1,
    linetype = 1,
    show.legend = FALSE
  ) +
   
  # predicted means of the model
  geom_pointrange2(
    data = preds_mod_3_fixed_congruence,
    aes(
      x = congruence,
      y = Mean,
      ymin = CI_low,
      ymax = CI_high,
      group = aphantasia
      ),
    color = "black",
    position = position_dodge(width = dw),
    size = .5,
    linewidth = .5,
    show.legend = FALSE
  ) +
  
  # intercept at 0
  geom_hline(yintercept = 0, linewidth = .05, linetype = 2, alpha = .5) +
  
  # stats display
  stat_pvalue_manual(
    stats_mod_3_g_cng_full, 
    label = "p.adj.signif", 
    # tip.length = 0,
    size = st
    ) +
  
  # stats display
  stat_pvalue_manual(
    stats_mod_3_g_cng_full2, 
    label = "p.adj.signif", 
    # tip.length = 0,
    size = st
    ) +
  
  # color_palettes and options
  labs(x = NULL, y = NULL) +
  # scale_x_discrete(labels = c("Congruent", "Incongruent")) +
  scale_y_continuous(breaks = breaks_pretty(10)) +
  scale_fill_okabeito(name = "Aphantasia", labels = c("Yes", "No")) +
  scale_color_okabeito(guide = NULL) +
  theme(
    panel.grid.major.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.text.x = element_blank(),
    legend.title = element_text(size = txt),
    legend.text = element_text(size = txt)
    )
```

<!-- Implicit model zoomed group and congruence plot -->
```{r model_implicit_gcn_zoomed_plot}
p_mod_im_gcn_interaction_zoom <-
  recipe_implicit %>% 
  prep() %>% 
  bake(df_implicit_rt) %>%
  ggplot(aes(
    x = congruence,
    y = rt_implicit,
    fill = aphantasia,
    color = aphantasia
    )
  ) +
  
  # group violin distributions with quantiles
  geom_violin(
    alpha = .1,
    trim = FALSE,
    adjust = .6,
    scale = "count",
    draw_quantiles = c(.25,.5,.75),
    position = position_dodge(width = dw),
    linewidth = .6
    ) +
  
  # participant points
  # geom_beeswarm(
  #   cex = .5,
  #   dodge.width = dw,
  #   alpha = 0.25,
  #   size = .5
  # ) +

  # linear modelling of the differences
  geom_line(
    data = preds_mod_3_fixed_congruence,
    aes(
      y = Mean,
      group = aphantasia
    ),
    position = position_dodge(width = dw),
    linewidth = 1.5,
    linetype = 1,
    show.legend = FALSE
  ) +
   
  # predicted means of the model
  geom_pointrange2(
    data = preds_mod_3_fixed_congruence,
    aes(
      x = congruence,
      y = Mean,
      ymin = CI_low,
      ymax = CI_high,
      group = aphantasia
      ),
    color = "black",
    position = position_dodge(width = dw),
    size = 1,
    linewidth = .75,
    show.legend = FALSE
  ) +
  
  # intercept at 0
  geom_hline(yintercept = 0, linetype = 2) +
  
  # stats display
  stat_pvalue_manual(
    stats_mod_3_g_cng_zoom, 
    label = "p.adj.signif", 
    tip.length = 0,
    size = st
    ) +
  
  # zoom on a shorter y range
  coord_cartesian(ylim = c(-.3,.3)) +
  
  # color_palettes and options
  labs(x = NULL, y = NULL) +
  scale_x_discrete(labels = c("Congruent", "Incongruent")) +
  scale_y_continuous(breaks = breaks_pretty(8)) +
  scale_fill_okabeito(name = "Aphantasia", labels = c("Yes", "No")) +
  scale_color_okabeito(guide = NULL) +
  theme(
    panel.grid.major.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.text.x = element_text(size = txt),
    legend.title = element_text(size = txt),
    legend.text = element_text(size = txt)
    )
```

<!-- Implicit model full group plot -->
```{r model_implicit_group_full_plot}
p_mod_im_group_full <-
  recipe_implicit %>% 
  prep() %>% 
  bake(df_implicit_rt) %>%
  ggplot(aes(
    x = aphantasia,
    y = rt_implicit
    )
  ) +
  
  # group violin distributions with quantiles
  geom_violin(
    aes(
    fill = aphantasia,
    color = aphantasia
    ),
    alpha = .2,
    trim = FALSE,
    adjust = .6,
    scale = "count",
    draw_quantiles = c(.25,.5,.75),
    position = position_dodge(width = dw),
    linewidth = .6
    ) +
  
  # participant points
  # geom_beeswarm(
  #   cex = .5,
  #   dodge.width = dw,
  #   alpha = 0.25,
  #   size = .5
  # ) +

  # linear modelling of the differences
  geom_line(
    data = preds_mod_3_fixed_group,
    aes(
      y = Mean,
      group = 1
    ),
    color = "black",
    position = position_dodge(width = dw),
    linewidth = 1,
    linetype = 1,
    show.legend = FALSE
  ) +
   
  # predicted means of the model
  geom_pointrange2(
    data = preds_mod_3_fixed_group,
    aes(
      y = Mean,
      ymin = CI_low,
      ymax = CI_high,
      group = 1
      ),
    color = "black",
    position = position_dodge(width = dw),
    size = .75,
    linewidth = .75,
    show.legend = FALSE
  ) +
  
  # intercept at 0
  geom_hline(yintercept = 0, linewidth = .05, linetype = 2, alpha = .5) +
  
  # stats display
  stat_pvalue_manual(
    stats_mod_3_group_full, 
    label = "p.adj.signif", 
    # tip.length = 0,
    size = st
    ) +
  
  # color_palettes and options
  labs(x = NULL, y = NULL) +
  # scale_x_discrete(labels = c("Congruent", "Incongruent")) +
  scale_y_continuous(breaks = breaks_pretty(10)) +
  scale_fill_okabeito(name = "Aphantasia", labels = c("Yes", "No")) +
  scale_color_okabeito(guide = NULL) +
  theme(
    panel.grid.major.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.text.x = element_blank(),
    legend.title = element_text(size = txt),
    legend.text = element_text(size = txt)
    )
```

<!-- Implicit model zoomed groupplot -->
```{r model_implicit_group_zoomed_plot}
p_mod_im_group_zoom <-
  recipe_implicit %>% 
  prep() %>% 
  bake(df_implicit_rt) %>%
  ggplot(aes(
    x = aphantasia,
    y = rt_implicit
    )
  ) +
  
  # group violin distributions with quantiles
  geom_violin(
    aes(
    fill = aphantasia,
    color = aphantasia
    ),
    alpha = .1,
    trim = FALSE,
    adjust = .6,
    scale = "count",
    draw_quantiles = c(.25,.5,.75),
    position = position_dodge(width = dw),
    linewidth = .6
    ) +
  
  # participant points
  # geom_beeswarm(
  #   cex = .5,
  #   dodge.width = dw,
  #   alpha = 0.25,
  #   size = .5
  # ) +

  # linear modelling of the differences
  geom_line(
    data = preds_mod_3_fixed_group,
    aes(
      y = Mean,
      group = 1
    ),
    color = "black",
    position = position_dodge(width = dw),
    linewidth = 1.5,
    linetype = 1,
    show.legend = FALSE
  ) +
   
  # predicted means of the model
  geom_pointrange2(
    data = preds_mod_3_fixed_group,
    aes(
      x = aphantasia,
      y = Mean,
      ymin = CI_low,
      ymax = CI_high,
      group = 1
      ),
    color = "black",
    position = position_dodge(width = dw),
    size = 1,
    linewidth = .75,
    show.legend = FALSE
  ) +
  
  # intercept at 0
  geom_hline(yintercept = 0, linetype = 2) +
  
  # stats display
  stat_pvalue_manual(
    stats_mod_3_group_zoom, 
    label = "p.adj.signif", 
    tip.length = 0,
    size = st
    ) +
  
  # zoom on a shorter y range
  coord_cartesian(ylim = c(-.26,.26)) +
  
  # color_palettes and options
  labs(x = NULL, y = NULL) +
scale_x_discrete(labels = c("Aphantasics", "Controls")) +
  scale_y_continuous(breaks = breaks_pretty(8)) +
  scale_fill_okabeito(name = "Aphantasia", labels = c("Yes", "No")) +
  scale_color_okabeito(guide = NULL) +
  theme(
    panel.grid.major.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.text.x = element_text(size = txt),
    legend.title = element_text(size = txt),
    legend.text = element_text(size = txt)
    )
```

:::{.column-page-inset-right}

<!-- Implicit model group and congruence ggarrange -->
```{r model_implicit_ggarrange}
#| label: fig-model_implicit_ggarrange
#| fig-cap: "Visualization of the Congruence and Group variables in the optimal model for the implicit task. The bottom plot is a 'zoomed' version of the first one on a shorter (standard) RT range for a clearer view of the model. The horizontal colored lines in the 'violins' represent quantiles at 25, 50 and 75%. The black dots indicate marginal means predicted by the model, whereas the black bars represent the credible intervals of these estimations." 
#| fig-width: 24
#| fig-height: 16

p_mod_implicit_ggarrange <-
  ggarrange(
    p_mod_im_group_full,
    p_mod_im_gcn_full,
    p_mod_im_group_zoom,
    p_mod_im_gcn_interaction_zoom,
    ncol = 2,
    nrow = 2,
    labels = c("Group", "Interaction"),
    label.x = c(-.03,.5),
    vjust = -.2,
    font.label = list(size = 38),
    common.legend = TRUE,
    legend = "top",
    heights = c(1.3,1),
    align = "v"
  ) %>% 
  annotate_figure(
    left = text_grob("Response time (standardized)", size = txt, rot = 90)
    )

p_mod_implicit_ggarrange

# ggexport(p_mod_implicit_ggarrange, filename = "plots/model_explicit.png", width = 1300, height = 800)
```

:::

# Further EDA: continuous analyses

## Continuous predictors: PCA

Theoretically, the four questionnaire variables - VVIQ, OSIQ-Object and Spatial, and SUIS - could be used as predictors (independent variables) for the RT outcomes (dependent variable) of the experiment. Three of these - VVIQ, OSIQ-Object and SUIS - evaluate visual imagery: yet here we only modeled the VVIQ as representative of visual imagery, what's more as a categorical predictor by dividing two groups based on it. In order to explore the potential of all these scales, we are going to run a Principal Component Analysis (PCA) on the four questionnaires' standardized scores to evaluate how many different constructs they represent. The suitability of the data for a PCA was assessed with Bartlett's test of sphericity (Bartlett, 1951), suggesting there was sufficient correlation in the data ($\chi^{2}$(55) = 408.01, p < .001) and the KMO measure of sampling adequacy (KMO = 0.73; see Kaiser, H. F., & Rice, J. (1974)). The Eigenvalues and variance explained by the PCA components computed, along with the loadings of each score on them, are displayed in @tbl-pca_tables.

```{r pca}
#| code-summary: "Computing the PCA"
#| echo: true

# ─── Principal Component Analysis ───
pca <- 
  principal_components(
    df_questionnaires[,4:7],
    n = "max",
    sort = TRUE,
    standardize = TRUE
    )
```

```{r pca_tables}
#| label: tbl-pca_tables
#| tbl-cap: "Results of the Principal Components Analysis."
#| tbl-subcap: 
#|   - "Loadings of each variable on the three components extracted by the PCA."
#|   - "Eigenvalues and variance explained by the three components extracted by the PCA."
#| layout-ncol: 2

# ─── Loadings ───
pca |> 
  as.data.frame() |>  
  mutate(Variable = case_when(
    Variable == "suis60" ~ "SUIS",
    Variable == "vviq80" ~ "VVIQ",
    Variable == "osiq_o75" ~ "OSIQ-O",
    Variable == "osiq_s75" ~ "OSIQ-S",
    TRUE ~ Variable
  )) |> 
  display()

# ─── Eigenvalues and variance ───
pca |> 
  summary() |> 
  as.data.frame() |>
  display()
```

The two first components (PC1 and PC2) explained 95% of the variance of the sample on the four scores (PC1 Eigenvalue = 2.84, 71% of the total variance explained, PC2 = 0.97, 24% of the total variance explained) and are the only meaningful ones in the PCA (PC3 explains 3% of variance). PC1 correlates highly with the VVIQ, OSIQ-Object and SUIS: this component can logically be interpreted as representing visual imagery (VI variable). PC2 also explains a significant part of variance, and correlates highly with the OSIQ-Spatial: we chose to interpret this component as representing spatial imagery (SI variable). These two variables, decorrelated by the PCA, are represented together in @fig-vi_si_corr.

```{r pca_data}
#| code-summary: "Adding the predicted PCA components to the data"
#| echo: true

# ─── Adding components to the data ───
pca_components <- pca |> predict()

df_questionnaires <-
  bind_cols(df_questionnaires[,1:8], pca_components[,1:2]) %>% 
  mutate(PC2 = -PC2) %>% 
  rename(
    "visual_imagery" = PC1,
    "spatial_imagery" = PC2
    )

# updating all the dataframes with the imagery variables
dfs <- 
  list( 
    implicit_task = df_implicit_rt, 
    explicit_task = df_explicit_rt
    ) %>%
  # adding the new variables to each dataframe
  imap(~left_join(
    .x |> select(-c(rt_mean, rt_mad)), 
    df_questionnaires %>% 
      select(
        # column to match with the correct participants
        subjectid, 
        # new variables to add
        visual_imagery, 
        spatial_imagery), 
    by = "subjectid") %>% 
      # reordering the final dfs
      select(
        subjectid, 
        age, aphantasia,
        visual_imagery, spatial_imagery,
        everything())
    )

df_implicit_rt <- dfs$implicit_task
df_explicit_rt <- dfs$explicit_task
rm(dfs)
```

```{r plot_vi_si_corr}
#| label: fig-vi_si_corr
#| fig-cap: "Correlation between the visual imagery PCA component and the spatial imagery one."
#| out-width: 100%

# --- correlation between visual and spatial ---
(df_questionnaires %>% 
  mutate(
    visual_imagery = rescale(visual_imagery),
    spatial_imagery = rescale(spatial_imagery),
    aphantasia = fct_relevel(aphantasia, "yes", "no")
    ) %>%
  ggplot(aes(x = visual_imagery, y = spatial_imagery)) +
  geom_point(aes(color = aphantasia)) +
  scale_color_okabeito(name = "Aphantasia", labels = c("Yes", "No")) +
  geom_smooth(
    aes(x = visual_imagery, y = spatial_imagery), 
    color = "black", 
    method = "lm", 
    stat = "smooth") +
  # stat_cor(
  #   aes(x = visual_imagery,
  #       y = spatial_imagery),
  #   inherit.aes = FALSE,
  #   cor.coef.name = "r",
  #   label.x.npc = .5,
  #   label.y.npc = .7) +
  labs(x = "Visual Imagery",
       y = "Spatial Imagery")) %>% 
  ggplotly

p_vi_si_corr <- 
  df_questionnaires %>% 
  mutate(
    visual_imagery = rescale(visual_imagery),
    spatial_imagery = rescale(spatial_imagery),
    aphantasia = fct_relevel(aphantasia, "yes", "no")
    ) %>%
  ggplot(aes(x = visual_imagery, y = spatial_imagery)) +
  geom_point(aes(color = aphantasia)) +
  scale_color_okabeito(name = "Aphantasia", labels = c("Yes", "No")) +
  geom_smooth(
    aes(x = visual_imagery, y = spatial_imagery), 
    color = "black", 
    method = "lm", 
    stat = "smooth") +
  # stat_cor(
  #   aes(x = visual_imagery,
  #       y = spatial_imagery),
  #   inherit.aes = FALSE,
  #   cor.coef.name = "r",
  #   label.x.npc = .5,
  #   label.y.npc = .7) +
  labs(x = "Visual Imagery",
       y = "Spatial Imagery")
```

## Modelling RTs with continuous predictors

Now that we have two new theoretically meaningful variables to explain our data, we can go back to model RTs again using these new predictors. 

For a subject $i$ with a given visual and spatial imagery (*VI* and *SI*), in the *Congruence* condition $j$ and the *Color* condition $k$, the new maximal model of the resulting response time $RT_{ijk}$ including all the predictors can be specified as such:

$$
\begin{aligned}
RT_{ijk} = \alpha + \alpha_{i} + \beta_{1} \cdot \ VI_{i} \times \beta_{2} \cdot \ SI_{i} \times (\beta_{3} + \beta_{3i}) \cdot Congruence_{j} \times (\beta_{4} + \beta_{4i}) \cdot Color_{k}
\end{aligned}
$$

Where $\alpha$ is the global intercept, $\alpha_{i}$ is a random intercept by subject accounting for the inherent randomness tied to participants, and $\beta_{1/2/3/4}$ are the parameters representing the effect of each predictor. The "$\times$" signs represent all the potential interactions along with fixed effects. Additionally, as one might expect the effect of the Congruence or Color conditions to have important variations between subjects (tied to cognitive processes and strategies), a slope $\beta_{3i/4i}$ by subject can be added to the Congruence or Color parameters to account for this variance. Likewise, several models will be fitted in turn with the same pattern as above. Only models including two-way interactions between the four factors have been kept, as three and four-way interactions were not improving the quality of the models in any way.

```{r new_recipes_workflows_and_engines}
# --- explicit data ---
recipe_explicit_b <- 
  df_explicit_rt %>%
  recipe %>%
  update_role(
    rt_explicit, 
    new_role = "outcome"
    ) %>%
  update_role(
    subjectid, age,
    aphantasia,
    visual_imagery, spatial_imagery,
    color, congruence,
    new_role = "predictor"
    ) %>%
  add_role(
    subjectid, 
    new_role = "group"
    ) %>%
  step_BoxCox(rt_explicit) %>% 
  step_normalize(rt_explicit, age)

# --- implicit data ---
recipe_implicit_b <- 
  df_implicit_rt %>%
  recipe %>%
  update_role(
    rt_implicit, 
    new_role = "outcome"
    ) %>%
  update_role(
    subjectid, age,
    aphantasia,
    visual_imagery, spatial_imagery,
    color, congruence,
    new_role = "predictor"
    ) %>%
  add_role(
    subjectid,
    new_role = "group"
    ) %>%
  step_BoxCox(rt_implicit) %>% 
  step_normalize(rt_implicit, age)

# --- workflows ---
workflow_explicit_b <- workflow() %>% add_recipe(recipe_explicit_b)
workflow_implicit_b <- workflow() %>% add_recipe(recipe_implicit_b)

# --- mixed models to be fitted ---
mod_0_lmer <-
  linear_reg() %>% 
  set_engine("lmer")
```

```{r new_model_specifications}
# --- Specifying all models ---

# --- Explicit task ---

# model 1: intercepts only
mod_explicit_1b <-
  workflow_explicit_b %>% add_model(
    mod_0_lmer,
    formula = rt_explicit ~ (1|subjectid)
    )

# model 2: fixed effects
mod_explicit_2b <-
  workflow_explicit_b %>% add_model(
    mod_0_lmer,
    formula = rt_explicit ~ (visual_imagery + spatial_imagery + congruence + color)^3 + (1 + color|subjectid)
  )

# model 3: interactions
mod_explicit_3b <- 
  workflow_explicit_b %>% add_model(
    mod_0_lmer,
    formula = rt_explicit ~ (visual_imagery + spatial_imagery + congruence + color)^2 + (1|subjectid)
  )

# model 4: slope by subject on congruence
mod_explicit_4b <-
  workflow_explicit_b %>% add_model(
    mod_0_lmer,
    formula = rt_explicit ~ (visual_imagery + spatial_imagery + congruence + color)^2 + (1 + congruence|subjectid)
  )

# model 5: slope by subject on color
mod_explicit_5b <-
  workflow_explicit_b %>% add_model(
    mod_0_lmer,
    formula = rt_explicit ~ (visual_imagery + spatial_imagery + congruence + color)^2 + (1 + color|subjectid)
  )

# model 6: maximal model
mod_explicit_6b <-
  workflow_explicit_b %>% add_model(
    mod_0_lmer,
    formula = rt_explicit ~ (visual_imagery + spatial_imagery + congruence + color)^2 + 
      (1 + congruence|subjectid) + (1 + color|subjectid)
  )

# --- Implicit task ---

# model 1: intercepts only
mod_implicit_1b <-
  workflow_implicit_b %>% add_model(
    mod_0_lmer,
    formula = rt_implicit ~ (1|subjectid)
    )

# model 2: group effect
mod_implicit_2b <-
  workflow_implicit_b %>% add_model(
    mod_0_lmer,
    formula = rt_implicit ~ (visual_imagery + spatial_imagery + congruence + color)^3 + (1 + congruence|subjectid)
  )

# model 3: congruence effect
mod_implicit_3b <- 
  workflow_implicit_b %>% add_model(
    mod_0_lmer,
    formula = rt_implicit ~ (visual_imagery + spatial_imagery + congruence + color)^2 + (1|subjectid)
  )

# model 4: color effect
mod_implicit_4b <-
  workflow_implicit_b %>% add_model(
    mod_0_lmer,
    formula = rt_implicit ~ (visual_imagery + spatial_imagery + congruence + color)^2 + (1 + congruence|subjectid)
  )

# model 5: slope by subject on color
mod_implicit_5b <-
  workflow_implicit_b %>% add_model(
    mod_0_lmer,
    formula = rt_implicit ~ (visual_imagery + spatial_imagery + congruence + color)^2 + (1 + color|subjectid)
  )

# model 6: maximal model
mod_implicit_6b <-
  workflow_implicit_b %>% add_model(
    mod_0_lmer,
    formula = rt_implicit ~ (visual_imagery + spatial_imagery + congruence + color)^2 + 
      (1 + congruence|subjectid) + (1 + color|subjectid)
  )
```

```{r new_model_fitting}

# --- Fitting all models ---

# --- Explicit task ---
fit_explicit_b_mods <-
  list(
    mod_explicit_1b = mod_explicit_1b, 
    mod_explicit_2b = mod_explicit_2b,
    mod_explicit_3b = mod_explicit_3b,
    mod_explicit_4b = mod_explicit_4b,
    mod_explicit_5b = mod_explicit_5b#,
    # mod_explicit_6b= mod_explicit_6b
    ) %>% 
  imap(~ .x %>% fit(data = df_explicit_rt) %>% extract_fit_engine())

# --- Implicit task ---
fit_implicit_b_mods <-
  list(
    mod_implicit_1b = mod_implicit_1b,
    mod_implicit_2b = mod_implicit_2b,
    mod_implicit_3b = mod_implicit_3b,
    mod_implicit_4b = mod_implicit_4b,
    mod_implicit_5b = mod_implicit_5b#,
    # mod_implicit_6b = mod_implicit_6b
    ) %>%
  imap(~ .x %>% fit(data = df_implicit_rt) %>% extract_fit_engine())

# --- nested list of all the lists of models ---
all_b_models_fitted <-
  list(
    explicit_b_mods = fit_explicit_b_mods,
    implicit_b_mods = fit_implicit_b_mods
    )
```

```{r new_model_performances}
#| label: tbl-new_model_perfs
#| tbl-cap: "Performances of the new fitted models with continuous predictors for both tasks."
#| tbl-subcap: 
#|   - "**Explicit** task models."
#|   - "**Implicit** task models."
#| layout-ncol: 2

# --- Performance of the models ---
all_b_models_performances <- 
  all_b_models_fitted %>% 
  imap(
    ~ .x %>% 
      compare_performance(metrics = c("AIC", "AICc")) %>% 
      select(-Model) %>%
      display
    )

all_b_models_performances[["explicit_b_mods"]]

all_b_models_performances[["implicit_b_mods"]]


```

```{r new_model_parameters}
# --- Parameter estimations ---
all_b_models_parameters <-
  all_b_models_fitted %>% 
  imap(
    ~ .x %>%
      imap(
        ~ .x %>% 
          model_parameters(effects = "fixed") #%>%
          # display
        )
    )
```

## Explicit task results

The best model for the RTs in the explicit task included a random intercept and slope by participant on the Color condition (AIC = 19,474, cAIC = 19,474, null model AIC = 19,582), and had a substantial explanatory power (conditional $R^{2}$ = .53). The parameters of this model are displayed in Table \ref{tbl:model_b_explicit}. The significant parameters in this task are the Congruence, the Color, the interaction between VI and SI and the interaction between VI and Congruence. The main effect of Congruence and Color indicate that participants responded overall slower in the incongruent condition ($\beta$  = 0.06,  95\% CI [0.02, 0.11], \textit{t}(8888) = 3.09, p = .002) and in the uncolored condition ($\beta$  = 0.13,  95\% CI [0.09, 0.18], \textit{t}(8888) = 6.06, p $<$ .001). The interaction between VI and SI ($\beta$ = 0.08, 95\% CI [0.01, 0.16], \textit{t}(8891) = 2.28, p = .023) reveals that RTs are longer with higher VI and SI. Finally, the interaction between VI and Congruence ($\beta$ = 0.03, 95\% CI [0.00, 0.04], \textit{t}(8888) = 2.14, p = .003) reveals that a higher VI leads to slower RTs in the incongruent condition. These effects are represented in Figure \ref{fig:model_b_explicit}. All estimates are $< 0.2$, which denotes a small effect sizes.

```{r new_model_explicit_params_table}
#| label: tbl-new_model_explicit_params_table
#| tbl-cap: "Parameters of the optimal model for the explicit task including a random intercept and slope by subject on Color."

all_b_models_parameters[["explicit_b_mods"]][["mod_explicit_5b"]]
```

```{r plot_vi_congruence_explicit}
df_explicit_recipe_b <- 
  recipe_explicit_b |> 
  prep() |> 
  bake(df_explicit_rt) 

vizdata_vi_cng_explicit <- 
  df_explicit_recipe_b |> 
  visualisation_matrix(
    at = c("visual_imagery", "congruence"),
    length = 100,
    preserve_range = TRUE
)

vizdata_vi_cng_explicit <- 
  vizdata_vi_cng_explicit |> 
  mutate(predicted = insight::get_predicted(
    all_b_models_fitted[["explicit_b_mods"]][["mod_explicit_5b"]], 
    vizdata_vi_cng_explicit
    )) |> 
  mutate(congruence = ifelse(congruence == "congruent", "Congruent", "Incongruent"))

p_b_mod_ex_vicng <-
  df_explicit_recipe_b |> 
  mutate(congruence = ifelse(congruence == "congruent", "Congruent", "Incongruent")) |>  
  ggplot(aes(
    x = visual_imagery,
    y = rt_explicit,
    color = congruence
  )) +
  geom_point(
    size = 1,
    alpha = .2
  ) +
  geom_line(
    data = vizdata_vi_cng_explicit,
    aes(
      y = predicted,
      group = congruence
    ),
    size = 1.5
  ) +
  geom_vline(xintercept = 0, linetype = 2) +
  coord_cartesian(
    ylim = c(-2,-.7)
  ) +
  labs(
    title = "Explicit task",
    x = "",
    y = ""
    ) +
  scale_color_lancet(name = "Congruence") +
  theme(
    title = element_text(size = txt),
    axis.text = element_text(size = txt/2),
    legend.text = element_text(size = txt),
    legend.title = element_text(size = txt)
    )
```

```{r plot_vi_si_explicit}
vizdata_vi_si_explicit <-
  df_explicit_recipe_b |> 
  visualisation_matrix(c("visual_imagery", "spatial_imagery"), length = 100) |> 
  visualisation_matrix("visual_imagery", length = 15, numerics = "all") 

vizdata_vi_si_explicit$predicted <- 
  insight::get_predicted(
    all_b_models_fitted[["explicit_b_mods"]][["mod_explicit_5b"]], 
    vizdata_vi_si_explicit
    )

p_b_mod_ex_visi <-
  df_explicit_recipe_b |> 
  ggplot(aes(
    x = visual_imagery,
    y = rt_explicit,
    color = spatial_imagery
    )) +
  geom_point(
    size = 1,
    alpha = .1
  ) +
  geom_line(
    data = vizdata_vi_si_explicit,
    aes(
      y = predicted,
      group = spatial_imagery
      ),
    size = 1
  ) +
  geom_vline(xintercept = 0, linetype = 2) +
  coord_cartesian(
    ylim = c(-3.5,1)
  ) +
  labs(
    title = "Explicit task",
    x = "",
    y = ""
    ) +
  scale_color_viridis(name = "Spatial imagery") +
  theme(
    title = element_text(size = txt),
    axis.text = element_text(size = txt/2),
    legend.text = element_text(size = txt/2),
    legend.title = element_text(size = txt)
    )
```


## Implicit task results

The best model for the RTs in the implicit task included a random intercept and slope by participant on the Congruence condition (AIC = 22,109, cAIC = 22,109, null model AIC = 22,116), and had a substantial explanatory power (conditional $R^{2}$ = .35). The parameters of this model are displayed in Table \ref{tbl:model_b_implicit}. The significant parameters in this task are the interaction between VI and Congruence, along with a trend towards an interaction between VI and SI. The interaction between VI and Congruence shows that a higher VI is associated with slower responses in the incongruent condition ($\beta$  = 0.03, SE = 0.01, 95\% CI [0.01, 0.05], t(8874) = 2.58, \textit{p} = .01). The trend interaction between VI and SI ($\beta$  = 0.06, SE = 0.03, 95\% CI [0.00, 0.12], t(8874) = 1.83, \textit{p} = .067) reveals that RTs are longer with a higher VI and SI. The two new interaction effects tied to the continuous variables are represented in Figure \ref{fig:model_continuous_vicng} and \ref{fig:model_continuous_visi}. All estimates are $< 0.2$, which denotes small effect sizes.

```{r new_model_implicit_params_table}
#| label: tbl-new_model_implicit_params_table
#| tbl-cap: "Parameters of the optimal model for the implicit task including a random intercept and slope by subject on Congruence."

all_b_models_parameters[["implicit_b_mods"]][["mod_implicit_4b"]]
```

```{r plot_vi_congruence_implicit}
df_implicit_recipe_b <- 
  recipe_implicit_b |> 
  prep() |> 
  bake(df_implicit_rt) 

vizdata_vi_cng_implicit <- 
  df_implicit_recipe_b |> 
  visualisation_matrix(
    at = c("visual_imagery", "congruence"),
    length = 100,
    preserve_range = TRUE
)

vizdata_vi_cng_implicit <- 
  vizdata_vi_cng_implicit |> 
  mutate(predicted = insight::get_predicted(
    all_b_models_fitted[["explicit_b_mods"]][["mod_explicit_5b"]], 
    vizdata_vi_cng_implicit
    )) |> 
  mutate(congruence = ifelse(congruence == "congruent", "Congruent", "Incongruent"))

p_b_mod_im_vicng <-
  df_implicit_recipe_b |> 
  mutate(congruence = ifelse(congruence == "congruent", "Congruent", "Incongruent")) |> 
  ggplot(aes(
    x = visual_imagery,
    y = rt_implicit,
    color = congruence
  )) +
  geom_point(
    size = 1,
    alpha = .2
  ) +
  geom_line(
    data = vizdata_vi_cng_implicit,
    aes(
      y = predicted,
      group = congruence
    ),
    size = 1.5
  ) +
  geom_vline(xintercept = 0, linetype = 2) +
  coord_cartesian(
    ylim = c(-2,-.7)
  ) +
  labs(
    title = "Implicit task",
    x = "",
    y = ""
    ) +
  scale_color_lancet(name = "Congruence") +
  theme(
    plot.title = element_text(hjust = 1),
    title = element_text(size = txt),
    axis.text = element_text(size = txt/2),
    legend.text = element_text(size = txt),
    legend.title = element_text(size = txt)
    )
```

```{r plot_vi_si_implicit}
vizdata_implicit <-
  df_implicit_recipe_b |> 
  visualisation_matrix(c("visual_imagery", "spatial_imagery"), length = 100) |> 
  visualisation_matrix("visual_imagery", length = 15, numerics = "all") 

vizdata_implicit$predicted <- insight::get_predicted(all_b_models_fitted[["explicit_b_mods"]][["mod_explicit_5b"]], vizdata_implicit)

p_b_mod_im_visi <-
  df_implicit_recipe_b |> 
  ggplot(aes(
    x = visual_imagery,
    y = rt_implicit,
    color = spatial_imagery
    )) +
  geom_point(
    size = 1,
    alpha = .1
  ) +
  geom_line(
    data = vizdata_implicit,
    aes(
      y = predicted,
      group = spatial_imagery
      ),
    size = 1
  ) +
  geom_vline(xintercept = 0, linetype = 2) +
  coord_cartesian(
    ylim = c(-3.5,1)
  ) +
  labs(
    title = "Implicit task",
    x = "",
    y = ""
    ) +
  scale_color_viridis(name = "Spatial imagery") +
  theme(
    plot.title = element_text(hjust = 1),
    title = element_text(size = txt),
    axis.text = element_text(size = txt/2),
    legend.text = element_text(size = txt/2),
    legend.title = element_text(size = txt)
    )
```

```{r b_models_ggarrange}
p_b_mods_vicng_ggarrange <-
  ggarrange(
    p_b_mod_ex_vicng,
    p_b_mod_im_vicng,
    common.legend = TRUE,
    legend = "top",
    ncol = 2,
    align = "v"
  ) |> 
  annotate_figure(
    left = text_grob(
      "Response time (standardized)", 
      size = txt, 
      rot = 90
      ),
    bottom = text_grob(
      "Visual imagery (standardized PCA variable)", 
      size = txt,
      vjust = .05
      )
    )

p_b_mods_visi_ggarrange <-
  ggarrange(
    p_b_mod_ex_visi,
    p_b_mod_im_visi,
    common.legend = TRUE,
    legend = "top",
    ncol = 2,
    align = "v"
  ) |> 
  annotate_figure(
    left = text_grob(
      "Response time (standardized)", 
      size = txt, 
      rot = 90
      ),
    bottom = text_grob(
      "Visual imagery (standardized PCA variable)", 
      size = txt,
      vjust = .05
      )
    )

ggexport(
  p_b_mods_vicng_ggarrange, 
  filename = "plots/model_continuous_vicng.png",
  width = 1600,
  height = 800
  )

ggexport(
  p_b_mods_visi_ggarrange, 
  filename = "plots/model_continuous_visi.png",
  width = 1600,
  height = 800
  )
```


## The Congruence effect

The results show a consistent interaction between the visual imagery (categorized or not) of participants and the effect of the congruence condition on their RTs. The above analyses also showed that an interaction existed between visual and spatial imagery in how they affected RTs. Therefore, we now have three "within-participant" variables characterizing our observations: 1) the visual imagery of a given participant; 2) their spatial imagery; 3) the extent to which the congruence condition affects their RTs, what could be called their own \textit{Congruence effect} (in the explicit and implicit tasks).

To calculate the Congruence effect on a by-participant level, two approaches are possible:

- An **empirical approach**, by averaging the RTs per condition across all trials and subtracting Congruent mean RT minus Incongruent.

- A **model-based approach**, by using the multilevel models we fitted to isolate an estimate representing more accurately the Congruence effect per subject, ,i.e. the varying slope by participant.

Let's compute both methods and plot them against each other.

<!-- Predicting the congruence effect for each subject -->
```{r congruence_effect}
#| echo: true
#| code-summary: "Computing the Congruence effect per subject"

# ═══ Congruence effect by-participant ═════════════════════════════════════════

# ─── Empirical approach ───────────────────────────────────────────────────────

# explicit task
congruence_effect_ex_empiric <-
  df_explicit_recipe_b |> 
  group_by(subjectid, congruence) |> 
  summarise(mean_rt_ex = mean(rt_explicit)) |> 
  pivot_wider(
    names_from = congruence,
    values_from = mean_rt_ex
  ) |> 
  mutate(
    congruence_eff_ex_emp = uncongruent - congruent,
    .keep = "unused"
  )

# implicit task
congruence_effect_im_empiric <-
  df_implicit_recipe_b |> 
  group_by(subjectid, congruence) |> 
  summarise(mean_rt_im = mean(rt_implicit)) |> 
  pivot_wider(
    names_from = congruence,
    values_from = mean_rt_im
  ) |> 
  mutate(
    congruence_eff_im_emp = uncongruent - congruent,
    .keep = "unused"
    )

# ─── Model-based approach ─────────────────────────────────────────────────────

# explicit task
congruence_effect_ex_mbased <-
  # selecting the random slope on congruence by subject model
  all_b_models_fitted[["explicit_b_mods"]][["mod_explicit_4b"]] |> 
  # estimating the coefficent and intercept by subject
  estimate_grouplevel() |> 
  # keeping only the coefficient and reshaping like the original dataframe
  reshape_grouplevel(indices = "Coefficient")  |>  
  # "summary" reduces to one row per subject
  summary() |> 
  # keeping only the Coefficient column
  select(-Intercept)  |>  
  rename("congruence_eff_ex_mb" = congruenceuncongruent)

# implicit task
congruence_effect_im_mbased <-
  all_b_models_fitted[["implicit_b_mods"]][["mod_implicit_4b"]] |> 
  estimate_grouplevel() |> 
  reshape_grouplevel(indices = "Coefficient")  |>  
  summary() |> 
  select(-Intercept)  |>  
  rename("congruence_eff_im_mb" = congruenceuncongruent)

# ─── Merging both ─────────────────────────────────────────────────────────────

df_congruence_effect <-
inner_join(
  congruence_effect_ex_empiric,
  # subjectid, aphantasia, visual and spatial imagery
  df_questionnaires %>% select(1, 8:10),
  by = "subjectid"
  ) |> 
  inner_join(
    congruence_effect_ex_mbased,
    by = "subjectid"
  ) |> 
  inner_join(
    congruence_effect_im_empiric,
    by = "subjectid"
  ) |> 
  inner_join(
    congruence_effect_im_mbased,
    by = "subjectid"
  ) |> 
  select(subjectid, aphantasia:spatial_imagery, 2, 6, 7, 8) |> 
  mutate(across(c(visual_imagery:congruence_eff_im_mb), ~as.numeric(.x))) 
```

```{r explicit_empirical_vs_modelbased_corr}
df_congruence_effect |> 
  ggplot(aes(
    x = congruence_eff_ex_emp,
    y = congruence_eff_ex_mb
  )) +
  geom_point(aes(color = aphantasia)) + 
  scale_color_okabeito()
```

```{r implicit_empirical_vs_modelbased_corr}
df_congruence_effect |> 
  ggplot(aes(
    x = congruence_eff_im_emp,
    y = congruence_eff_im_mb
  )) +
  geom_point(aes(color = aphantasia)) + 
  scale_color_okabeito()
```

```{r explicit_empirical_vs_modelbased_distrib}
df_congruence_effect |> 
  ggplot() +
  geom_density(aes(x = congruence_eff_ex_emp), color = "coral", fill = "coral", alpha = .2) +
  geom_density(aes(x = congruence_eff_ex_mb), color = "aquamarine", fill = "aquamarine", alpha = .2)
```
```{r implicit_empirical_vs_modelbased_distrib}
df_congruence_effect |> 
  ggplot() +
  geom_density(aes(x = congruence_eff_im_emp), color = "coral", fill = "coral", alpha = .2) +
  geom_density(aes(x = congruence_eff_im_mb), color = "aquamarine", fill = "aquamarine", alpha = .2)
```

We can see that both methods are very convergent. This confirms that the model-based approach is targeting the correct parameter: as of now, for precision purposes (as we can see from the spread of the distributions), this is the value that will be kept for the Congruence effect.

```{r selecting_mb_congruence_effect}
df_clustering <- df_congruence_effect |> select(subjectid:spatial_imagery, 6, 8)
```



<!-- The End -->
:::{.callout-note collapse="true" appearance="simple"}

#### R Session information

```{r session_information}
report_system()
```

The following packages were used:

```{r packages}
report_packages(
  session = sessionInfo(),
  include_R = FALSE
  )
```

:::








































