---
title: "Sensory priming in aphantasia - Data analysis report"
author: "Maël Delem"
date: 2023-09-13
date-modified: last-modified
date-format: "D/MM/YYYY"
format: html
execute: 
  echo: false
editor_options: 
  chunk_output_type: inline
toc: true
toc-depth: 3
toc-expand: 2
number-sections: true
number-depth: 2
fig-width: 6
fig-asp: .618
---

<!-- CSS options for custom title numbers styling-->
```{=html}
<style>
.header-section-number:after {
  content: ". ";
}
</style>
```

### Preliminary Set-up {.unnumbered}

::: {.callout-note collapse="true" appearance="simple"}

#### Datasets, code availability, software and setup

The code generating all the computations, figures, tables, etc. (only partially exposed here for clarity) can be found in the `analysis_report_osf.qmd` file, for which the best reading software are coding Integrated Development Environments (IDE) like [RStudio](https://posit.co/download/rstudio-desktop/) or [Visual Studio Code](https://code.visualstudio.com/). The file includes detailed commentaries along with the code to ease understanding, accessibility, and potential (welcome) criticism.

This analysis was conducted in R language on [RStudio](https://posit.co/download/rstudio-desktop/). This analysis report was written with [Quarto](https://quarto.org/). Down below is the set-up code, including two essential steps: 

1. Installing the required packages for this data analysis

2. importing data into the dataframes used throughout. 

```{r setup}
#| echo: true
#| output: false
#| code-summary: "Packages"

# ═══ Packages ═════════════════════════════════════════════════════════════════

# The package `librairian` will ease the package management with the "shelf" 
# function, which automatically: 
# 1) checks if a package is installed 
# 2) installs it if need be
# 3) loads the package like the "library()" function would.
if (!require(librarian)) install.packages(librarian)
library(librarian)

# now putting packages on our library's shelves:
shelf(
  # ─── essential package collections ───
  tidyverse,      # modern R ecosystem
  easystats,      # data analysis framework
  tidymodels,     # modelling framework
  
  # ─── tidymodels friends ──────────────
  corrr,          # correlational analyses
  tidybayes,      # bayesian inference
  multilevelmod,  # multilevel modelling with lmer and tidymodels
  
  # ─── modelling ───────────────────────
  lme4,           # mixed models
  mclust,         # mixture clustering
  rstanarm,       # bayesian models
  BayesFactor,    # BFs
  
  # ─── data management ─────────────────
  readxl,         # importing xlsx
  openxlsx,       # exporting xlsx
  
  #  data visualization ──────────────
  # plot types and geoms
  ricardo-bion/ggradar,  # radar plots
  ggbeeswarm,            # scatter violin plots
  GGally,         # complex plots
  # layout and options
  ggpubr,         # publication plots
  patchwork,      # layout control
  rstatix,        # ggplot stat tools
  # palettes
  ggsci,          # scientific palettes
  viridis,        # colour-blind friendly palettes
  # interactive
  plotly         # interactive plots
)

# ─── Global cosmetic theme ───q
theme_set(theme_bw(base_size = 14))

# ─── Fixing a seed for reproducibility ───
set.seed(14051998)
```

```{r importing_data}
#| echo: true
#| output: false
#| code-summary: "Importing data"

# Implicit task
df_implicit <- 
  read_excel(
    "data/aphantasia_priming_tidy_data.xlsx",
    sheet = "data_implicit"
    ) |> 
  rename("rt" = rt_implicit)

# Explicit task
df_explicit <- 
  read_excel(
    "data/aphantasia_priming_tidy_data.xlsx",
    sheet = "data_explicit"
    ) |> 
  rename("rt" = rt_explicit)

# Questionnaires
df_questionnaires <- 
  read_excel(
    "data/aphantasia_priming_tidy_data.xlsx",
    sheet = "data_questionnaires"
    ) %>% 
  # creating the a/phantasia groups
  mutate(
    aphantasia = ifelse(vviq80 < 32, "yes", "no"),
    aphantasia = fct_relevel(aphantasia, "yes", "no")
    )

# updating all the dataframes with the questionnaires data
dfs <- 
  list(
    implicit_task = df_implicit, 
    explicit_task = df_explicit
    ) |> 
  # adding the vviq and group column to every dataframe
  imap(~left_join(
    .x, 
    df_questionnaires |>  
      select(
        # column to match with the correct participants
        subjectid, 
        # new variables to add
        age,
        sexe,
        vviq80,
        aphantasia), by = "subjectid") |>  
      rename("sex" = sexe) |>  
      # reordering the final dfs
      select(
        subjectid, 
        age, sex, aphantasia,
        vviq80,
        everything())
    )

df_implicit <- dfs$implicit_task
df_explicit <- dfs$explicit_task
rm(dfs)
```

:::

:::{.callout-tip collapse="true" appearance="simple"}

#### Interactive figures

Many figures in this report are interactive: hover over the plots to see some of the tools available. You can select a zone to zoom on a plot, hover over bars to see details about data, select only specific groups in the legend, among many other features.

:::

# Exploratory Data Analysis (EDA) {#sec-eda}

## Accuracy

Traditionally, accuracy is mostly used to remove incorrect trials from RT modelling. We'll describe accuracy data to evaluate its relevance in this analysis. The distribution of the percentages of errors across the three tasks is displayed in @fig-tasks_errors and [-@fig-tasks_errors2].

:::{.panel-tabset}

#### Implicit task accuracy

```{r tasks_errors_plotly_implicit}
#| label: fig-tasks_errors2
#| fig-cap: "Distribution of errors between groups in the implicit task."
#| out-width: 100%
#| fig-height: 4

# ═══ Percentage of errors plot - Implicit task ════════════════════════════════

(df_implicit |> 
  select(subjectid, correct_implicit, aphantasia) |>  
  group_by(subjectid, aphantasia) |>  
  count(correct_implicit) |>  
  filter(correct_implicit == 1) |>  
  mutate(n = (64 - n)/64 * 100) |>  
  ggplot(aes(
    x = n, 
    color = aphantasia,
    fill = aphantasia
    )) +
  geom_bar(
    aes(y = after_stat(prop)),
    position = position_dodge(),
    width = .6,
    alpha = .6
    ) +
  scale_x_continuous(
    name = "Percentage of errors",
    breaks = breaks_pretty(n = 20)
    ) +
  scale_y_continuous(
    name = "Proportion of the group",
    breaks = breaks_pretty(n = 10)
    ) +
  coord_cartesian(
    xlim = c(1, 40),
    ylim = c(.01,.28)
    ) +
  # labs(title = "Implicit task") +
  scale_color_okabeito(guide = NULL) +
  scale_fill_okabeito(name = "Aphantasia", labels = c("Yes", "No"))) |>  
  # plotly-ing it
  ggplotly()
```

#### Explicit task accuracy

```{r tasks_errors_plotly_explicit}
#| label: fig-tasks_errors
#| fig-cap: "Distribution of errors between groups in the explicit task."
#| out-width: 100%
#| fig-height: 4

# ═══ Percentage of errors plot - Explicit task ════════════════════════════════

(df_explicit |> 
  select(subjectid, correct_explicit, aphantasia) |> 
  group_by(subjectid, aphantasia) |>  
  count(correct_explicit) |>  
  filter(correct_explicit == 1) |> 
  mutate(n = (64 - n)/64 * 100) |>  
  ggplot(aes(
    x = n, 
    color = aphantasia,
    fill = aphantasia
    )) +
  geom_bar(
    aes(y = after_stat(prop)),
    position = position_dodge(),
    width = .6,
    alpha = .6
    ) +
  scale_x_continuous(
    name = "Percentage of errors",
    breaks = breaks_pretty(n = 20)
    ) +
  scale_y_continuous(
    name = "Proportion of the group",
    breaks = breaks_pretty(n = 10)
    ) +
  coord_cartesian(
    xlim = c(1, 46),
    ylim = c(.01,.36)
    ) +
  # labs(title = "Explicit task") +
  scale_color_okabeito(guide = NULL) +
  scale_fill_okabeito(name = "Aphantasia", labels = c("Yes", "No"))) |>  
  # plotly-ing it
  ggplotly()
```

:::

We are going to remove missed trials in the analyses of the RTs. Nonetheless, the main noticeable aspect of these plots are the obvious outliers in each of the tasks. This information is crucial as it could reflect a wrong understanding of the task, or random responses: in any case, participants that have high error rates would require a deletion of up to 47% of their trials, which could become a bias in the modelling of the overall data. As there appear to be a cut-off of the main distribution around 16% of errors in all tasks, this value will be chosen as threshold. **For each task separately, the results of participants with an error rate superior to 16% will be removed** *(i.e., five participants in the explicit task and four in the implicit task)***, prior to removing all the missed trials of the remaining participants for modelling RTs.**

```{r finding_and_removing_accuracy_outliers}
#| code-summary: "Removing incorrect trials and task-wise accuracy outliers"
#| echo: true
#| output: false

# ═══ Accuracy outliers analysis ═══════════════════════════════════════════════

# ─── Listing error rates per subject ───
list(df_explicit, df_implicit) %>%
  imap(
    ~.x %>%
      select(subjectid, starts_with("correct"), aphantasia) %>%
      group_by(subjectid) %>%
      count(pick(2)) %>%
      filter(pick(1) == 1) %>%
      ungroup() %>%
      mutate(
        n_tot = max(n),
        prop = (n_tot - n) / n_tot * 100  # analysing the error rate per subject
      ) %>%
      arrange(desc(prop)) %>%
      select(1, 5)
    )
# 5 accuracy outliers in the explicit task, 4 in the implicit one

# ─── Removing incorrect trials and task-wise accuracy outliers ───
df_explicit_rt <-
  df_explicit %>%
  # filtering out...
  filter(
    # incorrect trials
    correct_explicit == 1 &
    # participants identified with with high error rates
    !(subjectid %in% c( 
      "aknezevic", 
      "lbrunie",  
      "agayou", 
      "bluciani",
      "ldossantos"))
    ) %>% 
  # removing irrelevant variables
  select(-c(sex, vviq80, orientation, response, correct_explicit))

# percentage of trials removed in the explicit task
(count(df_explicit) - count(df_explicit_rt)) / count(df_explicit)
# 9091 trials left, 573 = 5.9% removed

df_implicit_rt <- 
  df_implicit %>% 
  filter(
    correct_implicit == 1 &
    !(subjectid %in% c(
      "bdispaux", 
      "eleveque", 
      "aleclaire", 
      "dchimenton"))
      ) %>% 
  select(-c(sex, vviq80, orientation, response, correct_implicit))

# percentage of trials removed in the implicit task
(count(df_implicit) - count(df_implicit_rt)) / count(df_implicit) 
# 9078 left, 586 = 6% removed

```

## Response times

### Extreme RTs

As a preprocessing, response times below 300ms and above 3000ms will be removed as they could represent false alarms.

```{r removing_first_rt_outliers}
#| code-summary: "Removing extreme RTs"
#| echo: true
#| output: false

# ═══ First broad RT outlier trials removal ════════════════════════════════════

df_explicit_rt <- 
  df_explicit_rt %>% 
  # filtering out extreme RTs
  filter(rt > 300 & rt < 3000)

# total percentage of trials removed in the explicit task
(count(df_explicit) - count(df_explicit_rt)) / count(df_explicit) 
# 9000 trials left, 664 = 6.9% removed

df_implicit_rt <- 
  df_implicit_rt %>% 
  filter(rt > 300 & rt < 3000)

# total percentage of trials removed in the implicit task
(count(df_implicit) - count(df_implicit_rt)) / count(df_implicit) 
# 9017 left, 647 = 6.7% removed
```

### Aberrant RT means

A first level of the RT outliers analysis is based on the overall mean RT of the participants. Participants with abnormally high RT means could represent various specific situations out of the range of our study: pathological conditions, attention deficits, or even more trivially low attention to the task. Such participants could bias both the overall results *and the analysis of the individual trials*: just like the accuracy outliers, the removal of their slow trials could result in a deletion of a large part of their responses, thus biasing the distributions. Let's visualize the distribution of the RT means in @fig-rt_means1 and [-@fig-rt_means2].

::: panel-tabset
#### Explicit task RT means

```{r explicit_task_rt_means_plotly}
#| label: fig-rt_means1
#| fig-cap: "Distribution of the mean RTs of participants in the explicit task (very high RT means have been cut for better readability)."
#| fig-height: 4

# ═══ RT means plot - Explicit task ════════════════════════════════════════════

(df_explicit_rt |>  
  group_by(subjectid) |>  
  summarise(mean = mean(rt)) |>  
  ggplot(aes(x = mean)) +
  geom_histogram(
    fill = "aquamarine2", 
    color = "aquamarine4", 
    alpha = .3,
    bins = 70
    # adjust = .4
    ) +
  labs(x = "Mean RT", y = "Number of participants") +
  scale_y_continuous(breaks = seq(0, 13, by = 1))) |>  
  ggplotly()
```

#### Implicit task RT means

```{r implicit_task_rt_means_plotly}
#| label: fig-rt_means2
#| fig-cap: "Distribution of the mean RTs of participants in the implicit task (very high RT means have been cut for better readability)."
#| fig-height: 4

# ═══ RT means plot - Implicit task ════════════════════════════════════════════

(df_implicit_rt |> 
  group_by(subjectid) |>  
  summarise(mean = mean(rt)) |>  
  ggplot(aes(x = mean)) +
  geom_histogram(
    fill = "coral2", 
    color = "coral4", 
    alpha = .3,
    bins = 70
    # adjust = .4
    ) +
  labs(x = "Mean RT", y = "Number of participants") +
  scale_y_continuous(breaks = seq(0, 9, by = 1))) |>  
  ggplotly()
```

#### RT means table

```{r rt_means_table}
#| label: tbl-rt_means
#| tbl-cap: "Descriptive statistics of the average RTs across the sample in both tasks."

# ═══ RT means table - Both tasks ══════════════════════════════════════════════

df_rt <- 
  list(
  df_explicit_rt |>  rename("Explicit task mean RTs" = rt), 
  df_implicit_rt |>  rename("Implicit task mean RTs" = rt)
  ) |>  
  imap(
    ~select(.x, contains("RT")) |> 
      report() |>  
      as.data.frame() |>  
      select(1:10)
    )

df_rt <- bind_rows(df_rt[[1]], df_rt[[2]])
df_rt |>  display()
```
:::

The median RT mean among participants is `r df_rt$Median[1]` in the explicit task, and `r df_rt$Median[2]` in the implicit one. Using an outlier detection procedure based on MADs, a common scaling factor to determine acceptable values is $\pm 3 \times MAD$: as 300ms is our chosen minimal value, this would result in our case in an acceptable range (in ms) of \[300,`r round(df_rt$Median[1] + 3*df_rt$MAD[1])`\] for the explicit task and \[300,`r round(df_rt$Median[2] + 3*df_rt$MAD[2])`\] for the implicit task.

```{r removing_rt_means_outliers}
#| code-summary: "Removing outliers with aberrant RT means"
#| echo: true
#| output: false

# ═══ Aberrant RT means outliers removal ═══════════════════════════════════════

# ─── Finding outliers ───

df_explicit_rt |>
  group_by(subjectid) |>
  summarise(mean_rt_explicit = mean(rt)) |>
  ungroup() |>
  filter(mean_rt_explicit > 1384) |>
  arrange(desc(mean_rt_explicit))

df_implicit_rt |>
  group_by(subjectid) |>
  summarise(mean_rt_implicit = mean(rt)) |>
  ungroup() |>
  filter(mean_rt_implicit > 1063) |>
  arrange(desc(mean_rt_implicit))

# ─── Removing specific outliers ───

df_explicit_rt <-
  df_explicit_rt |>
  filter(
    !(subjectid %in% c("dchimenton"))
  )

df_implicit_rt <-
  df_implicit_rt |>
  filter(
    !(subjectid %in% c(
      "mbilodeau",
      "rcarnez",
      "cbertrand",
      "omeyer"
    ))
  )
```

We will conduct a more detailed inspection of the RTs on a by-participant level. Once again, we are going to detect these outliers using MAD thresholds. The RTs have been group by subsets of conditions, as we know that our experimental conditions could have affected them: thus, using a global median would necessarily flatten within-participant outcomes and have a major impact on the analyses.

```{r removing_second_rt_outliers}
#| code-summary: "Removing individual outlier trials"
#| echo: true
#| output: false

# ═══ By-participant MAD outlier detection ═════════════════════════════════════

df_explicit_rt <- 
  df_explicit_rt |> 
  group_by(subjectid, congruence, color) |> 
  mutate(
    rt_mean = mean(rt),
    rt_mad = mad(rt)
    ) |> 
  filter(
    rt < rt_mean + 5 * rt_mad &
    rt > rt_mean - 2.5 * rt_mad
  ) |>
  ungroup()
# 8719 trials left
# (8939-8719)/8939 # 2.5% trials out

df_implicit_rt <-
  df_implicit_rt |> 
  group_by(subjectid, congruence, color) |> 
  mutate(
    rt_mean = mean(rt),
    rt_mad = mad(rt)
    ) |> 
  filter(
    rt < rt_mean + 5 * rt_mad &
    rt > rt_mean - 2.5 * rt_mad
  ) |>
  ungroup()
# 8391 trials left
# (8777-8391)/8777 # 4.4% trials out
```

::: {.panel-tabset .column-page-inset-right}
#### Explicit task RT per participant

```{r explicit_rt_per_participant_plotly}
#| label: fig-rt_per_participant_1
#| fig-cap: "Distribution of RTs in the explicit task for each participant. Each colored distribution represents a single participant. *Hover to see details on the individual distributions*."
#| fig-height: 5

# ═══ RTs per participant plot - Explicit task ═════════════════════════════════

(df_explicit_rt |>  
  ggplot(aes(x = rt, fill = subjectid)) +
  geom_density(alpha = .25, color = "black") +
  scale_x_continuous(name = "Response time", breaks = breaks_pretty(10)) +
  scale_y_continuous(name = "Density") +
  theme(
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank()
    ) +
  # coord_cartesian(
  #   xlim = c(380, 1700),
  #   ylim = c(0.0005, .01)
  # ) +
  scale_fill_viridis_d(guide = NULL) +
  scale_color_viridis_d(guide = NULL)) |>  
  ggplotly() |>  
  style(showlegend = FALSE)
```

#### Implicit task RT per participant

```{r implicit_rt_per_participant_plotly}
#| label: fig-rt_per_participant_2
#| fig-cap: "Distribution of RTs in the implicit task for each participant. Each colored distribution represents a single participant. *Hover to see details on the individual distributions*."
#| fig-height: 5

# ═══ RTs per participant plot - Implicit task ═════════════════════════════════

(df_implicit_rt |>  
  ggplot(aes(x = rt, fill = subjectid)) +
  geom_density(alpha = .25, color = "black") +
  scale_x_continuous(name = "Response time", breaks = breaks_pretty(5)) +
  scale_y_continuous(name = "Density") +
  theme(
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank()
    ) +
  # coord_cartesian(
  #   xlim = c(350, 1320),
  #   ylim = c(0.0005, .01)
  # ) +
  scale_fill_viridis_d(guide = NULL) +
  scale_color_viridis_d(guide = NULL)) |>  
  ggplotly() |>  
  style(showlegend = FALSE)
```
:::


# Inferential Analyses {#sec-inferential}

## Model description (Multilevel modelling)

### Predictors and outcome

Our analyses aim to evaluate the predictive abilities of several variables on one outcome, the **Response times** of the participants in the tasks. Our potential predictors are:

- **Group** membership, with two levels: aphantasia/phantasia

- **Congruence** conditions, with two levels: congruent and incongruent

- **Color** conditions, with two levels: colored and uncolored.

Sub-levels of the responses ("random effects") can also be accounted for:

- the dependency between response times for **each participant** (also referred to as *subjects*) caused by repeated measures

- the varying effects of **Congruence for each participant**

- the varying effects of **Color for each participant**.

This structure will be modeled using Multilevel Models (also called hierarchical or mixed models), allowing us to add the sub-levels of the hierarchy within participant measures we described above in the model. **RT data will be transformed using a Box-Cox transformation** to bring the distributions closer to normality and improve the quality of the models.

For a subject $i$ with a given *Group*/visual imagery, in the *Congruence* condition $j$ and the *Color* condition $k$, the maximal model of the resulting response time $RT_{ijk}$ including all the predictors can be specified as such:

$$
\begin{aligned}
RT_{ijk} = \alpha + \alpha_{subject[i]} + \beta_{1} \cdot \ Group_{i} \times (\beta_{2} + \beta_{2_{subject[i]}}) \cdot Congruence_{j} \times (\beta_{3} + \beta_{3_{subject[i]}}) \cdot Color_{k}
\end{aligned}
$$
Where $\alpha$ is the global intercept, $\alpha_{subject[i]}$ is a random intercept by subject accounting for the inherent randomness tied to participants, and $\beta_{1/2/3}$ are the parameters representing the effect of each predictor. The "$\times$" signs represent all the potential interactions along with fixed effects. Additionally, as one might expect the effect of the Congruence or Color conditions to have important variations between subjects (tied to cognitive processes and strategies), a slope $\beta_{2/3_{subject[i]}}$ by subject can be added to the Congruence or Color parameters to account for this variance. These random effects will be added if they contribute significantly to the quality of the models.

## Fitting the models

```{r fitting_lmms}

# ═══ Fitting Linear Mixed Models ══════════════════════════════════════════════

# ─── Preparing variable roles ─────────────────────────────────────────────────
model_recipe_ex <-
  df_explicit_rt |> 
  recipe() |> 
  update_role(rt, new_role = "outcome") |> 
  update_role(
    subjectid, age, aphantasia, color, congruence, 
    new_role = "predictor"
  ) |> 
  add_role(subjectid, new_role = "group") |> 
  step_BoxCox(rt)|> 
  step_normalize(rt)

model_recipe_im <-
  df_implicit_rt |> 
  recipe() |> 
  update_role(rt, new_role = "outcome") |> 
  update_role(
    subjectid, age, aphantasia, color, congruence, 
    new_role = "predictor"
  ) |> 
  add_role(subjectid, new_role = "group") |> 
  step_BoxCox(rt)|> 
  step_normalize(rt)

# ─── Specifying the distributions for the models ──────────────────────────────
model_lmm <-
  linear_reg() %>% 
  set_engine("lmer")

# listing it
model_specs <- list(model_lmm = model_lmm)

# ─── Writing down the formulas of our models ──────────────────────────────────
# null model
formula_0 <- rt ~ (1|subjectid)
# intercept by-participant only
formula_1 <- rt ~ (aphantasia + congruence + color)^3 + (1|subjectid)
# intercept and slope on congruence by-participant
formula_2 <- rt ~ (aphantasia + congruence + color)^3 + (congruence|subjectid)
# intercept and slope on color by-participant
formula_3 <- rt ~ (aphantasia + congruence + color)^3 + (color|subjectid)
# intercept and slope on congruence and color by-participant
# formula_4 <- rt ~ (aphantasia + congruence + color)^3 + (congruence|subjectid) + (color|subjectid)

# Listing these formulas
model_formulas <- list(
  formula_0 = formula_0,
  formula_1 = formula_1,
  formula_2 = formula_2,
  formula_3 = formula_3
  # formula_4 = formula_4
  )

# ─── Table to combine everything in workflows and fit the models ──────────────
# (
models_fitted <- 
  tribble(  ~recipe,     ~ task,      ~model,       ~formula,
    model_recipe_ex, "explicit", model_specs, model_formulas,
    model_recipe_im, "implicit", model_specs, model_formulas
  ) |> 
  # combining recipes with the model spec
  unnest_longer(model) |> 
  # combining them with formulas
  unnest_longer(formula) |>
  rowwise() |>
  mutate(
    # creating workflows
    workflow = list(
      workflow() |>
      add_recipe(recipe) |> 
      add_model(model, formula = formula)  
      ),
    # fitting all the workflows (models) for each task
    fitted_model = ifelse(
      task == "explicit",
      list(workflow |> fit(data = df_explicit_rt) |> extract_fit_engine()),
      list(workflow |> fit(data = df_implicit_rt) |> extract_fit_engine())
    ),
    # extracting the parameters of the models
    parameters = list(model_parameters(fitted_model)),
    # checking the convergence of the models
    convergence = check_convergence(fitted_model),
    # model quality indices
    model_perf = list(model_performance(fitted_model)),
    AIC  = model_perf[[1]],
    AICc = model_perf[[2]],
    BIC  = model_perf[[3]]
  ) |>
  ungroup() |> 
  select(-c(recipe, model, formula, workflow, model_perf))

# ─── Comparing the models' quality among those that converged ─────────────────
models_selection <-
  models_fitted |> 
  filter(
    formula_id != "formula_0" & 
    convergence == TRUE
  ) |> 
  group_by(task, model_id) |> 
  mutate(best_model = ifelse(AICc == min(AICc), TRUE, FALSE)) |> 
  filter(best_model == TRUE)
```

The second model including a slope by subject on Congruence is the most supported for both tasks. The parameters of these two models will be analysed in the following. First, let's check the assumptions of both models.

```{r check_the_best_models}
#| fig-label: fig-model_checks
#| fig-cap: "Checking the assumptions of all the models for both tasks."
#| fig-subcap: true
#| layout-ncol: 1

best_model_explicit <- models_selection$fitted_model[[1]]
best_model_implicit <- models_selection$fitted_model[[2]]

# characteristics to check
model_checks = c("pp_check", "linearity", "homogeneity", "vif", "outliers", "qq")

# ─── Model checks ───────────────────────────
p_model_checks_explicit <-
  best_model_explicit |> check_model(check = model_checks, detrend = FALSE)
p_model_checks_implicit <-
  best_model_implicit |> check_model(check = model_checks, detrend = FALSE)

ggexport(
  p_model_checks_explicit,
  filename = "plots/model_check_explicit.png",
  width = 1000,
  height = 800,
  dpi = 600
  )

ggexport(
  p_model_checks_implicit,
  filename = "plots/model_checks_implicit.png",
  width = 1000,
  height = 800,
  dpi = 600
  )
```


## Explicit task results

```{r model_explicit_contrasts}
# # model 5 contrasts between aphantasia and congruence levels
# c_ex_gcn <-
#   all_models_fitted[[1]][[5]] %>% 
#   estimate_contrasts(
#     contrast = c("aphantasia", "congruence"), 
#     lmerTest.limit = 9000, 
#     pbkrtest.limit = 9000,
#     p_adjust = "fdr"
#   ) %>% 
#   mutate(across(where(is.numeric), ~ round(.x, digits = 2)))
# 
# # model 5 contrasts between color levels
# c_ex_col <-
#   all_models_fitted[[1]][[5]] %>% 
#   estimate_contrasts(
#     contrast = c("color"), 
#     lmerTest.limit = 9000, 
#     pbkrtest.limit = 9000,
#     p_adjust = "fdr"
#   ) %>% 
#   mutate(across(where(is.numeric), ~ round(.x, digits = 2)))
```

The parameters of the best model for the explicit task are displayed in @tbl-model_explicit_params_table. The significant parameters in the explicit task are the Color and the interaction between the Group and the Congruence conditions. The **main effect of Color** indicate that participants responded quicker in the colored condition (Marginal contrast (colored - uncolored) = `r c_ex_col[1,3]`, CI = $[`r c_ex_col[1,4]` ; `r c_ex_col[1,5]`]$, SE = `r c_ex_col[1,6]`, $p < .001$), although this effect has no interaction with the other variables. The **interaction between Group and Congruence** reveals that non-aphantasics responded slower in the uncongruent condition, as this contrast is the only significant one in this interaction (Marginal contrast (non-aphantasic congruent - incongruent) = `r c_ex_gcn[1,3]`, CI = $[`r c_ex_gcn[1,4]` ; `r c_ex_gcn[1,5]`]$, SE = `r c_ex_gcn[1,6]`, $p < .001$). These effects are illustrated in @fig-model_explicit_ggarrange. Both estimates are $\lt 0.2$, which denotes a *very small* effect size according to most standardized differences interpretation guidelines (e.g. Cohen, 1988; Gignac & Szodorai, 2016; Lovakov & Agadullina, 2021).

```{r model_plots_ex}
#| label: fig-model_plots_ex
#| fig-cap: "Plots for the effects of interest in the explicit task."
#| fig-subcap:
#|   - "Group x Congruence interaction in the GLMM for the explicit task."
#|   - "Group x Congruence interaction in the LMM for the explicit task."

# marginal means predictions
best_model_explicit_preds <- 
  best_model_explicit |>  
  estimate_means(
    at = c("aphantasia", "congruence"), 
    lmerTest.limit = 9000, 
    pbkrtest.limit = 9000
    )

# marginal means predictions
best_model_implicit_preds <- 
  best_model_implicit |>  
  estimate_means(
    at = c("aphantasia", "congruence"), 
    lmerTest.limit = 9000, 
    pbkrtest.limit = 9000
    )

# # stats for the gcn interaction
# stats_mod_4_g_cng_full <- 
#   df_explicit_rt %>% 
#   standardize(rt_explicit) %>% 
#   group_by(aphantasia) %>% 
#   pairwise_wilcox_test(rt_explicit ~ congruence) %>% 
#   add_xy_position(x = "congruence", group = "aphantasia", dodge = dw) %>% 
#   mutate(y.position = 3.1) %>% 
#   filter(aphantasia == "no")
# 
# stats_mod_4_g_cng_zoom <- 
#   df_explicit_rt %>% 
#   standardize(rt_explicit) %>% 
#   group_by(aphantasia) %>% 
#   pairwise_wilcox_test(rt_explicit ~ congruence) %>% 
#   add_xy_position(x = "congruence", group = "aphantasia", dodge = dw) %>% 
#   mutate(y.position = c(.22, .3))
#   
# # ggplot stats display
# stat_pvalue_manual(
#   stats_mod_4_g_cng_full, 
#   label = "p.adj.signif", 
#   # tip.length = 0,
#   size = st
#   )

# ─── Model effects plots ───────────────────────────

# setting dodge width for all the geoms
dw <- .75
# stat text size
st <- 7
# legend and axis text size
txt <- 32

# plot
df_explicit_rt |>
  ggplot(aes(
    x = congruence,
    y = rt,
    fill = aphantasia,
    color = aphantasia
  )) +
  # linear modelling of the differences
  geom_line(
    data = best_model_explicit_preds,
    aes(
      y = Mean,
      group = aphantasia
    ),
    position = position_dodge(width = dw),
    linewidth = 1.5,
    linetype = 1,
    show.legend = FALSE
  ) +
  # predicted means of the model
  geom_pointrange2(
    data = best_model_explicit_preds,
    aes(
      x = congruence,
      y = Mean,
      ymin = CI_low,
      ymax = CI_high,
      group = aphantasia
      ),
    color = "black",
    position = position_dodge(width = dw),
    size = 1,
    linewidth = .75,
    show.legend = FALSE
  ) +
  # intercept
  geom_hline(yintercept = 0, linetype = 2) +
  labs(
    x = NULL,
    y = "Response time (ms)"
    ) +
  scale_x_discrete(labels = c("Congruent", "Incongruent")) +
  scale_fill_okabeito(name = "Aphantasia: ", labels = c("Yes", "No")) +
  scale_color_okabeito(guide = NULL)
```

```{r model_plots_im}
#| label: fig-model_plots_im
#| fig-cap: "Plots for the effects of interest in the implicit task."
#| fig-subcap:
#|   - "Group x Congruence interaction in the GLMM for the implicit task."
#|   - "Group x Congruence interaction in the LMM for the implicit task."

# ─── Model effects plot ───────────────────────────
df_implicit_rt |>
  ggplot(aes(
    x = congruence,
    y = rt,
    fill = aphantasia,
    color = aphantasia
  )) +
  # linear modelling of the differences
  geom_line(
    data = best_model_implicit_preds,
    aes(
      y = Mean,
      group = aphantasia
    ),
    position = position_dodge(width = dw),
    linewidth = 1.5,
    linetype = 1,
    show.legend = FALSE
  ) +
  # predicted means of the model
  geom_pointrange2(
    data = best_model_implicit_preds,
    aes(
      x = congruence,
      y = Mean,
      ymin = CI_low,
      ymax = CI_high,
      group = aphantasia
      ),
    color = "black",
    position = position_dodge(width = dw),
    size = 1,
    linewidth = .75,
    show.legend = FALSE
  ) +
  # intercept
  geom_hline(yintercept = 0, linetype = 2) +
  labs(
    x = NULL,
    y = "Response time (ms)"
    ) +
  scale_x_discrete(labels = c("Congruent", "Incongruent")) +
  scale_fill_okabeito(name = "Aphantasia: ", labels = c("Yes", "No")) +
  scale_color_okabeito(guide = NULL)
```

:::{.column-page-inset-right}

```{r model_explicit_ggarrange}
#| label: fig-model_explicit_ggarrange
#| fig-cap: "Visualization of the predictions of the optimal model for the explicit task. The bottom plots are 'zoomed' versions of the top ones on shorter (standard) RT ranges for clearer views of the model. The horizontal colored lines in the 'violins' (colored shapes outlining the distribution of responses) represent quantiles at 25, 50 and 75%. The black dots indicate marginal means predicted by the model whereas the black bars represent the credible intervals of these estimations. **Left:** The *Congruence* plots represent the estimates of the model at each Congruence condition and Group, highlighting the significant interaction between the two variables. **Right**: The *Color* plots represent the estimates at each Color condition and Group, highlighting the main effect of Color and non-significance of the interaction with the Group factor."
#| fig-width: 24
#| fig-height: 16

# p_mod_explicit_ggarrange <-
#   ggarrange(
#     p_mod_ex_gcn_full,
#     p_mod_ex_gcol_full,
#     p_mod_ex_gcn_zoom,
#     p_mod_ex_gcol_zoom,
#     labels = c("Congruence", "Color"),
#     label.x = c(-.1,.7),
#     vjust = -.2,
#     font.label = list(size = 38),
#     common.legend = TRUE,
#     legend = "top",
#     ncol = 2,
#     nrow = 2,
#     heights = c(1.3,1),
#     align = "v"
#   ) %>%
#   annotate_figure(
#     left = text_grob("Response time (standardized)", size = txt, rot = 90)
#     )

# p_mod_explicit_ggarrange
```

:::
  
## Implicit task results

```{r model_implicit_contrasts}

# # model 4 contrasts between aphantasia and congruence levels
# c_im_gcn <-
#   all_models_fitted[[2]][[4]] %>% 
#   estimate_contrasts(
#     contrast = c("aphantasia", "congruence"), 
#     lmerTest.limit = 9000, 
#     pbkrtest.limit = 9000,
#     p_adjust = "fdr"
#   ) %>% 
#   mutate(across(where(is.numeric), ~ round(.x, digits = 2)))
# 
# # model 4 contrasts between group levels
# c_im_group <-
#   all_models_fitted[[2]][[4]] %>% 
#   estimate_contrasts(
#     contrast = c("aphantasia"), 
#     lmerTest.limit = 9000, 
#     pbkrtest.limit = 9000,
#     p_adjust = "fdr"
#   ) %>% 
#   mutate(across(where(is.numeric), ~ round(.x, digits = 2)))
```

The parameters of the best model for the **implicit task** are displayed in @tbl-model_implicit_params_table. The only significant parameter is the **interaction between Group and Congruence**. This interaction shows that non-aphantasics only responded slower in the incongruent condition, which is the only significant contrast (Marginal contrast (non-aphantasic congruent - incongruent) = `r c_im_gcn[1,3]`, CI = $[`r c_im_gcn[1,4]`;`r c_im_gcn[1,5]`]$, SE = `r c_im_gcn[1,6]`, $p = `r c_im_gcn[1,9]`$). This effect is represented in @fig-model_implicit_ggarrange. This estimate $\lt 0.2$, which denotes a *very small* effect size.

# Further EDA: continuous analyses

## Continuous predictors: PCA

Theoretically, the four questionnaire variables - VVIQ, OSIQ-Object and Spatial, and SUIS - could be used as predictors (independent variables) for the RT outcomes (dependent variable) of the experiment. Three of these - VVIQ, OSIQ-Object and SUIS - evaluate visual imagery: yet here we only modeled the VVIQ as representative of visual imagery, what's more as a categorical predictor by dividing two groups based on it. In order to explore the potential of all these scales, we are going to run a Principal Component Analysis (PCA) on the four questionnaires' standardized scores to evaluate how many different constructs they represent. The suitability of the data for a PCA was assessed with Bartlett's test of sphericity (Bartlett, 1951), suggesting there was sufficient correlation in the data ($\chi^{2}$(55) = 408.01, p < .001) and the KMO measure of sampling adequacy (KMO = 0.73; see Kaiser, H. F., & Rice, J. (1974)). The Eigenvalues and variance explained by the PCA components computed, along with the loadings of each score on them, are displayed in @tbl-pca_tables.

```{r pca}
#| code-summary: "Computing the PCA"
#| echo: true

# ─── Principal Component Analysis ───
pca <- 
  principal_components(
    df_questionnaires[,4:7],
    n = "max",
    sort = TRUE,
    standardize = TRUE
    )
```

```{r pca_tables}
#| label: tbl-pca_tables
#| tbl-cap: "Results of the Principal Components Analysis."
#| tbl-subcap: 
#|   - "Loadings of each variable on the three components extracted by the PCA."
#|   - "Eigenvalues and variance explained by the three components extracted by the PCA."
#| layout-ncol: 2

# ─── Loadings ───
pca |> 
  as.data.frame() |>  
  mutate(Variable = case_when(
    Variable == "suis60" ~ "SUIS",
    Variable == "vviq80" ~ "VVIQ",
    Variable == "osiq_o75" ~ "OSIQ-O",
    Variable == "osiq_s75" ~ "OSIQ-S",
    TRUE ~ Variable
  )) |> 
  display()

# ─── Eigenvalues and variance ───
pca |> 
  summary() |> 
  as.data.frame() |>
  display()
```

The two first components (PC1 and PC2) explained 95% of the variance of the sample on the four scores (PC1 Eigenvalue = 2.84, 71% of the total variance explained, PC2 = 0.97, 24% of the total variance explained) and are the only meaningful ones in the PCA (PC3 explains 3% of variance). PC1 correlates highly with the VVIQ, OSIQ-Object and SUIS: this component can logically be interpreted as representing visual imagery (VI variable). PC2 also explains a significant part of variance, and correlates highly with the OSIQ-Spatial: we chose to interpret this component as representing spatial imagery (SI variable). These two variables, decorrelated by the PCA, are represented together in @fig-vi_si_corr.

```{r pca_data}
#| code-summary: "Adding the predicted PCA components to the data"
#| echo: true

# ─── Adding components to the data ───
pca_components <- pca |> predict()

df_questionnaires <-
  bind_cols(df_questionnaires[,1:8], pca_components[,1:2]) %>% 
  mutate(PC2 = -PC2) %>% 
  rename(
    "visual_imagery" = PC1,
    "spatial_imagery" = PC2
    )

# updating all the dataframes with the imagery variables
dfs <- 
  list( 
    implicit_task = df_implicit_rt, 
    explicit_task = df_explicit_rt
    ) %>%
  # adding the new variables to each dataframe
  imap(~left_join(
    .x |> select(-c(rt_mean, rt_mad)), 
    df_questionnaires %>% 
      select(
        # column to match with the correct participants
        subjectid, 
        # new variables to add
        visual_imagery, 
        spatial_imagery), 
    by = "subjectid") %>% 
      # reordering the final dfs
      select(
        subjectid, 
        age, aphantasia,
        visual_imagery, spatial_imagery,
        everything())
    )

df_implicit_rt <- dfs$implicit_task
df_explicit_rt <- dfs$explicit_task
rm(dfs)
```

## Modelling RTs with continuous predictors

Now that we have two new theoretically meaningful variables to explain our data, we can go back to model RTs again using these new predictors. 

For a subject $i$ with a given visual and spatial imagery (*VI* and *SI*), in the *Congruence* condition $j$ and the *Color* condition $k$, the new maximal model of the resulting response time $RT_{ijk}$ including all the predictors can be specified as such:

$$
\begin{aligned}
RT_{ijk} = \alpha + \alpha_{i} + \beta_{1} \cdot \ VI_{i} \times \beta_{2} \cdot \ SI_{i} \times (\beta_{3} + \beta_{3i}) \cdot Congruence_{j} \times (\beta_{4} + \beta_{4i}) \cdot Color_{k}
\end{aligned}
$$

Where $\alpha$ is the global intercept, $\alpha_{i}$ is a random intercept by subject accounting for the inherent randomness tied to participants, and $\beta_{1/2/3/4}$ are the parameters representing the effect of each predictor. The "$\times$" signs represent all the potential interactions along with fixed effects. Additionally, as one might expect the effect of the Congruence or Color conditions to have important variations between subjects (tied to cognitive processes and strategies), a slope $\beta_{3i/4i}$ by subject can be added to the Congruence or Color parameters to account for this variance. Likewise, several models will be fitted in turn with the same pattern as above. Only models including two-way interactions between the four factors have been kept, as three and four-way interactions were not improving the quality of the models in any way.


```{r fitting_continuous_lmms}

# ═══ Fitting Linear Mixed Models ══════════════════════════════════════════════

# ─── Preparing variable roles ─────────────────────────────────────────────────
model_recipe_ex_continuous <-
  df_explicit_rt |> 
  recipe() |> 
  update_role(rt, new_role = "outcome") |> 
  update_role(
    subjectid, age, visual_imagery, spatial_imagery, color, congruence, 
    new_role = "predictor"
  ) |> 
  add_role(subjectid, new_role = "group") |> 
  step_BoxCox(rt)|> 
  step_normalize(rt)

model_recipe_im_continuous <-
  df_implicit_rt |> 
  recipe() |> 
  update_role(rt, new_role = "outcome") |> 
  update_role(
    subjectid, age, visual_imagery, spatial_imagery, color, congruence, 
    new_role = "predictor"
  ) |> 
  add_role(subjectid, new_role = "group") |> 
  step_BoxCox(rt)|> 
  step_normalize(rt)

# ─── Writing down the formulas of our models ──────────────────────────────────
# null model
formula_0_continuous <- rt ~ (1|subjectid)
# intercept by-participant only
formula_1_continuous <- rt ~ (visual_imagery + spatial_imagery + congruence + color)^2 + (1|subjectid)
# intercept and slope on congruence by-participant
formula_2_continuous <- rt ~ (visual_imagery + spatial_imagery + congruence + color)^2 + (congruence|subjectid)
# intercept and slope on color by-participant
formula_3_continuous <- rt ~ (visual_imagery + spatial_imagery + congruence + color)^2 + (color|subjectid)

# Listing these formulas
model_formulas_continuous <- list(
  formula_0 = formula_0_continuous,
  formula_1 = formula_1_continuous,
  formula_2 = formula_2_continuous,
  formula_3 = formula_3_continuous
  # formula_4 = formula_4
  )

# ─── Table to combine everything in workflows and fit the models ──────────────
# (
models_fitted_continuous <- 
  tribble(             ~recipe,     ~ task,      ~model,                  ~formula,
    model_recipe_ex_continuous, "explicit", model_specs, model_formulas_continuous,
    model_recipe_im_continuous, "implicit", model_specs, model_formulas_continuous
  ) |> 
  # combining recipes with the model spec
  unnest_longer(model) |> 
  # combining them with formulas
  unnest_longer(formula) |>
  rowwise() |>
  mutate(
    # creating workflows
    workflow = list(
      workflow() |>
      add_recipe(recipe) |> 
      add_model(model, formula = formula)  
      ),
    # fitting all the workflows (models) for each task
    fitted_model = ifelse(
      task == "explicit",
      list(workflow |> fit(data = df_explicit_rt) |> extract_fit_engine()),
      list(workflow |> fit(data = df_implicit_rt) |> extract_fit_engine())
    ),
    # extracting the parameters of the models
    parameters = list(model_parameters(fitted_model)),
    # checking the convergence of the models
    convergence = check_convergence(fitted_model),
    # model quality indices
    model_perf = list(model_performance(fitted_model)),
    AIC  = model_perf[[1]],
    AICc = model_perf[[2]],
    BIC  = model_perf[[3]]
  ) |>
  ungroup() |> 
  select(-c(recipe, model, formula, workflow, model_perf))

# ─── Comparing the models' quality among those that converged ─────────────────
models_selection_continuous <-
  models_fitted_continuous |> 
  filter(
    formula_id != "formula_0" & 
    convergence == TRUE
  ) |> 
  group_by(task, model_id) |> 
  mutate(best_model = ifelse(AICc == min(AICc), TRUE, FALSE)) |> 
  filter(best_model == TRUE)
```



## Explicit task results

The best model for the RTs in the explicit task included a random intercept and slope by participant on the Color condition (AIC = 19,474, cAIC = 19,474, null model AIC = 19,582), and had a substantial explanatory power (conditional $R^{2}$ = .53). The parameters of this model are displayed in @tbl-new_model_explicit_params_table The significant parameters in this task are the Congruence, the Color, the interaction between VI and SI and the interaction between VI and Congruence. The main effect of Congruence and Color indicate that participants responded overall slower in the incongruent condition ($\beta$  = 0.06,  95\% CI [0.02, 0.11], *t*(8888) = 3.09, *p* = .002) and in the uncolored condition ($\beta$  = 0.13,  95\% CI [0.09, 0.18], *t*(8888) = 6.06, *p* $<$ .001). The interaction between VI and SI ($\beta$ = 0.08, 95\% CI [0.01, 0.16], *t*(8891) = 2.28, *p* = .023) reveals that RTs are longer with higher VI and SI. Finally, the interaction between VI and Congruence ($\beta$ = 0.03, 95\% CI [0.00, 0.04], *t*(8888) = 2.14, *p* = .003) reveals that a higher VI leads to slower RTs in the incongruent condition. The two new interaction effects tied to the continuous variables are represented in @fig-models_continuous. All estimates are $< 0.2$, which denotes small effect sizes.

```{r tbl-}
#| label: tbl-new_model_explicit_params_table
#| tbl-cap: "Parameters of the optimal model for the explicit task including a random intercept and slope by subject on Color."

all_b_models_parameters[["explicit_b_mods"]][["mod_explicit_5b"]] |> 
  format() |>
  display()
```

```{r plot_vi_congruence_explicit}
df_explicit_recipe_b <- 
  recipe_explicit_b |> 
  prep() |> 
  bake(df_explicit_rt) 

vizdata_vi_cng_explicit <- 
  df_explicit_recipe_b |> 
  visualisation_matrix(
    at = c("visual_imagery", "congruence"),
    length = 100,
    preserve_range = TRUE
)

vizdata_vi_cng_explicit <- 
  vizdata_vi_cng_explicit |> 
  mutate(predicted = insight::get_predicted(
    all_b_models_fitted[["explicit_b_mods"]][["mod_explicit_5b"]], 
    vizdata_vi_cng_explicit
    )) |> 
  mutate(congruence = ifelse(congruence == "congruent", "Congruent", "Incongruent"))

p_b_mod_ex_vicng <-
  df_explicit_recipe_b |> 
  mutate(congruence = ifelse(congruence == "congruent", "Congruent", "Incongruent")) |>  
  ggplot(aes(
    x = visual_imagery,
    y = rt_explicit,
    color = congruence
  )) +
  geom_point(
    size = 1,
    alpha = .2
  ) +
  geom_line(
    data = vizdata_vi_cng_explicit,
    aes(
      y = predicted,
      group = congruence
    ),
    size = 1.5
  ) +
  geom_vline(xintercept = 0, linetype = 2) +
  coord_cartesian(
    ylim = c(-2,-.7)
  ) +
  labs(
    title = "Explicit task",
    x = "",
    y = ""
    ) +
  scale_color_lancet(name = "Congruence") +
  theme(
    title = element_text(size = txt),
    axis.text = element_text(size = txt/2),
    legend.text = element_text(size = txt),
    legend.title = element_text(size = txt)
    )
```

```{r plot_vi_si_explicit}
vizdata_vi_si_explicit <-
  df_explicit_recipe_b |> 
  visualisation_matrix(c("visual_imagery", "spatial_imagery"), length = 100) |> 
  visualisation_matrix("visual_imagery", length = 15, numerics = "all") 

vizdata_vi_si_explicit$predicted <- 
  insight::get_predicted(
    all_b_models_fitted[["explicit_b_mods"]][["mod_explicit_5b"]], 
    vizdata_vi_si_explicit
    )

p_b_mod_ex_visi <-
  df_explicit_recipe_b |> 
  ggplot(aes(
    x = visual_imagery,
    y = rt_explicit,
    color = spatial_imagery
    )) +
  geom_point(
    size = 1,
    alpha = .1
  ) +
  geom_line(
    data = vizdata_vi_si_explicit,
    aes(
      y = predicted,
      group = spatial_imagery
      ),
    size = 1
  ) +
  geom_vline(xintercept = 0, linetype = 2) +
  coord_cartesian(
    ylim = c(-3.5,1)
  ) +
  labs(
    title = "Explicit task",
    x = "",
    y = ""
    ) +
  scale_color_viridis(name = "Spatial imagery") +
  theme(
    title = element_text(size = txt),
    axis.text = element_text(size = txt/2),
    legend.text = element_text(size = txt/2),
    legend.title = element_text(size = txt)
    )
```


## Implicit task results

The best model for the RTs in the implicit task included a random intercept and slope by participant on the Congruence condition (AIC = 22,109, cAIC = 22,109, null model AIC = 22,116), and had a substantial explanatory power (conditional $R^{2}$ = .35). The parameters of this model are displayed in @tbl-new_model_implicit_params_table. The significant parameters in this task are the interaction between VI and Congruence, along with a trend towards an interaction between VI and SI. The interaction between VI and Congruence shows that a higher VI is associated with slower responses in the incongruent condition ($\beta$  = 0.03, SE = 0.01, 95\% CI [0.01, 0.05], *t*(8874) = 2.58, *p* = .01). The trend interaction between VI and SI ($\beta$  = 0.06, SE = 0.03, 95\% CI [0.00, 0.12], *t*(8874) = 1.83, *p* = .067) reveals that RTs are longer with a higher VI and SI. The two new interaction effects tied to the continuous variables are represented in @fig-models_continuous. All estimates are $< 0.2$, which denotes small effect sizes.

```{r new_model_implicit_params_table}
#| label: tbl-new_model_implicit_params_table
#| tbl-cap: "Parameters of the optimal model for the implicit task including a random intercept and slope by subject on Congruence."

all_b_models_parameters[["implicit_b_mods"]][["mod_implicit_4b"]] |> 
  format() |>
  display()
```

```{r plot_vi_congruence_implicit}
df_implicit_recipe_b <- 
  recipe_implicit_b |> 
  prep() |> 
  bake(df_implicit_rt) 

vizdata_vi_cng_implicit <- 
  df_implicit_recipe_b |> 
  visualisation_matrix(
    at = c("visual_imagery", "congruence"),
    length = 100,
    preserve_range = TRUE
)

vizdata_vi_cng_implicit <- 
  vizdata_vi_cng_implicit |> 
  mutate(predicted = insight::get_predicted(
    all_b_models_fitted[["explicit_b_mods"]][["mod_explicit_5b"]], 
    vizdata_vi_cng_implicit
    )) |> 
  mutate(congruence = ifelse(congruence == "congruent", "Congruent", "Incongruent"))

p_b_mod_im_vicng <-
  df_implicit_recipe_b |> 
  mutate(congruence = ifelse(congruence == "congruent", "Congruent", "Incongruent")) |> 
  ggplot(aes(
    x = visual_imagery,
    y = rt_implicit,
    color = congruence
  )) +
  geom_point(
    size = 1,
    alpha = .2
  ) +
  geom_line(
    data = vizdata_vi_cng_implicit,
    aes(
      y = predicted,
      group = congruence
    ),
    size = 1.5
  ) +
  geom_vline(xintercept = 0, linetype = 2) +
  coord_cartesian(
    ylim = c(-2,-.7)
  ) +
  labs(
    title = "Implicit task",
    x = "",
    y = ""
    ) +
  scale_color_lancet(name = "Congruence") +
  theme(
    plot.title = element_text(hjust = 1),
    title = element_text(size = txt),
    axis.text = element_text(size = txt/2),
    legend.text = element_text(size = txt),
    legend.title = element_text(size = txt)
    )
```

```{r plot_vi_si_implicit}
vizdata_implicit <-
  df_implicit_recipe_b |> 
  visualisation_matrix(c("visual_imagery", "spatial_imagery"), length = 100) |> 
  visualisation_matrix("visual_imagery", length = 15, numerics = "all") 

vizdata_implicit$predicted <- insight::get_predicted(all_b_models_fitted[["explicit_b_mods"]][["mod_explicit_5b"]], vizdata_implicit)

p_b_mod_im_visi <-
  df_implicit_recipe_b |> 
  ggplot(aes(
    x = visual_imagery,
    y = rt_implicit,
    color = spatial_imagery
    )) +
  geom_point(
    size = 1,
    alpha = .1
  ) +
  geom_line(
    data = vizdata_implicit,
    aes(
      y = predicted,
      group = spatial_imagery
      ),
    size = 1
  ) +
  geom_vline(xintercept = 0, linetype = 2) +
  coord_cartesian(
    ylim = c(-3.5,1)
  ) +
  labs(
    title = "Implicit task",
    x = "",
    y = ""
    ) +
  scale_color_viridis(name = "Spatial imagery") +
  theme(
    plot.title = element_text(hjust = 1),
    title = element_text(size = txt),
    axis.text = element_text(size = txt/2),
    legend.text = element_text(size = txt/2),
    legend.title = element_text(size = txt)
    )
```

```{r b_models_ggarrange}
#| label: fig-models_continuous
#| fig-cap: "Visualization of the variables in the optimal models for the RTs in both tasks. The black dotted vertical line is at 0, the mean of the standard VI variable."
#| fig-subcap: 
#|   - "Visualization of the VI and Congruence variables. The straight lines represent the model at each level of the Congruence variable to illustrate the interaction between VI and Congruence, while transparent dots represent individual trials' standardized RTs."
#|   - "Visualization of the VI and SI variables. The straight lines represent the model at fixed levels of the continuous SI variable to illustrate the interaction between VI and SI, while transparent dots represent individual trials' standardized RTs."
#| fig-width: 16
#| fig-height: 8
#| column: page-inset-right

p_b_mods_vicng_ggarrange <-
  ggarrange(
    p_b_mod_ex_vicng,
    p_b_mod_im_vicng,
    common.legend = TRUE,
    legend = "top",
    ncol = 2,
    align = "v"
  ) |> 
  annotate_figure(
    left = text_grob(
      "Response time (standardized)", 
      size = txt, 
      rot = 90
      ),
    bottom = text_grob(
      "Visual imagery (standardized PCA variable)", 
      size = txt,
      vjust = .05
      )
    )

p_b_mods_visi_ggarrange <-
  ggarrange(
    p_b_mod_ex_visi,
    p_b_mod_im_visi,
    common.legend = TRUE,
    legend = "top",
    ncol = 2,
    align = "v"
  ) |> 
  annotate_figure(
    left = text_grob(
      "Response time (standardized)", 
      size = txt, 
      rot = 90
      ),
    bottom = text_grob(
      "Visual imagery (standardized PCA variable)", 
      size = txt,
      vjust = .05
      )
    )

p_b_mods_vicng_ggarrange

p_b_mods_visi_ggarrange

# ggexport(
#   p_b_mods_vicng_ggarrange, 
#   filename = "plots/model_continuous_vicng.png",
#   width = 1600,
#   height = 800
#   )
# 
# ggexport(
#   p_b_mods_visi_ggarrange, 
#   filename = "plots/model_continuous_visi.png",
#   width = 1600,
#   height = 800
#   )
```


<!-- The End -->
:::{.callout-note collapse="true" appearance="simple"}

#### R Session information

```{r session_information}
report_system()
```

The following packages were used:

```{r packages}
report_packages(
  session = sessionInfo(),
  include_R = FALSE
  )
```

:::








































