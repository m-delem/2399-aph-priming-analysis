---
title: "Supplementary Materials - Data analysis report"
subtitle: "No sensory visual imagery in aphantasia? An intricate question when it comes to priming"
author: 
  - name: Maël Delem
    orcid: 0009-0005-8518-1991
  - name: Rudy Purkart
    orcid: 0000-0002-5491-9958
  - name: Eddy Cavalli
    orcid: 0000-0003-3944-1973
  - name: Virginie Ranson
  - name: Charlotte Andrey
  - name: Rémy Versace
    orcid: 0000-0002-4219-6617
  - name: Gaën Plancher
    orcid: 0000-0002-0178-6207
date: 2023-11-03
date-modified: last-modified
date-format: "D/MM/YYYY"
format:
  html: default
editor_options: 
  chunk_output_type: inline
crossref: 
  fig-title:  "Figure S-"
  fig-prefix: "Figure S-"
  tbl-title:  "Table S-"
  tbl-prefix: "Table S-"
  chapters: true
---

<!-- CSS options for custom title numbers styling-->

```{=html}
<style>
.header-section-number:before {
  content: "S ";
}
.header-section-number:after {
  content: ". ";
}
</style>
```

# Preliminary Set-up {.unnumbered}

::: {.callout-note collapse="true" appearance="simple"}
## Datasets, code availability, software and setup

The data is retrieved from the file `data/aphantasia_priming_tidy_data.xlsx`, which contains four sheets, containing the raw data, the data from the association, explicit, and implicit task respectively.

This analysis was conducted in R language on [RStudio](https://posit.co/download/rstudio-desktop/). This analysis report was written with [Quarto](https://quarto.org/).

The code generating all the computations, figures, tables, etc. (only partially exposed here for clarity) can be found in the `analysis-report.qmd` Quarto file, for which the best reading software are coding Integrated Development Environments (IDE) like [RStudio](https://posit.co/download/rstudio-desktop/) or [Visual Studio Code](https://code.visualstudio.com/). The file includes detailed commentaries along with the code to ease understanding, accessibility, and welcome criticism. The code for heavy computations is not re-run upon rendering the Quarto file to `.docx` or HTML, but can be ran manually in the R code chunks of the file itself if one wishes to re-run the analyses.

Down below is the set-up code, including two essential steps:

1.  Installing the required packages for this data analysis

2.  importing data into the dataframes used throughout.

```{r setup}
#| output: false
#| code-summary: "Packages"

# The package `librairian` will ease the package management with the "shelf" 
# function, which automatically: 
# 1) checks if a package is installed 
# 2) installs it if need be
# 3) loads the package like the "library()" function would.
if (!require(librarian)) install.packages(librarian)
library(librarian)

# now putting packages on our library's shelves:
shelf(
  # ─── data management ─────────────────
  readxl,         # importing xlsx
  
  # ─── modelling ───────────────────────
  lme4,           # mixed models
  emmeans,        # marginal estimates
  statmod,        # easystats dependency
  doParallel,     # parallel execution
  multilevelmod,  # multilevel modelling with lmer and tidymodels
  simr,           # simulation for power analysis
  
  # ─── data visualization ──────────────
  ggpubr,         # publication plots
  plotly,         # interactive plots
  gt,             # tables
  
  # ─── essential package collections ───
  easystats,      # data analysis framework
  tidymodels,     # modelling framework
  tidyverse       # modern R ecosystem
)

# ─── Fixing a seed for reproducibility ───
set.seed(14051998)
```

```{r importing_data}
#| output: false
#| code-summary: "Importing data"

# Implicit task
df_implicit <- 
  read_excel(
    "data/aphantasia_priming_tidy_data.xlsx",
    sheet = "data_implicit"
    ) |> 
  rename("rt" = rt_implicit) |> 
  # converting RTs to seconds
  mutate(rt = rt/1000)

# Explicit task
df_explicit <- 
  read_excel(
    "data/aphantasia_priming_tidy_data.xlsx",
    sheet = "data_explicit"
    ) |> 
  rename("rt" = rt_explicit) |> 
  # convert RTs to seconds
  mutate(rt = rt/1000)

# Questionnaires
df_questionnaires <- 
  read_excel(
    "data/aphantasia_priming_tidy_data.xlsx",
    sheet = "data_questionnaires"
    ) %>% 
  # creating the a/phantasia groups
  mutate(
    aphantasia = ifelse(vviq80 < 32, "yes", "no"),
    aphantasia = fct_relevel(aphantasia, "yes", "no")
    )

# updating all the dataframes with the questionnaires data
dfs <- 
  list(
    implicit_task = df_implicit, 
    explicit_task = df_explicit
    ) |> 
  # adding the vviq and group column to every dataframe
  imap(~left_join(
    .x, 
    df_questionnaires |>  
      select(
        # column to match with the correct participants
        subjectid, 
        # new variables to add
        age,
        sexe,
        vviq80,
        aphantasia), by = "subjectid") |>  
      rename("sex" = sexe) |>  
      # reordering the final dfs
      select(
        subjectid, 
        age, sex, aphantasia,
        vviq80,
        everything())
    )

df_implicit <- dfs$implicit_task
df_explicit <- dfs$explicit_task
rm(dfs)
```
:::

# Self-report questionnaires

We modeled the scores at each questionnaire with Generalized Linear Models (GLMs) to accommodate the non-normal distributions in the sample. To ensure the best fit to the data, we fitted models with Gaussian, Gamma and inverse Gaussian distributions  and compared thel with the AIC and BIC as indices of model quality. The code of the model fitting workflow using the `tidymodels` R package is available below. The quality checks of the optimal models selected, that used Gamma distributions, are displayed in @fig-vviq-model and subsequent tabs. The summary of the estimated marginal means and post-hoc contrast analyses of between-group differences is presented in @tbl-questionnaire-results and depicted in @fig-questionnaire-results.

```{r fitting-glm-questionnaires}
#| output: false
#| code-summary: "Fitting GLMs on questionnaire scores with `tidymodels`"

# ─── Defining a tidymodels "recipe" to prepare the data ───────────────────────
model_recipe_glm <-
  df_questionnaires |> 
  recipe() |> 
  # declaring scores as dependent variables
  update_role(vviq80, suis60, osiq_o75, osiq_s75, new_role = "outcome") |> 
  # declaring groups and age as independent variables
  update_role(aphantasia, age, new_role = "predictor")

# ─── Specifying models with various distributions to be compared ──────────────

# Gaussian distribution
glm_gaussian <-
  linear_reg() |> 
  set_engine(
    "glm",
    family = gaussian()
    )

# Gamma distribution
glm_gamma <-
  linear_reg() |> 
  set_engine(
    "glm",
    family = Gamma()
    )

# Inverse Gaussian distribution
glm_inverse <-
  linear_reg() |> 
  set_engine(
    "glm",
    family = inverse.gaussian()
    )

# Listing these models
model_specs_glm <- list(
  glm_gaussian = glm_gaussian,
  glm_gamma    = glm_gamma,
  glm_inverse  = glm_inverse
)

# ─── Formulas for each questionnaire model ────────────────────────────────────
formula_q1 <-   vviq80 ~ aphantasia*age
formula_q2 <-   suis60 ~ aphantasia*age
formula_q3 <- osiq_o75 ~ aphantasia*age
formula_q4 <- osiq_s75 ~ aphantasia*age

# Listing these formulas
model_formulas_glm <- list(
  formula_q1 = formula_q1,
  formula_q2 = formula_q2,
  formula_q3 = formula_q3,
  formula_q4 = formula_q4
)

# ─── Table to combine everything in workflows and fit the models ──────────────

model_all_glm_fitted <-
  tribble(   ~recipe,          ~model,           ~formula,
    model_recipe_glm, model_specs_glm, model_formulas_glm
  ) |> 
  # combining recipes with models
  unnest_longer(model) |> 
  # combining them with formulas
  unnest_longer(formula) |>
  rowwise() |>
  mutate(
    # fitting models
    fitted_model = list(
      workflow() |>
      add_recipe(recipe) |> 
      add_model(model, formula = formula) |> 
      fit(df_questionnaires) |> 
      extract_fit_engine()
      )
  ) |> 
  select(!c(recipe, model, formula)) |>
  mutate(
    parameters = list(model_parameters(fitted_model)),
    model_perf = list(model_performance(fitted_model)),
    AICc  = model_perf[[2]]
  ) |> 
  select(!c(model_perf)) |> 
  arrange(formula_id)
```


::: {.panel-tabset .column-page-inset-right}
### VVIQ Model checks

```{r running-model-checks-vviq}
#| eval: false
#| code-summary: "Running model checks"

# loading the model saved after the analysis
model_vviq <- readRDS(file = "analyses-results/00-model-vviq.RDS")

# plotting
model_vviq |> check_model(check = "all")
```

![Model assumption checks for the Generalized Linear Model fit on the VVIQ scores.](plots/S0-glm-vviq-checks.png){#fig-vviq-model}

### SUIS Model checks

```{r running-model-checks-suis}
#| eval: false
#| code-summary: "Running model checks"

# loading the model saved after the analysis
model_suis <- readRDS(file = "analyses-results/00-model-suis.RDS")

# plotting
model_suis |> check_model(check = "all")
```

![Model assumption checks for the Generalized Linear Model fit on the VVIQ scores.](plots/S0-glm-suis-checks.png){#fig-suis-model}

### OSIQ-Object Model checks

```{r running-model-checks-osiqo}
#| eval: false
#| code-summary: "Running model checks"

# loading the model saved after the analysis
model_osiq_o <- readRDS(file = "analyses-results/00-model-osiq-o.RDS")

# plotting
model_osiq_o |> check_model(check = "all")
```

![Model assumption checks for the Generalized Linear Model fit on the VVIQ scores.](plots/S0-glm-osiq-o-checks.png){#fig-osiqo-model}

### OSIQ-Spatial Model checks

```{r running-model-checks-osiqs}
#| eval: false
#| code-summary: "Running model checks"

# loading the model saved after the analysis
model_osiq_s <- readRDS(file = "analyses-results/00-model-osiq-s.RDS")

# plotting
model_osiq_s |> check_model(check = "all")
```

![Model assumption checks for the Generalized Linear Model fit on the VVIQ scores.](plots/S0-glm-osiq-s-checks.png){#fig-osiqs-model}
:::

```{r loading-rds-questionnaires}
#| echo: false

model_vviq   <- readRDS(file = "analyses-results/00-model-vviq.RDS")
model_suis   <- readRDS(file = "analyses-results/00-model-suis.RDS")
model_osiq_o <- readRDS(file = "analyses-results/00-model-osiq-o.RDS")
model_osiq_s <- readRDS(file = "analyses-results/00-model-osiq-s.RDS")
```

```{r table-questionnaire-results}
#| label: tbl-questionnaire-results
#| code-summary: "Generating the summary table of the model results"
#| tbl-cap: "Estimated marginal means (± standard errors) of the groups at each questionnaire and results of the post-hoc contrast analyses of between-group differences."

# ─── Creating a function to extract all the information from a model ──────────
generate_model_summary <- 
  function(model, questionnaire_name){
    table_summary <-
      estimate_means(model, at = "aphantasia", p_adjust = "fdr") |> 
      select(!c(CI_low, CI_high)) |>
      mutate(across(c(Mean, SE), ~as.character(round(.x, digits = 2)))) |> 
      unite("Mean ± SE", Mean:SE, sep = " ± ") |> 
      pivot_wider(
        names_from = aphantasia,
        values_from = "Mean ± SE"
      ) |> 
      mutate(Questionnaire = questionnaire_name) |> 
      rename(
        "Aphantasics" = yes,
        "Controls" = no
      ) |> 
      select(Questionnaire, everything()) |> 
      bind_cols(
        estimate_contrasts(
          model, 
          contrast = "aphantasia", 
          p_adjust = "fdr")[,7:9]
      ) 
    
    return(table_summary)
}

# ─── Merging the resulting tables of each questionnaire ───────────────────────
table_vviq   <- generate_model_summary(model_vviq,   "VVIQ")
table_suis   <- generate_model_summary(model_suis,   "SUIS")
table_osiq_o <- generate_model_summary(model_osiq_o, "OSIQ-Object")
table_osiq_s <- generate_model_summary(model_osiq_s, "OSIQ-Spatial")

table_questionnaire_results <-
  bind_rows(
    table_vviq,
    table_suis,
    table_osiq_o,
    table_osiq_s
  )

# ─── Displaying ───────────────────────────────────────────────────────────────
table_questionnaire_results |>
  gt() |> 
  cols_align(
    align = "center",
    columns = 2:6
  ) |> 
  fmt_markdown(columns = 1:6) |> 
  fmt_number(columns = 5, decimals = 2) |> 
  fmt_scientific(columns = 6) |> 
  tab_options(table.width = pct(100)) |> 
  tab_style(
    style = cell_text(style = "italic"),
    locations = cells_column_labels(columns = 5:6)
  )
```

```{r standardized-questionnaire-plots}
#| label: fig-questionnaire-results
#| code-summary: "Generating the standardized model plots"
#| fig-cap: "Visualization of self-report questionnaires results for aphantasics and controls. Violin plots depict the distributions and quantiles of the scores in each group, median-centered on each scale. Colored dots depict marginal means estimated by the models fitted on the scores, while the solid lines represent their 95% confidence intervals. On the vertical axis, 0.0 is the normalized lowest possible score, 0.5 the median score, and 1 the maximum possible score for each questionnaire. Stars denote *p*-values inferior to .001 for each pairwise contrast between groups."
#| out-width: 100%

# ─── Standardized model refits for the plots ──────────────────────────────────
df_questionnaires_standard <-
  df_questionnaires |>
  mutate(
    vviq80   = as.numeric(scales::rescale(vviq80, 
                                          from = c(16, 80), 
                                          to = c(0, 1))),
    suis60   = as.numeric(scales::rescale(suis60, 
                                          from = c(12, 60), 
                                          to = c(0, 1))),
    osiq_o75 = as.numeric(scales::rescale(osiq_o75, 
                                          from = c(15, 75), 
                                          to = c(0, 1))),
    osiq_s75 = as.numeric(scales::rescale(osiq_s75, 
                                          from = c(15, 75), 
                                          to = c(0., 1)))
    )

model_recipe_glm_standard <-
  df_questionnaires_standard |> 
  recipe() |> 
  update_role(vviq80, suis60, osiq_o75, osiq_s75, new_role = "outcome") |> 
  update_role(aphantasia, age, new_role = "predictor")

model_specs_glm_standard<- list(glm_gaussian = glm_gaussian)

model_all_glm_fitted_standard <-
  tribble(            ~recipe,                   ~model,           ~formula,
    model_recipe_glm_standard, model_specs_glm_standard, model_formulas_glm
  ) |> 
  # combining recipes with models
  unnest_longer(model) |> 
  # combining them with formulas
  unnest_longer(formula) |>
  rowwise() |>
  mutate(
    # fitting models
    fitted_model = list(
      workflow() |>
      add_recipe(recipe) |> 
      add_model(model, formula = formula) |> 
      fit(df_questionnaires_standard) |> 
      extract_fit_engine()
      )
  ) |> 
  select(!c(recipe, model, formula)) |> 
  arrange(formula_id)

model_vviq_standard   <- model_all_glm_fitted_standard[[3]][[1]]
model_suis_standard   <- model_all_glm_fitted_standard[[3]][[2]]
model_osiq_o_standard <- model_all_glm_fitted_standard[[3]][[3]]
model_osiq_s_standard <- model_all_glm_fitted_standard[[3]][[4]]

# ─── Settings for the plot ────────────────────────────────────────────────────

# calculating marginal means and CIs
marginal_vviq   <- estimate_means(model_vviq_standard,   at = "aphantasia")
marginal_suis   <- estimate_means(model_suis_standard,   at = "aphantasia")
marginal_osiq_o <- estimate_means(model_osiq_o_standard, at = "aphantasia")
marginal_osiq_s <- estimate_means(model_osiq_s_standard, at = "aphantasia")
 
marginal_means <-
  marginal_vviq |> 
  mutate(variable = "vviq80") |> 
  bind_rows(marginal_suis   |> mutate(variable = "suis60")) |> 
  bind_rows(marginal_osiq_o |> mutate(variable = "osiq_o75")) |> 
  bind_rows(marginal_osiq_s |> mutate(variable = "osiq_s75"))

# dodge width for all the geoms
dw <- 1
# axis text size
txt <- 14
# legend text size
txt_legend <- 12

# ─── Plotting ─────────────────────────────────────────────────────────────────
df_questionnaires_standard |> 
  pivot_longer(
    cols = c(vviq80, suis60, osiq_o75, osiq_s75),
    names_to = "variable"
  ) |> 
  ggplot(aes(
    x = fct_relevel(variable, c("vviq80", "suis60", "osiq_o75", "osiq_s75")),
    y = value,
    fill = aphantasia,
    color = aphantasia
  )) +
  # accentuation of the median line at 0.5
  geom_hline(
    yintercept = .5,
    linetype = 1,
    color = "grey30",
    alpha = .2
  ) +
  # violin shapes for the distributions and quantiles
  geom_violin(
    position = position_dodge(dw),
    alpha = .1,
    draw_quantiles = c(.25, .5, .75)
    ) +
  # points for means and lines for CIs
  geom_pointrange(
    data = marginal_means,
    aes(
    x = fct_relevel(variable, c("vviq80", "suis60", "osiq_o75", "osiq_s75")),
    y = Mean,
    ymin = CI_low,
    ymax = CI_high,
    color = aphantasia
    ),
    size = .75,
    linewidth = 1,
    position = position_dodge(dw)
  ) +
  # star for significance
  annotate(
    geom  = "text",
    label = "*",
    color = "black",
    x = 1,
    y = .95,
    size  = 10 
    ) +
  # dotted line that separates the different questionnaires
  geom_vline(
    aes(xintercept = stage(variable, after_scale = 1.5)),
    linetype = 3
  ) +
  # star for significance
  annotate(
    geom  = "text",
    label = "*",
    color = "black",
    x = 2,
    y = .95,
    size  = 10 
    ) +
  # dotted line that separates the different questionnaires
  geom_vline(
    aes(xintercept = stage(variable, after_scale = 2.5)),
    linetype = 3
  ) +
  # star for significance
  annotate(
    geom  = "text",
    label = "*",
    color = "black",
    x = 3,
    y = .95,
    size  = 10 
    ) +
  # dotted line that separates the different questionnaires
  geom_vline(
    aes(xintercept = stage(variable, after_scale = 3.5)),
    linetype = 3
  ) +
  # star for significance
  annotate(
    geom  = "text",
    label = "*",
    color = "black",
    x = 4,
    y = .95,
    # vjust = .1,
    # hjust = 6,
    size  = 10 
    ) +
  # Aesthetics
  scale_color_okabeito(name = "Group:  ", labels = c(" Aphantasic   ", " Control")) +
  scale_fill_okabeito(name = "Group:  ", labels = c(" Aphantasic   ", " Control")) +
  scale_x_discrete(
    name = "",
    labels = c("VVIQ", "SUIS", "OSIQ-Object", "OSIQ-Spatial")
  ) +
  scale_y_continuous(
    name = "Standardized score",
    breaks = breaks_pretty(8)
  ) +
  theme_modern() +
  theme(
    panel.grid.major.x = element_blank(),
    panel.grid.major.y = element_line(),
    axis.text.x  = element_text(size = txt),
    axis.title.y = element_text(size = txt),
    legend.title = element_text(size = txt_legend),
    legend.text  = element_text(size = txt_legend),
    legend.position = "top"
    )
```

# Response times

## Power analysis

### Rationale

We hypothesised that difference in reaction times (RT) between congruent and incongruent trials (the congruence effect) in the tasks would be modulated by the visual imagery ability of participants, and therefore that we would observe between-group differences in the magnitude of this effect. In a statistical model with categorical predictors, evidence in favour of our hypothesis would be provided by a significant two-way interaction between Group and Congruence condition. Estimating the statistical power to capture such an effect, given an experimental design, a sample size and an effect size, requires simulations from a model close to the one that will be used for the analysis of real data, as well as assumptions about the structure of data. The power estimation procedure requires 3 steps:

1.	Specifying the structure and coefficients of a generative model

2.	Generating a synthetic dataset using the generative model and an expected effect size

3.	Fitting the same model on the simulated data and test the statistical significance of the interaction of interest

Steps 2 and 3 are then repeated as many times as necessary to reach a desired precision of estimation. The proportion of synthetic datasets for which the effect of interest is significant is an estimation of power. Steps 2 and 3 can also be repeated for a range of effect sizes, if the expected effect size is not known exactlyn which is what we have done here. We detail and justify below every assumption made for the generative model.

### Generative model

In real datasets, the distributions of RTs are right-skewed and can be modeled with transformation using Gamma or inverse Gaussian distributions, yet such a modelling choice is only an approximation as RTs do not follow exactly any distribution of the exponential family for which generalized models can be fitted. It is difficult to evaluate the impact of such approximation on type I and type II errors. For power calculation, we generated normally distributed RT and modeled them with a regular mixed model, which simplifies the model parametrization as well as alleviates the computational burden.

The generative model has been created using the `simr` R package.

```{r generate-data}
#| code-summary: "Creating a dataset following the structure of our data for the generative model"
#| eval: false

# First creating a dataframe with no response data, but whose structure reflects the dataset that will be collected. 

# vectors for subjects
id <- seq(1:150)
groups <- rep(c("aphantasia", "control"), 75)

# conditions
congruences <- list("congruent", "incongruent")
colors <- list("colored", "uncolored")
# repeated 4 times each
congruence = rep(congruence, 4)
color = rep(colors, 4)

# creating the simulation df
df <- 
  tibble(
    id = id, 
    group = groups,
    congruence = list(congruence),
    color = list(color)
    ) |> 
  # crossing conditions for 64 trials/subject total
  unnest_longer(congruence) |> 
  unnest_longer(color)
```

-	Fixed effects: We included the ***Group*** (aphantasic, control), ***Congruence*** condition (congruent or incongruent) and ***Color*** condition (color or uncolored) along with all their two and three way interactions as fixed categorical predictors. Regression coefficients were set in such a way as to produce a pattern of means roughly following our hypotheses, where the control group would be faster solely in the congruent condition. 

`simr` requires these regression coefficients in order to simulate data. The functions below transform a pattern of cell means to regressions coefficients of a linear model, by modelling a dataframe of hypothesized cell means, as if each of them was one noise-less observation of a combination of experimental factors, thus providing the desired coefficient estimates.

```{r sim-regression-coefs}
#| code-summary: "Creating regression coefficients through models"
#| eval: false

# creating dataframes of regression coefficients
extract_coefficients <- function(effectsize) {
  df_temp <- tribble(
          ~group,   ~congruence,       ~color,   ~y,
    "aphantasia",   "congruent",    "colored",  -30,
    "aphantasia",   "congruent",  "uncolored",    0,
    "aphantasia", "incongruent",    "colored",  -30, 
    "aphantasia", "incongruent",  "uncolored",    0,
       "control",   "congruent",    "colored", -30 - effectsize,
       "control",   "congruent",  "uncolored",   0 - effectsize,
       "control", "incongruent",    "colored",  -30,
       "control", "incongruent",  "uncolored",    0
  )
  
  lm_coef <- lm(y ~ (group + congruence + color)^3, data = df_temp)

  # Set numerical errors to 0
  coef(lm_coef)[abs(coef(lm_coef)) < 10^(-10)] <- 0
  
  # converting to ms upon return
  return(coef(lm_coef)/1000)
}
```

-	Random intercepts: We included a random intercept for participants with a standard deviation of 150ms. This number was derived from the literature (see Fucci et al., 2023) - however, previous simulation studies have shown that the magnitude of random intercepts has no effect on statistical power whatsoever (Stevens & Brysbaert 2016), a result that we could verify in our own simulations.

-	Random slopes: We included random by-participant slopes for Congruence and Color. Standard deviations of random slopes are virtually never reported in scientific publications; we set them at 50ms, which is in the same range as the maximum expected population-average effect size.

-	Correlations between random effects were all set to 0, but an alternative value (0.5) produced similar results.

This random effect structure has been specified and provided to a `simr` modelling function to simulate the models that will be fitted on our data.

```{r sim-random-effects}
#| code-summary: "Specifying the random effect structure and the final generative model"
#| eval: false

## Fixed effects: initialized at 0
fixed <- c(700,   # intercept
           0,0,0, # main effects
           0,0,0, # 2-way interactions
           0     # 3-way interactions
           )/1000

## Random intercepts for participants
v1 <- 0.150

## Random intercept, slopes (main effects only) and their covariances
slope  <- .05
correl <- 0
v2 <- matrix(
  c(1, correl, correl,
    correl, 1, correl,
    correl, correl, 1),
  3)

v2 <- cor_to_cov(v2, sd = c((v1), slope, slope))

## residual std dev
res <- .15

model <- makeLmer(
  formula = y ~ (group + congruence + color)^3 + (congruence + color|id),
  fixef   = fixed, 
  VarCorr = list(v2), 
  sigma = res,
  data  = df
  )
```

### Simulations

- Effect sizes: For the interaction Group x Congruence, the effect size can be defined as the double difference (aphantasics - controls) x (congruent - incongruent). Assuming, based on previous works, that the strongest difference would not exceed 50-60ms, and that differences below 10ms would hardly be meaningful, we ran simulations for differences between 10 and 60ms, by steps of 5ms. As the power reached the ceiling of 100% after 40ms effect sizes, we report here the results up to this size. 

- Number of simulations: For each effect size, we ran as many simulations as were needed to obtain a confidence interval below ±10 points around the mean. Goind by steps of 50, we eventually ran 200 simulations for each effect size.

```{r simulations}
#| code-summary: "Running the simulations for various effect sizes"
#| eval: false

# ─── Running simulations with parallel processing ─────────────────────────────

# finding the available cores for parallel processing
n_cores <- parallel::detectCores() - 1

# creating the cluster of cores
parallel_cluster <- 
  parallel::makeCluster(
    n_cores,
    type = "PSOCK"
  )

# registering the cluster for `foreach`
doParallel::registerDoParallel(cl = parallel_cluster)
# checking
# foreach::getDoParRegistered()
# foreach::getDoParWorkers()

# initializing, ready for takeoff
nsim <- 200

# Run calculations for a range of effect sizes
(simulations <-
  foreach (
    effectsize = c(10, 15, 20, 25, 30, 35, 40), 
    .packages = c("tidyverse", "simr")
    ) %dopar% {
      # Calculate regression coefficients corresponding to the effect size and 
      # update the model to simulate from accordingly
      fixef(model) <- extract_coefficients(effectsize)
      
      # Simulate data and estimate power
      powerSim(
        model, 
        nsim = nsim,
        test = simr::fixed(
          xname = "group:congruence", 
          method = 'anova'
          ))
    }) |> system.time() -> time_simulating

# stopping the cluster when we're done
parallel::stopCluster(cl = parallel_cluster)
```

### Results

The analysis yielded a power of 82% starting at effect sizes around 25ms, goind up to 91% at 30ms and 97% at 35ms. Every effect size equal and above 40ms reached a ceiling of 100% power. The complete results are summarized in @tbl-simulations-table and @fig-simulations-plot. 

```{r simulations-table}
#| label: tbl-simulations-table
#| code-summary: "Generating the summary table for the power analysis"
#| tbl-cap: "Results of the power analysis through simulation."
#| tbl-cap-location: margin

simulations_table <- 
  readRDS(file = "analyses-results/00-power-analyses-table.RDS")

simulations_table |> 
  # All the code below is simple formatting of the table that is in the RDS
  rename(
    "Effect size (difference in ms)" = effectsize,
    "Successes"   = successes,
    "Simulations" = trials,
    "Power" = mean
  ) |> 
  mutate(across(c(lower:upper), ~round(.x, digits = 2))) |> 
  unite("CI", lower:upper, sep = ", ") |> 
  mutate(CI = paste("[", CI, "]")) |> 
  rename("95% CI" = CI) |> 
  gt() |> 
  cols_align(
    align = "center",
    columns = 1:5
  ) |>
  fmt_markdown(columns = 1:5) |> 
  fmt_number(columns = 4, decimals = 2) |> 
  tab_options(table.width = pct(100))
```

```{r simulations-plot}
#| label: fig-simulations-plot
#| code-summary: "Generating the plot of the power analysis results"
#| fig-cap: "Results of the power analysis using simulations. 200 simulations have been computed for each effect size."
#| out-width: 100%

simulations_table |> 
  ggplot(aes(
    x = effectsize,
    y = mean,
    ymin  = lower,
    ymax  = upper,
    label = effectsize
    )) +
  # the band representing the 95% CIs
  geom_ribbon(fill = "aquamarine", alpha = .2) +
  # the means and CIs at each specific effect size
  geom_pointrange(colour = "aquamarine4") +
  geom_point(colour = "aquamarine4") +
  # line connecting the dots
  geom_line(colour = "aquamarine4") +
  # horizontal line at 80% power and corresponding annotation
  geom_hline(yintercept = .8, color = "black", linetype = 1) +
  annotate(
    geom  = "text",
    label = "80% power",
    fontface = "italic",
    color = "black",
    x = -Inf,
    y = .8,
    vjust = -.5,
    hjust = -.3,
    size  = 4 
    ) +
  # horizontal dotted line at 90% power and corresponding annotation
  geom_hline(yintercept = .9, color = "gray60", linetype = 2) +
  annotate(
    geom  = "text",
    label = "90% power",
    fontface = "italic",
    color = "grey60",
    x = -Inf,
    y = .9,
    vjust = -.5,
    hjust = -.3,
    size  = 4 
    ) +
  # Aesthetics
  scale_x_continuous(
    name = "Effect size (RT difference in ms)",
    breaks = unique(simulations_table$effectsize)
  ) +
  scale_y_continuous(
    name = "Statistical power",
    breaks = seq(0, 1, .1),
    limits = c(0, 1)
    ) +
  theme_modern() +
  theme(panel.grid.major = element_line())
```

## Outlier detection procedure {#sec-outliers}

We removed missed trials in the analyses of the RTs. Beforehand, we analysed the proportion of missed trials for each participant and removed for each task the participants with abnormally high rates of missed trials (> 20%).

```{r accuracy-outliers}
#| code-summary: "Removing incorrect trials and task-wise accuracy outliers"
#| output: false

# ─── Listing error rates per subject ───
list(df_implicit, df_explicit) |> 
  imap(
    ~.x |> 
      select(subjectid, starts_with("correct"), aphantasia) |> 
      group_by(subjectid) |> 
      count(pick(2)) |> 
      filter(pick(1) == 1) |> 
      ungroup() |> 
      mutate(
        n_tot = max(n),
        prop = (n_tot - n) / n_tot * 100  # analyzing the error rate per subject
      ) %>%
      arrange(desc(prop)) |> 
      select(1, 5)
    )
# 5 accuracy outliers in the explicit task, 4 in the implicit one

# ─── Removing incorrect trials and task-wise accuracy outliers ───
df_implicit_rt <- 
  df_implicit |>  
  # filtering out...
  filter(
    # incorrect trials
    correct_implicit == 1 &
    # participants identified with with high error rates
    !(subjectid %in% c( 
      "bdispaux", 
      "eleveque", 
      "aleclaire", 
      "dchimenton"))
      ) |>  
  # removing irrelevant variables
  select(-c(sex, vviq80, orientation, response, correct_implicit))

# same for the explicit task
df_explicit_rt <-
  df_explicit |> 
  filter(
    correct_explicit == 1 &
    !(subjectid %in% c( 
      "aknezevic",
      "lbrunie", 
      "agayou", 
      "bluciani",
      "ldossantos"))
    ) |>  
  select(-c(sex, vviq80, orientation, response, correct_explicit))

```

As a preprocessing, response times below 250ms and above 3000ms will be removed as they could represent false alarms.

```{r removing-extreme-rts}
#| code-summary: "Removing extreme RTs"
#| output: false

# in the implicit task
df_implicit_rt <- 
  df_implicit_rt |>  
  # filtering out extreme RTs
  filter(rt > .25 & rt < 3)

# and the explicit one
df_explicit_rt <- 
  df_explicit_rt |>  
  filter(rt > .25 & rt < 3)
```

```{r rt-means-df}
#| echo: false
#| output: false

# ═══ RT means table - Both tasks ══════════════════════════════════════════════

df_rt <- 
  list(
  df_explicit_rt |>  rename("Explicit task mean RTs" = rt), 
  df_implicit_rt |>  rename("Implicit task mean RTs" = rt)
  ) |>  
  imap(
    ~select(.x, contains("RT")) |> 
      report() |>  
      as.data.frame() |>  
      select(1:10)
    )

df_rt <- bind_rows(df_rt[[1]], df_rt[[2]])

# explicit upper outlier threshold
threshold_explicit <- df_rt$Median[1] + 3*df_rt$MAD[1]
# 1.35

# implicit upper outlier threshold
threshold_implicit <- df_rt$Median[2] + 3*df_rt$MAD[2]
# 1.055
```

A first level of the RT outliers analysis is based on the overall mean RT of the participants. Using a procedure based on , participants with abnormally high RT means were removed from the dataset of the task. Using an outlier detection procedure based on Mean Absolute Deviations (MADs), a common scaling factor to determine acceptable values is $\pm$ 3 MADs: this resulted in our case in an upper threshold of `r round(threshold_implicit, digits = 3)*1000`ms for the implicit task and `r round(threshold_explicit, digits = 3)*1000`ms for the explicit task.

```{r rt-means-outliers}
#| code-summary: "Removing outliers with aberrant RT means"
#| output: false

# ─── Finding outliers ───
df_implicit_rt |>
  group_by(subjectid) |> 
  summarise(median_rt = median(rt)) |> 
  ungroup() |> 
  filter(median_rt > threshold_implicit) |> 
  arrange(desc(median_rt))
# 0 outliers in the implicit task

df_explicit_rt |> 
  group_by(subjectid) |> 
  summarise(median_rt = median(rt)) |> 
  ungroup() |> 
  filter(median_rt > threshold_explicit) |> 
  arrange(desc(median_rt))
# 3 outliers in the explicit task

# ─── Removing specific outliers ───
df_explicit_rt <- 
  df_explicit_rt |> 
  filter(
    !(subjectid %in% c(
      "dchimenton",
      "fc",
      "mbilodeau"
    ))
  )

# Examination of remaining trials
df_explicit_rt |> 
  group_by(subjectid) |> 
  count() |> 
  arrange(n)
# 3 have very few trials

# ─── Removing specific outliers ───
df_explicit_rt <- 
  df_explicit_rt |> 
  filter(
    !(subjectid %in% c(
      "llhermitte",
      "cmarcenytheault",
      "mbillon"
    ))
  )

df_implicit_rt |> 
  group_by(subjectid) |> 
  count() |> 
  arrange(n)
# implicit trials are ok
```

Finally, we conducted a more detailed inspection of the RTs on a by-participant level. Once again, we detected these outliers using MAD thresholds. The RTs have been group by subsets of conditions, as we know that our experimental conditions could have affected them: thus, using a global median would necessarily flatten within-participant outcomes and have a major impact on the analyses. After close inspection of the distributions and individual MADs of participants, a threshold at 5 MADs was chosen for outlier detection.The resulting RT distributions per participant in each task are presented in @fig-rt-per-participant-1 and [-@fig-rt-per-participant-2].

```{r removing-outliers-by-participant}
#| code-summary: "Removing outlier trials by-participant"
#| output: false

df_implicit_rt <-
  df_implicit_rt |> 
  group_by(subjectid, congruence) |> 
  mutate(
    rt_median = median(rt),
    rt_mad = mad(rt)
    ) |> 
  # filtering based on a 5 MAD threshold      
  filter(
    rt < rt_median + 5 * rt_mad
  ) |>
  ungroup()

# same for the explicit task
df_explicit_rt <- 
  df_explicit_rt |> 
  group_by(subjectid, congruence) |> 
  mutate(
    rt_median = median(rt),
    rt_mad = mad(rt)
    ) |> 
  filter(
    rt < rt_median + 5 * rt_mad
  ) |>
  ungroup()
```

:::{.panel-tabset .column-page-inset-right}
### RT distributions - Implicit task

```{r rt-per-participant-1}
#| label: fig-rt-per-participant-1
#| code-summary: "Generating distribution plots"
#| fig-cap: "Resulting distribution of RTs in the implicit task for each participant. Each colored distribution represents a single participant. *Hover to see details on the individual distributions*."
#| out-width: 100%

(df_implicit_rt |>
  ggplot(aes(x = rt, fill = subjectid)) +
  geom_density(alpha = .25, color = "black") +
  scale_x_continuous(name = "Response time", breaks = breaks_pretty(5)) +
  scale_y_continuous(name = "Density") +
  theme(
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank()
    ) +
  scale_fill_viridis_d(guide = NULL) +
  scale_color_viridis_d(guide = NULL) +
  theme_modern() +
  theme(panel.grid.major = element_line())
 ) |>
  ggplotly() |>
  style(showlegend = FALSE)
```

### RT distributions - Explicit task

```{r rt-per-participant-2}
#| label: fig-rt-per-participant-2
#| code-summary: "Generating distribution plots"
#| fig-cap: "Resulting distribution of RTs in the explicit task for each participant. Each colored distribution represents a single participant. *Hover to see details on the individual distributions*."
#| out-width: 100%

(df_explicit_rt |>
  ggplot(aes(x = rt, fill = subjectid)) +
  geom_density(alpha = .25, color = "black") +
  scale_x_continuous(name = "Response time", breaks = breaks_pretty(5)) +
  scale_y_continuous(name = "Density") +
  theme(
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank()
    ) +
  scale_fill_viridis_d(guide = NULL) +
  scale_color_viridis_d(guide = NULL) +
  theme_modern() +
  theme(panel.grid.major = element_line())
 ) |>
  ggplotly() |>
  style(showlegend = FALSE)
```
:::

## Modelling

To account for the non-normal, positively skewed distributions of the RTs, we fitted Generalized Linear Mixed Models (GLMMs) with inverse Gaussian distributions. The models were implemented in the `lme4` R package and integrated in `tidymodels` workflows using the package `multilevelmod`. Models with Gamma and Gaussian distributions were also fitted and compared with the AIC and BIC to ensure that we chose the best distribution available. 

The models included the ***Group*** (aphantasic, control), ***Congruence*** condition (congruent or incongruent) and ***Color*** condition (color or uncolored) along with all their two and three way interactions as fixed categorical predictors, while ***participants*** have been included as grouping factors (i.e. "random effects"). The random effect structure was chosen by fitting and comparing models with every possible combination of distribution and structure (intercept by participant, congruence or color, slope by participant on congruence and/or color) aiming for the best balance between goodness of fit and parsimony. The optimal models included a single by-participant random intercept and random slopes on congruence and color.

We reported unstandardized effect sizes for post-hoc tests in the form of estimated marginal contrasts in milliseconds (i.e. differences in marginal means estimated by the model). The family-wise error rate on parameters and pairwise contrasts was controlled using a FDR correction on *p*-values.

The complete `tidymodels` workflows coded to fit and compare all the models are presented in the code sections down below.

### Conventional VVIQ Groups

```{r fitting-glmms-conventional-groups}
#| eval: false
#| code-summary: "Fitting Generalized Linear Mixed Models on RTs in both tasks with `tidymodels`"

# ─── Defining tidymodels recipes to prepare the data ──────────────────────────

# implicit task recipe
model_recipe_glmm_im <- 
  df_implicit_rt |> 
  recipe() |> 
  # RT as the dependent variable
  update_role(rt, new_role = "outcome") %>%  
  # All our predictors
  update_role(
    subjectid, age, aphantasia, color, congruence, 
    new_role = "predictor"
  ) |> 
  # participants as grouping factors, i.e. "random effects"
  add_role(subjectid, new_role = "group")

# same for the explicit data
model_recipe_glmm_ex <- 
  df_explicit_rt |> 
  recipe() |> 
  update_role(rt, new_role = "outcome") %>%
  update_role(
    subjectid, age, aphantasia, color, congruence, 
    new_role = "predictor"
  ) |> 
  add_role(subjectid, new_role = "group")

# ─── Specifying the distributions for the models ──────────────────────────────

# Gamma distribution
glmm_gamma_id <-
  linear_reg() |> 
  set_engine(
    "glmer",
    family = Gamma(link = "identity")
  )

# Inverse Gaussian distribution
glmm_inverse_id <-
  linear_reg() |> 
  set_engine(
    "glmer",
    family = inverse.gaussian(link = "identity")
  )

# Gaussian distribution
glmm_gaussian <-
  linear_reg() |> 
  set_engine("lmer")

# Listing these models
model_specs_glmm <- list(
  glmm_gamma_id    = glmm_gamma_id,
  glmm_inverse_id  = glmm_inverse_id,
  glmm_gaussian    = glmm_gaussian
)

# ─── Writing down the formulas with different random effect structures ────────

# null model
formula_0 <- rt ~ (1|subjectid)

# intercept by-participant only
formula_1 <- rt ~ (aphantasia + congruence + color)^3 + (1|subjectid)

# intercept and slope on congruence by-participant
formula_2 <- rt ~ (aphantasia + congruence + color)^3 + (congruence|subjectid)

# intercept and slope on color by-participant
formula_3 <- rt ~ (aphantasia + congruence + color)^3 + (color|subjectid)

# single intercept and two slopes on congruence and color by-participant
formula_4 <- rt ~ (aphantasia + congruence + color)^3 + (congruence + color|subjectid)

# Listing these formulas
model_formulas_glmm <- list(
  formula_0  = formula_0,
  formula_1  = formula_1,
  formula_2  = formula_2,
  formula_3  = formula_3,
  formula_4  = formula_4
  )

# ─── Table to combine everything in workflows and fit the models ──────────────
model_all_glmms_fitted <- 
  tribble(       ~recipe,     ~ task,           ~model,       ~formula,
    model_recipe_glmm_ex, "explicit", model_specs_glmm, model_formulas_glmm,
    model_recipe_glmm_im, "implicit", model_specs_glmm, model_formulas_glmm
  ) |> 
  # combining recipes with models
  unnest_longer(model) |> 
  # combining them with formulas
  unnest_longer(formula) |>
  rowwise() |>
  mutate(
    # creating workflows
    workflow = list(
      workflow() |>
      add_recipe(recipe) |> 
      add_model(model, formula = formula)  
      )
  )

# ─── Fitting the models with parallel processing ──────────────────────────────

# finding the available cores for parallel processing
n_cores <- parallel::detectCores() - 1

# creating the cluster of cores
parallel_cluster <- 
  parallel::makeCluster(
    n_cores,
    type = "PSOCK"
  )

# registering the cluster for the `foreach` package
doParallel::registerDoParallel(cl = parallel_cluster)
# checking
# foreach::getDoParRegistered()
# foreach::getDoParWorkers()

# creating a new list-column with all the models fitted in parallel
(model_all_workflows_fitted$fitted_model <-
  foreach(
    workflow = model_all_workflows_fitted$workflow,
    task     = model_all_workflows_fitted$task,
    .combine  = "c",
    .packages = c("tidymodels", "multilevelmod")
) %dopar% {
  # fitting the models for the implicit task with the appropriate dataset
  if(task == "implicit"){
    model_fit <-
      list(
        workflow |> 
        fit(data = df_implicit_rt) |> 
        extract_fit_engine()
      )
  }
  # and for the explicit task
  else{
    model_fit <-
      list(
        workflow |> 
        fit(data = df_explicit_rt) |> 
        extract_fit_engine()
      )
  }
  
  return(model_fit)
# (measuring runtime for benchmarking)
}) |> system.time() -> time_parallel

# removing irrelevant used columns
model_all_workflows_fitted <-  
  model_all_workflows_fitted |> 
  select(-c(recipe, model, formula, workflow))

# ─── Examining the quality of the models, estimating the parameters ───────────

# parameter tables with all estimates
model_all_workflows_fitted$parameters <-
  foreach(
    fitted_model = model_all_workflows_fitted$fitted_model,
    .combine  = "c",
    .packages = c("parameters")
) %dopar% {
  parameters <- list(model_parameters(fitted_model))
  return(parameters)
}

# convergence checks
model_all_workflows_fitted$convergence <-
  foreach(
    fitted_model = model_all_workflows_fitted$fitted_model,
    .combine  = "c",
    .packages = c("performance")
) %dopar% {
  convergence <- check_convergence(fitted_model)
  return(convergence)
}

# model quality and performance indices
model_all_workflows_fitted$model_perf <-
  foreach(
    fitted_model = model_all_workflows_fitted$fitted_model,
    .combine  = "c",
    .packages = c("performance")
) %dopar% {
  model_perf <- list(model_performance(fitted_model))
  return(model_perf)
}

# extracting relevant indices
model_all_workflows_fitted <-
  model_all_workflows_fitted |>
  mutate(
    # extracting model quality indices
    AIC  = model_perf[[1]],
    AICc = model_perf[[2]],
    BIC  = model_perf[[3]]
  ) |>
  ungroup() |> 
  select(-model_perf)

# stopping the cluster when we're done
parallel::stopCluster(cl = parallel_cluster)

# 119 seconds on 19 cores

# ─── Comparing the models' quality among those that converged ─────────────────
model_selection <-
  model_all_workflows_fitted |> 
  filter(convergence == TRUE) |> 
  group_by(task, model_id) |> 
  mutate(best_model = ifelse(AICc == min(AICc), TRUE, FALSE)) |> 
  filter(best_model == TRUE)
```

The quality checks of the optimal models selected for the implicit and explicit tasks, that used inverse Gaussian distributions, are displayed in @fig-implicit-checks and @fig-explicit-checks. The summaries of estimated model parameters are presented in @tbl-implicit-parameters-conventional and @tbl-explicit-parameters-conventional. Pair-wise contrast analyses for both tasks on the relevant factor levels are displayed in @tbl-implicit-contrasts-conventional and @tbl-explicit-contrasts-conventional. The visualizations of the interaction of interest for our hypotheses, Group x Congruence, are depicted in @fig-implicit-model-conventional and @fig-explicit-model-conventional.

```{r loading-glmms-rds}
#| echo: false

# implicit task
model_task_implicit <- 
  readRDS(file = "analyses-results/01-glmm-inverse-id-implicit.RDS")

# explicit task
model_task_explicit <- 
  readRDS(file = "analyses-results/01-glmm-inverse-id-explicit.RDS")
```

#### Models' quality and assumptions

:::{.panel-tabset .column-page-inset-right}
##### Implicit task - Model checks

```{r running-model-checks-implicit}
#| eval: false
#| code-summary: "Running model checks"

# loading the model saved after the analysis
model_task_implicit <- 
  readRDS(file = "analyses-results/01-glmm-inverse-id-implicit.RDS")

# characteristics to check
model_checks = c("pp_check","homogeneity", "vif", "outliers", "qq", "reqq")

# plotting
model_task_implicit |> check_model(check = model_checks, detrend = FALSE)
```

![Model assumption checks for the Generalized Linear Mixed Model fit on the RTs in the implicit task.](plots/S1-glmm-checks-implicit.png){#fig-implicit-checks}

##### Explicit task - Model checks

```{r running-model-checks-explicit}
#| eval: false
#| code-summary: "Running model checks"

# loading the model saved after the analysis
model_task_explicit <- 
  readRDS(file = "analyses-results/01-glmm-inverse-id-explicit.RDS")

# characteristics to check
model_checks = c("pp_check","homogeneity", "vif", "outliers", "qq", "reqq")

# plotting
model_task_explicit |> check_model(check = model_checks, detrend = FALSE)
```

![Model assumption checks for the Generalized Linear Mixed Model fit on the RTs in the explicit task.](plots/S1-glmm-checks-explicit.png){#fig-explicit-checks}
:::

#### Models' estimates

:::{.panel-tabset .column-page-inset-right}
##### Implicit task estimates

```{r implicit-parameters-table-conventional}
#| label: tbl-implicit-parameters-conventional
#| echo: false
#| tbl-cap: "Estimates of the GLMM fitted on the RTs in the implicit task. *'aphantasia (no)' refers to the control group*."

# printing with the package `parameters`
model_task_implicit |> 
  model_parameters() |>
  print_html() 
```

##### Explicit task estimates

```{r explicit-parameters-table-conventional}
#| label: tbl-explicit-parameters-conventional
#| echo: false
#| tbl-cap: "Estimates of the GLMM fitted on the RTs in the explicit task. *'aphantasia (no)' refers to the control group*."

# printing with the package `parameters`
model_task_explicit |> 
  model_parameters() |> 
  print_html() 
```

##### Plot - Implicit task

```{r implicit-parameters-fig-conventional}
#| label: fig-implicit-parameters-conventional
#| echo: false
#| fig-cap: "Estimates of the GLMM fitted on the RTs in the implicit task. *'aphantasia (no)' refers to the control group*."
#| out-width: 100%

# plotting with the packages `parameters` and `see`
model_task_implicit |> 
  model_parameters() |> 
  plot()
```

##### Plot - Explicit task

```{r explicit-parameters-fig-conventional}
#| label: fig-explicit-parameters-conventional
#| echo: false
#| fig-cap: "Estimates of the GLMM fitted on the RTs in the explicit task. *'aphantasia (no)' refers to the control group*."
#| out-width: 100%

# plotting with the packages `parameters` and `see`
model_task_explicit |> 
  model_parameters() |> 
  plot()
```

:::

#### Marginal contrasts

:::{.panel-tabset .column-page-inset-right}
##### Implicit task marginal contrasts

```{r implicit-contrasts-conventional}
#| label: tbl-implicit-contrasts-conventional
#| echo: false
#| tbl-cap: "Pair-wise contrast analyses between levels of factors in the implicit task. *'No' represents the control group. Thus, 'no congruent' is the estimates of the control group in the congruent condition, etc.*" 

model_task_implicit |> 
  estimate_contrasts(
    contrast = c("aphantasia", "congruence"),
    p_adjust = "fdr"
  ) |> 
  format() |> 
  select(1,2,3,4,7,8) |> 
  print_html()
```

##### Explicit task marginal contrasts

```{r explicit-contrasts-conventional}
#| label: tbl-explicit-contrasts-conventional
#| echo: false
#| tbl-cap: "Pair-wise contrast analyses between levels of factors in the explicit task. *'No' represents the control group. Thus, 'no coloured' is the estimates of the control group in the coloured condition, etc.*" 

model_task_explicit |> 
  estimate_contrasts(
    contrast = c("aphantasia", "color"),
    p_adjust = "fdr"
  ) |> 
  format() |> 
  select(1,2,3,4,7,8) |> 
  print_html()
```

:::

#### Group x Congruence interaction plots

:::{.panel-tabset}
##### Implicit task

```{r model-implicit-plot-conventional}
#| label: fig-implicit-model-conventional
#| code-summary: "Creating the plot for the Group x Congruence interaction"
#| fig-cap: "Visualizations of the interactions between Group and Congruence in the optimal models for the implicit task. The black dots indicate marginal means predicted by the models whereas the black bars represent the standard error of these estimates. The stars represent FDR-corrected *p*-values inferior to .05."
#| out-width: 100%

# ─── Setup variables ──────────────────────────────────────────────────────────

# dodge width for all the geoms
dw <- .75
# stat text size
st <- 7
# legend and axis text size
txt <- 18
title_size <- 20

# ─── Marginal means for the plots ─────────────────────────────────────────────
model_implicit_preds <-
  model_task_implicit |> 
  estimate_means(
    at = c("aphantasia", "congruence"),
    p_adjust = "fdr"
    )

# ─── Plotting ─────────────────────────────────────────────────────────────────
df_implicit_rt |>
  ggplot(aes(
    x = congruence,
    y = rt * 1000,
    color = aphantasia
  )) +
  # linear modelling of the differences
  geom_line(
    data = model_implicit_preds,
    aes(
      y = Mean * 1000,
      group = aphantasia
    ),
    position = position_dodge(width = dw),
    linewidth = 1.5,
    linetype = 1
  ) +
  # predicted means of the model and their SE
  geom_pointrange2(
    data = model_implicit_preds,
    aes(
      x = congruence,
      y = Mean * 1000,
      ymin = Mean * 1000 - SE * 1000,
      ymax = Mean * 1000 + SE * 1000,
      group = aphantasia
      ),
    color = "black",
    position = position_dodge(width = dw),
    size = 1,
    linewidth = .75,
    show.legend = FALSE
  ) +
  # adding a star for the significant contrast
  annotate(
    geom  = "text",
    label = "*",
    fontface = "italic",
    color = "#56b4e9",
    x = 2.05,
    y = 628,
    vjust = .1,
    hjust = 6,
    size  = 12 
    ) +
  labs(
    title = NULL,
    x = NULL,
    y = "Response time (ms)"
    ) +
  # Aesthetics
  scale_y_continuous(breaks = breaks_pretty(10)) +
  scale_x_discrete(labels = c("Congruent", "Incongruent")) +
  scale_color_okabeito(name = "", labels = c(" Aphantasic   ", " Control")) +
  theme_modern() +
  theme(
    panel.grid.major.x = element_blank(),
    panel.grid.major.y = element_line(),
    axis.ticks.x = element_blank(),
    axis.title.y = element_text(size = txt),
    axis.text.x = element_text(size = txt),
    legend.title = element_text(size = txt),
    legend.text = element_text(size = txt),
    legend.position = "top"
    )
```

##### Explicit task

```{r model-explicit-plot-conventional}
#| label: fig-explicit-model-conventional
#| code-summary: "Creating the plot for the Group x Congruence interaction"
#| fig-cap: "Visualizations of the interactions between Group and Congruence in the optimal models for the explicit task. The black dots indicate marginal means predicted by the models whereas the black bars represent the standard error of these estimates. The stars represent FDR-corrected *p*-values inferior to .05."
#| out-width: 100%

# ─── Setup variables ──────────────────────────────────────────────────────────

# dodge width for all the geoms
dw <- .75
# stat text size
st <- 7
# legend and axis text size
txt <- 18
title_size <- 20

# ─── Marginal means for the plots ─────────────────────────────────────────────
model_explicit_preds <-
  model_task_explicit |> 
  estimate_means(
    at = c("aphantasia", "congruence"),
    p_adjust = "fdr"
    )

# ─── Plotting ─────────────────────────────────────────────────────────────────
df_implicit_rt |>
  ggplot(aes(
    x = congruence,
    y = rt * 1000,
    color = aphantasia
  )) +
  # linear modelling of the differences
  geom_line(
    data = model_explicit_preds,
    aes(
      y = Mean * 1000,
      group = aphantasia
    ),
    position = position_dodge(width = dw),
    linewidth = 1.5,
    linetype = 1
  ) +
  # predicted means of the model and their SE
  geom_pointrange2(
    data = model_explicit_preds,
    aes(
      x = congruence,
      y = Mean * 1000,
      ymin = Mean * 1000 - SE * 1000,
      ymax = Mean * 1000 + SE * 1000,
      group = aphantasia
      ),
    color = "black",
    position = position_dodge(width = dw),
    size = 1,
    linewidth = .75,
    show.legend = FALSE
  ) +
  labs(
    title = NULL,
    x = NULL,
    y = "Response time (ms)"
    ) +
  # Aesthetics
  scale_y_continuous(breaks = breaks_pretty(10)) +
  scale_x_discrete(labels = c("Congruent", "Incongruent")) +
  scale_color_okabeito(name = "", labels = c(" Aphantasic   ", " Control")) +
  theme_modern() +
  theme(
    panel.grid.major.x = element_blank(),
    panel.grid.major.y = element_line(),
    axis.ticks.x = element_blank(),
    axis.title.y = element_text(size = txt),
    axis.text.x = element_text(size = txt),
    legend.title = element_text(size = txt),
    legend.text = element_text(size = txt),
    legend.position = "top"
    )
```
:::

### Extremal VVIQ Groups

The same modelling pipeline has been applied to a dataset restricted to participants scoring at floor VVIQ (VVIQ = 16, N = 50) and matched controls scoring the highest at the VVIQ in the sample (VVIQ between 42 and 78). The full pre-processing of the data to get this new dataset ready for modelling, along with the modelling and analyses themselves, are presented in the *very long* code section down below. It is essentially equivalent to a concatenation in one code chunk of all the successive steps followed in the previous sections, with very few modifications.

```{r extremal-groups-data-analysis}
#| eval: false
#| code-summary: "Full pipeline for the extreme VVIQ groups analyses (*warning: long code section*)"

# ═══ Importing and keeping only "extreme" VVIQs ═══════════════════════════════

# Implicit task
df_implicit <- 
  read_excel(
    "data/aphantasia_priming_tidy_data.xlsx",
    sheet = "data_implicit"
    ) |> 
  rename("rt" = rt_implicit) |> 
  # convert to seconds
  mutate(rt = rt/1000)

# Explicit task
df_explicit <- 
  read_excel(
    "data/aphantasia_priming_tidy_data.xlsx",
    sheet = "data_explicit"
    ) |> 
  rename("rt" = rt_explicit) |> 
  # convert to seconds
  mutate(rt = rt/1000)

# Questionnaires
df_questionnaires <- 
  read_excel(
    "data/aphantasia_priming_tidy_data.xlsx",
    sheet = "data_questionnaires"
    ) |>  
  # creating the a/phantasia groups
  mutate(
    aphantasia = ifelse(vviq80 < 32, "yes", "no"),
    aphantasia = fct_relevel(aphantasia, "yes", "no")
    ) |>
  filter(vviq80 <= 16.5 | vviq80 >= 42)

# updating all the dataframes with the questionnaires data
dfs <- 
  list(
    implicit_task = df_implicit, 
    explicit_task = df_explicit
    ) |> 
  # adding the vviq and group column to every dataframe
  imap(~right_join(
    .x, 
    df_questionnaires |>  
      select(
        # column to match with the correct participants
        subjectid, 
        # new variables to add
        age,
        sexe,
        vviq80,
        aphantasia), by = "subjectid") |>  
      rename("sex" = sexe) |>  
      # reordering the final dfs
      select(
        subjectid, 
        age, sex, aphantasia,
        vviq80,
        everything())
    )

df_implicit <- dfs$implicit_task
df_explicit <- dfs$explicit_task
rm(dfs)

# ═══ Accuracy outliers analysis ═══════════════════════════════════════════════

# ─── Listing error rates per subject ───
list(df_explicit, df_implicit) |> 
  imap(
    ~.x |> 
      select(subjectid, starts_with("correct"), aphantasia) |> 
      group_by(subjectid) |> 
      count(pick(2)) |> 
      filter(pick(1) == 1) |> 
      ungroup() |> 
      mutate(
        n_tot = max(n),
        prop = (n_tot - n) / n_tot * 100  # analyzing the error rate per subject
      ) %>%
      arrange(desc(prop)) |> 
      select(1, 5)
    )
# 5 accuracy outliers in the explicit task, 4 in the implicit one

# ─── Removing incorrect trials and task-wise accuracy outliers ───
df_explicit_rt <-
  df_explicit |> 
  filter(
    correct_explicit == 1 &
    !(subjectid %in% c( 
      "aknezevic",
      "lbrunie", 
      "agayou", 
      "bluciani",
      "ldossantos"))
    ) |>  
  select(-c(sex, vviq80, orientation, response, correct_explicit))

df_implicit_rt <- 
  df_implicit |>  
  filter(
    correct_implicit == 1 &
    !(subjectid %in% c( 
      "bdispaux", 
      "eleveque", 
      "aleclaire", 
      "dchimenton"))
      ) |>  
  select(-c(sex, vviq80, orientation, response, correct_implicit))

# ═══ First broad RT outlier trials removal ════════════════════════════════════

df_explicit_rt <- 
  df_explicit_rt |>  
  # filtering out extreme RTs
  filter(rt > .25 & rt < 2)

df_implicit_rt <- 
  df_implicit_rt |>  
  filter(rt > .25 & rt < 2)


# ─── Defining tidymodels recipes to prepare the data ──────────────────────────

# implicit task recipe
model_recipe_glmm_im <- 
  df_implicit_rt |> 
  recipe() |> 
  # RT as the dependent variable
  update_role(rt, new_role = "outcome") %>%  
  # All our predictors
  update_role(
    subjectid, age, aphantasia, color, congruence, 
    new_role = "predictor"
  ) |> 
  # participants as grouping factors, i.e. "random effects"
  add_role(subjectid, new_role = "group")

# same for the explicit data
model_recipe_glmm_ex <- 
  df_explicit_rt |> 
  recipe() |> 
  update_role(rt, new_role = "outcome") %>%
  update_role(
    subjectid, age, aphantasia, color, congruence, 
    new_role = "predictor"
  ) |> 
  add_role(subjectid, new_role = "group")

# ─── Specifying the distributions for the models ──────────────────────────────

# Gamma distribution
glmm_gamma_id <-
  linear_reg() |> 
  set_engine(
    "glmer",
    family = Gamma(link = "identity")
  )

# Inverse Gaussian distribution
glmm_inverse_id <-
  linear_reg() |> 
  set_engine(
    "glmer",
    family = inverse.gaussian(link = "identity")
  )

# Gaussian distribution
glmm_gaussian <-
  linear_reg() |> 
  set_engine("lmer")

# Listing these models
model_specs_glmm <- list(
  glmm_gamma_id    = glmm_gamma_id,
  glmm_inverse_id  = glmm_inverse_id,
  glmm_gaussian    = glmm_gaussian
)

# ─── Writing down the formulas with different random effect structures ────────

# null model
formula_0 <- rt ~ (1|subjectid)

# intercept by-participant only
formula_1 <- rt ~ (aphantasia + congruence + color)^3 + (1|subjectid)

# intercept and slope on congruence by-participant
formula_2 <- rt ~ (aphantasia + congruence + color)^3 + (congruence|subjectid)

# intercept and slope on color by-participant
formula_3 <- rt ~ (aphantasia + congruence + color)^3 + (color|subjectid)

# single intercept and two slopes on congruence and color by-participant
formula_4 <- rt ~ (aphantasia + congruence + color)^3 + (congruence + color|subjectid)

# Listing these formulas
model_formulas_glmm <- list(
  formula_0  = formula_0,
  formula_1  = formula_1,
  formula_2  = formula_2,
  formula_3  = formula_3,
  formula_4  = formula_4
  )

# ─── Table to combine everything in workflows and fit the models ──────────────
model_all_glmms_fitted <- 
  tribble(       ~recipe,     ~ task,           ~model,       ~formula,
    model_recipe_glmm_ex, "explicit", model_specs_glmm, model_formulas_glmm,
    model_recipe_glmm_im, "implicit", model_specs_glmm, model_formulas_glmm
  ) |> 
  # combining recipes with models
  unnest_longer(model) |> 
  # combining them with formulas
  unnest_longer(formula) |>
  rowwise() |>
  mutate(
    # creating workflows
    workflow = list(
      workflow() |>
      add_recipe(recipe) |> 
      add_model(model, formula = formula)  
      )
  )

# ─── Fitting the models with parallel processing ──────────────────────────────

# finding the available cores for parallel processing
n_cores <- parallel::detectCores() - 1

# creating the cluster of cores
parallel_cluster <- 
  parallel::makeCluster(
    n_cores,
    type = "PSOCK"
  )

# registering the cluster for the `foreach` package
doParallel::registerDoParallel(cl = parallel_cluster)
# checking
# foreach::getDoParRegistered()
# foreach::getDoParWorkers()

# creating a new list-column with all the models fitted in parallel
(model_all_workflows_fitted$fitted_model <-
  foreach(
    workflow = model_all_workflows_fitted$workflow,
    task     = model_all_workflows_fitted$task,
    .combine  = "c",
    .packages = c("tidymodels", "multilevelmod")
) %dopar% {
  # fitting the models for the implicit task with the appropriate dataset
  if(task == "implicit"){
    model_fit <-
      list(
        workflow |> 
        fit(data = df_implicit_rt) |> 
        extract_fit_engine()
      )
  }
  # and for the explicit task
  else{
    model_fit <-
      list(
        workflow |> 
        fit(data = df_explicit_rt) |> 
        extract_fit_engine()
      )
  }
  
  return(model_fit)
# (measuring runtime for benchmarking)
}) |> system.time() -> time_parallel

# removing irrelevant used columns
model_all_workflows_fitted <-  
  model_all_workflows_fitted |> 
  select(-c(recipe, model, formula, workflow))

# ─── Examining the quality of the models, estimating the parameters ───────────

# parameter tables with all estimates
model_all_workflows_fitted$parameters <-
  foreach(
    fitted_model = model_all_workflows_fitted$fitted_model,
    .combine  = "c",
    .packages = c("parameters")
) %dopar% {
  parameters <- list(model_parameters(fitted_model))
  return(parameters)
}

# convergence checks
model_all_workflows_fitted$convergence <-
  foreach(
    fitted_model = model_all_workflows_fitted$fitted_model,
    .combine  = "c",
    .packages = c("performance")
) %dopar% {
  convergence <- check_convergence(fitted_model)
  return(convergence)
}

# model quality and performance indices
model_all_workflows_fitted$model_perf <-
  foreach(
    fitted_model = model_all_workflows_fitted$fitted_model,
    .combine  = "c",
    .packages = c("performance")
) %dopar% {
  model_perf <- list(model_performance(fitted_model))
  return(model_perf)
}

# extracting relevant indices
model_all_workflows_fitted <-
  model_all_workflows_fitted |>
  mutate(
    # extracting model quality indices
    AIC  = model_perf[[1]],
    AICc = model_perf[[2]],
    BIC  = model_perf[[3]]
  ) |>
  ungroup() |> 
  select(-model_perf)

# stopping the cluster when we're done
parallel::stopCluster(cl = parallel_cluster)

# ─── Comparing the models' quality among those that converged ─────────────────
model_selection <-
  model_all_workflows_fitted |> 
  filter(convergence == TRUE) |> 
  group_by(task, model_id) |> 
  mutate(best_model = ifelse(AICc == min(AICc), TRUE, FALSE)) |> 
  filter(best_model == TRUE)
```

The quality checks of the optimal models selected for the implicit and explicit tasks, that used inverse Gaussian distributions, are displayed in @fig-implicit-checks-extreme and @fig-explicit-checks-extreme. The summaries of estimated model parameters are presented in @tbl-implicit-parameters-extreme and @tbl-explicit-parameters-extreme. The visualizations of the interaction of interest for our hypotheses, Group x Congruence, are depicted in @fig-implicit-model-extreme and @fig-explicit-model-extreme.

```{r loading-glmms-extreme-rds}
#| echo: false

# implicit task
model_task_implicit_extreme <- 
  readRDS(file = "analyses-results/02-glmm-floor-inverse-id-implicit.RDS")

# explicit task
model_task_explicit_extreme <- 
  readRDS(file = "analyses-results/02-glmm-floor-inverse-id-explicit.RDS")
```

#### Models' quality and assumptions

:::{.panel-tabset .column-page-inset-right}
##### Implicit task - Model checks

```{r running-model-checks-implicit-extreme}
#| eval: false
#| code-summary: "Running model checks"

# loading the model saved after the analysis
model_task_implicit_extreme <- 
  readRDS(file = "analyses-results/02-glmm-floor-inverse-id-implicit.RDS")

# characteristics to check
model_checks = c("pp_check","homogeneity", "vif", "outliers", "qq", "reqq")

# plotting
model_task_implicit_extreme |> check_model(check = model_checks, detrend = FALSE)
```

![Model assumption checks for the Generalized Linear Mixed Model fit on the RTs in the implicit task.](plots/S2-glmm-checks-floor-inv-id-implicit.png){#fig-implicit-checks-extreme}

##### Explicit task - Model checks

```{r running-model-checks-explicit-extreme}
#| eval: false
#| code-summary: "Running model checks"

# loading the model saved after the analysis
model_task_explicit_extreme <- 
  readRDS(file = "analyses-results/02-glmm-floor-inverse-id-explicit.RDS")

# characteristics to check
model_checks = c("pp_check","homogeneity", "vif", "outliers", "qq", "reqq")

# plotting
model_task_explicit_extreme |> check_model(check = model_checks, detrend = FALSE)
```

![Model assumption checks for the Generalized Linear Mixed Model fit on the RTs in the explicit task.](plots/S2-glmm-checks-floor-inv-id-explicit.png){#fig-explicit-checks-extreme}
:::

#### Models' estimates

:::{.panel-tabset .column-page-inset-right}
##### Implicit task estimates

```{r implicit-parameters-table-extreme}
#| label: tbl-implicit-parameters-extreme
#| echo: false
#| tbl-cap: "Estimates of the GLMM fitted on the RTs in the implicit task. *'aphantasia (no)' refers to the control group*."

# printing with the package `parameters`
model_task_implicit_extreme |> 
  model_parameters() |>
  print_html() 
```

##### Explicit task estimates

```{r explicit-parameters-table-extreme}
#| label: tbl-explicit-parameters-extreme
#| echo: false
#| tbl-cap: "Estimates of the GLMM fitted on the RTs in the explicit task. *'aphantasia (no)' refers to the control group*."

# printing with the package `parameters`
model_task_explicit_extreme |> 
  model_parameters() |> 
  print_html() 
```

##### Plot - Implicit task

```{r implicit-parameters-fig-extreme}
#| label: fig-implicit-parameters-extreme
#| echo: false
#| fig-cap: "Estimates of the GLMM fitted on the RTs in the implicit task. *'aphantasia (no)' refers to the control group*."
#| out-width: 100%

# plotting with the packages `parameters` and `see`
model_task_implicit_extreme |> 
  model_parameters() |> 
  plot()
```

##### Plot - Explicit task

```{r explicit-parameters-fig-extreme}
#| label: fig-explicit-parameters-extreme
#| echo: false
#| fig-cap: "Estimates of the GLMM fitted on the RTs in the explicit task. *'aphantasia (no)' refers to the control group*."
#| out-width: 100%

# plotting with the packages `parameters` and `see`
model_task_explicit_extreme |> 
  model_parameters() |> 
  plot()
```

:::

#### Group x Congruence interaction plots

:::{.panel-tabset}
##### Implicit task

```{r model-implicit-plot-extreme}
#| label: fig-implicit-model-extreme
#| code-summary: "Creating the plot for the Group x Congruence interaction"
#| fig-cap: "Visualizations of the interactions between Group and Congruence in the optimal models for the implicit task. The black dots indicate marginal means predicted by the models whereas the black bars represent the standard error of these estimates. The stars represent FDR-corrected *p*-values inferior to .05."
#| out-width: 100%

# ─── Setup variables ──────────────────────────────────────────────────────────

# dodge width for all the geoms
dw <- .75
# stat text size
st <- 7
# legend and axis text size
txt <- 18
title_size <- 20

# ─── Marginal means for the plots ─────────────────────────────────────────────
model_implicit_preds_extreme <-
  model_task_implicit_extreme |> 
  estimate_means(
    at = c("aphantasia", "congruence"),
    p_adjust = "fdr"
    )

# ─── Plotting ─────────────────────────────────────────────────────────────────
df_implicit_rt |>
  ggplot(aes(
    x = congruence,
    y = rt * 1000,
    color = aphantasia
  )) +
  # linear modelling of the differences
  geom_line(
    data = model_implicit_preds_extreme,
    aes(
      y = Mean * 1000,
      group = aphantasia
    ),
    position = position_dodge(width = dw),
    linewidth = 1.5,
    linetype = 1
  ) +
  # predicted means of the model and their SE
  geom_pointrange2(
    data = model_implicit_preds_extreme,
    aes(
      x = congruence,
      y = Mean * 1000,
      ymin = Mean * 1000 - SE * 1000,
      ymax = Mean * 1000 + SE * 1000,
      group = aphantasia
      ),
    color = "black",
    position = position_dodge(width = dw),
    size = 1,
    linewidth = .75,
    show.legend = FALSE
  ) +
  # adding a star for the significant contrast
  annotate(
    geom  = "text",
    label = "*",
    fontface = "italic",
    color = "#56b4e9",
    x = 2.05,
    y = 628,
    vjust = .1,
    hjust = 6,
    size  = 12 
    ) +
  labs(
    title = NULL,
    x = NULL,
    y = "Response time (ms)"
    ) +
  # Aesthetics
  scale_y_continuous(breaks = breaks_pretty(10)) +
  scale_x_discrete(labels = c("Congruent", "Incongruent")) +
  scale_color_okabeito(
    name = "", 
    labels = c(" Aphantasic (VVIQ = 16)   ", " Control (VVIQ > 42)")) +
  theme_modern() +
  theme(
    panel.grid.major.x = element_blank(),
    panel.grid.major.y = element_line(),
    axis.ticks.x = element_blank(),
    axis.title.y = element_text(size = txt),
    axis.text.x = element_text(size = txt),
    legend.title = element_text(size = txt),
    legend.text = element_text(size = txt),
    legend.position = "top"
    )
```

##### Explicit task

```{r model-explicit-plot-extreme}
#| label: fig-explicit-model-extreme
#| code-summary: "Creating the plot for the Group x Congruence interaction"
#| fig-cap: "Visualizations of the interactions between Group and Congruence in the optimal models for the explicit task. The black dots indicate marginal means predicted by the models whereas the black bars represent the standard error of these estimates. The stars represent FDR-corrected *p*-values inferior to .05."
#| out-width: 100%

# ─── Setup variables ──────────────────────────────────────────────────────────

# dodge width for all the geoms
dw <- .75
# stat text size
st <- 7
# legend and axis text size
txt <- 18
title_size <- 20

# ─── Marginal means for the plots ─────────────────────────────────────────────
model_explicit_preds_extreme <-
  model_task_explicit_extreme |> 
  estimate_means(
    at = c("aphantasia", "congruence"),
    p_adjust = "fdr"
    )

# ─── Plotting ─────────────────────────────────────────────────────────────────
df_implicit_rt |>
  ggplot(aes(
    x = congruence,
    y = rt * 1000,
    color = aphantasia
  )) +
  # linear modelling of the differences
  geom_line(
    data = model_explicit_preds_extreme,
    aes(
      y = Mean * 1000,
      group = aphantasia
    ),
    position = position_dodge(width = dw),
    linewidth = 1.5,
    linetype = 1
  ) +
  # predicted means of the model and their SE
  geom_pointrange2(
    data = model_explicit_preds_extreme,
    aes(
      x = congruence,
      y = Mean * 1000,
      ymin = Mean * 1000 - SE * 1000,
      ymax = Mean * 1000 + SE * 1000,
      group = aphantasia
      ),
    color = "black",
    position = position_dodge(width = dw),
    size = 1,
    linewidth = .75,
    show.legend = FALSE
  ) +
  labs(
    title = NULL,
    x = NULL,
    y = "Response time (ms)"
    ) +
  # Aesthetics
  scale_y_continuous(breaks = breaks_pretty(10)) +
  scale_x_discrete(labels = c("Congruent", "Incongruent")) +
  scale_color_okabeito(
    name = "", 
    labels = c(" Aphantasic (VVIQ = 16)   ", " Control (VVIQ > 42)")) +
  theme_modern() +
  theme(
    panel.grid.major.x = element_blank(),
    panel.grid.major.y = element_line(),
    axis.ticks.x = element_blank(),
    axis.title.y = element_text(size = txt),
    axis.text.x = element_text(size = txt),
    legend.title = element_text(size = txt),
    legend.text = element_text(size = txt),
    legend.position = "top"
    )
```
:::










































